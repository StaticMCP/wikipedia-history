{
  "content": [
    {
      "type": "text",
      "text": "# MRI artifact\n\nAn MRI artifact is a visual artifact (an anomaly seen during visual representation) in magnetic resonance imaging (MRI). It is a feature appearing in an image that is not present in the original object. Many different artifacts can occur\nduring MRI, some affecting the diagnostic quality, while others may be confused with pathology. Artifacts can be classified as patient-related, signal processing-dependent and hardware (machine)-related.\nPatient-related MR artifacts\nMotion artifacts\nA motion artifact is one of the most common artifacts in MR imaging. Motion can cause either ghost images or diffuse image noise in the phase-encoding direction. The reason for mainly affecting data sampling in the phase-encoding direction is the significant difference in the time of acquisition in the frequency- and phase-encoding directions.  Frequency-encoding sampling in all the rows of the matrix (128, 256 or 512) takes place during a single echo (milliseconds). Phase-encoded sampling takes several seconds, or even minutes, owing to the collection of all the k-space lines to enable Fourier analysis. Major physiological movements are of millisecond to seconds duration and thus too slow to affect frequency-encoded sampling, but they have a pronounced effect in the phase-encoding direction. Periodic movements such as cardiac movement and blood vessel or CSF pulsation cause ghost images, while non-periodic movement causes diffuse image noise (Fig. 1). Ghost image intensity increases with amplitude of movement and the signal intensity from the moving tissue. Several methods can be used to reduce motion artifacts, including patient immobilisation, cardiac and respiratory gating, signal suppression of the tissue causing the artifact, choosing the shorter dimension of the matrix as the phase-encoding direction, view-ordering or phase-reordering methods and swapping phase and frequency-encoding directions to move the artifact out of the field of interest.\nFlow\nFlow can manifest as either an altered intravascular signal (flow enhancement or flow-related signal loss), or as flow-related artifacts (ghost images or spatial misregistration). Flow enhancement, also known as inflow effect, is caused by fully magnetised protons entering the imaged slice while the stationary protons have not fully regained their magnetization.  The fully magnetized protons yield a high signal in comparison with the rest of the surroundings. High velocity flow causes the protons entering the image to be removed from it by the time the 180-degree pulse is administered. The effect is that these protons do not contribute to the echo and are registered as a signal void or flow-related signal loss (Fig. 2).  Spatial misregistration manifests as displacement of an intravascular signal owing to position encoding of a voxel in the phase direction preceding frequency encoding by time TE/2.The intensity of the artifact is dependent on the signal intensity from the vessel, and is less apparent with increased TE.\nMetal artifacts\nMetal artifacts occur at interfaces of tissues with different magnetic susceptibilities, which cause local magnetic fields to distort the external magnetic field. This distortion changes the precession frequency in the tissue leading to spatial mismapping of information. The degree of distortion depends on the type of metal (stainless steel having a greater distorting effect than titanium alloy), the type of interface (most striking effect at soft tissue-metal interfaces), pulse sequence and imaging parameters. Metal artifacts are caused by external ferromagnetics such as cobalt containing make-up, internal ferromagnetics such as surgical clips, spinal hardware and other orthopaedic devices, and in some cases, metallic objects swallowed by people with pica. Manifestation of these artifacts is variable, including total signal loss, peripheral high signal and image distortion (Figs 3 and 4).  Reduction of these artifacts can be attempted by orientating the long axis of an implant or device parallel to the long axis of the external magnetic field, possible with mobile extremity imaging and an open magnet. Further methods used are choosing the appropriate frequency encoding direction, since metal artifacts are most pronounced in this direction, using smaller voxel sizes, fast imaging sequences, increased readout bandwidth and avoiding gradient-echo imaging when metal is present. A technique called MARS (metal artifact reduction sequence) applies an additional gradient, along the slice select gradient at the time the frequency encoding gradient is applied.\nSignal processing dependent artifacts\nThe ways in which the data are sampled, processed and mapped out on the image matrix manifest these artifacts.\nChemical shift artifact\nChemical shift artifact occurs at the fat/water interface in the frequency encoding direction (Fig. 5). These artifacts arise due to the difference in resonance of protons as a result of their micromagnetic environment. The protons of fat resonate at a slightly lower frequency than those of water. High field strength magnets are particularly susceptible to this artifact.  Determination of the artifact can be made by swapping the phase- and frequency-encoding gradients and examining the resultant shift of fat tissue.\nPartial volume\nPartial volume artifacts arise from the size of the voxel over which the signal is averaged. Objects smaller than the voxel dimensions lose their identity, and loss of detail and spatial resolution occurs. Reduction of these artifacts is accomplished by using a smaller pixel size and/or a smaller slice thickness.\nWrap-around\nA wrap-around artifact also known as an aliasing artifact, is a result of mismapping of anatomy that lies outside the field of view but within the slice volume. The selected field of view is smaller than the size of the imaged object. The anatomy is usually displaced to the opposite side of the image (Figs 6 and 7). It can be caused by non-linear gradients or by undersampling of the frequencies contained within the return signal.  The sampling rate must be twice the maximal frequency that occurs in the object (Nyquist sampling limit). If not, the Fourier transform will assign very low values to the frequency signals greater than the Nyquist limit. These frequencies will then 'wrap around' to the opposite side of the image, masquerading as low-frequency signals. In the frequency encode direction a filter can be applied to the acquired signal to eliminate frequencies greater than the Nyquist frequency. In the phase encode direction, artifacts can be reduced by an increasing number of phase encode steps (increased image time). For correction, a larger field of view may be chosen.\nGibbs artifacts\nGibbs artifacts or Gibbs ringing artifacts, also known as truncation artifacts are caused by the under-sampling of high spatial frequencies at sharp boundaries in the image.  Lack of appropriate high-frequency components leads to an oscillation at a sharp transition known as a ringing artifact. It appears as multiple, regularly spaced parallel bands of alternating bright and dark signal that slowly fade with distance (Fig. 8). Ringing artifacts are more prominent in smaller digital matrix sizes.  Methods employed to correct Gibbs artifact include filtering the k-space data prior to Fourier transform, increasing the matrix size for a given field of view, the Gegenbauer reconstruction and Bayesian approach.\nMachine/hardware-related artifacts\nThis is a wide and still expanding subject. Only a few common artifacts are recognised.\nRadiofrequency (RF) quadrature\nRF detection circuit failure arises from improper detector channel operation. Fourier-transformed data display a bright spot in the centre of the image. If one channel of the detector has a higher gain than the other it will result in object ghosting in the image. This is the result of a hardware failure and must be addressed by a service representative.\nExternal magnetic field (B0) inhomogeneity\nB0 inhomogeneity leads to mismapping of tissues. Inhomogeneous external magnetic field causes either spatial, intensity, or both distortions. Intensity distortion occurs when the field in a location is greater or less than in the rest of the imaged object (Fig. 9). Spatial distortion results from long-range field gradients, which remain constant in the inhomogeneous field.\nGradient field artifacts\nMagnetic field gradients are used to spatially encode the location of signals from excited protons within the volume being imaged. The slice select gradient defines the volume (slice). Phase- and frequency-encoding gradients provide the information in the other two dimensions. Any deviation in the gradient would be represented as a distortion.  As the distance increases from the centre of the applied gradient, loss of field strength occurs at the periphery. Anatomical compression occurs and is especially pronounced on coronal and sagittal imaging.  When the phase-encoding gradient is different, the width or height of the voxel is different, resulting in distortion. Anatomical proportions are compressed along one or the other axis. Square pixels (and voxels) should be obtained.  Ideally the phase gradient should be assigned to the smaller dimension of the object and the frequency gradient to the larger dimension. In practice this is not always possible because of the necessity of displacing motion artifacts.  This may be corrected by reducing the field of view, by lowering the gradient field strength or by decreasing the frequency bandwidth of radio signal. If correction is not achieved, the cause might be either a damaged gradient coil or an abnormal current passing through the gradient coil.\nRF (B1) inhomogeneity\nVariation in intensity across the image may be due to the failure of the RF coil, non-uniform B1 field, non-uniform sensitivity of the receive only coil (spaces between wire in the coil, uneven distribution of wire), or presence of non-ferromagnetic material in the imaged object.\nWhen using a FLASH sequence, tip angle variations due to B1 inhomogeneity can affect the contrast of the image. Similarly, for inversion recovery pulses, and other T1-dependent methods, will suffer from signal intensity errors and generally lower T1 weighting. This is due to imperfect flip angles throughout the slice, but particularly around the edges of the body, resulting in imperfect magnetization recovery.\nRF tip angle theory vs reality\nHuman body is full of protons and during imaging, the B0 field aligns these individual protons to a net magnetization in the direction of the magnetic field. An RF pulse that is applied perpendicular to the main magnetic field flips the spins to a desired angle. This flip angle scales with the B1 field amplitude. Accurate flip angle is crucial because the measured MR signals depend on the flip angle of the protons. However, this theory assumes that the B1 field is homogenous and, therefore, all spins in a slice are flipped an equal amount.\nIn reality, different areas of a slice see different radio frequency fields, leading to different flip angles. One reason this occurs is because the RF wavelength is inversely proportional to B0. So RF wavelength decreases when B0 increases. At B0 fields of 1.5T, RF wavelengths are long compared to the size of the body. But as the main magnetic field is increased, these wavelengths become the same or smaller than the regions of the body being imaged, resulting in flip angle inhomogeneity. In the images of a healthy patient's brain, it can be visually seen how inhomogeneous the fields are at 3T and 7T.\nOn a side note, this isn't the only cause of B1 inhomogeneity. It could also be due to the RF pulse design, B0 field inhomogeneity, or even patient movement.\nAsymmetrical brightness\nThere is a uniform decrease in signal intensity along the frequency encoding axis. Signal drop-off is due to filters that are too tight about the signal band. Some of the signal generated by the imaged section is, thereby, inappropriately rejected. A similar artifact may be caused by non-uniformity in slice thickness.\nRF noise\nRF pulses and precessional frequencies of MRI instruments occupy the same frequency bandwidth as common sources such as TV, radio, fluorescent lights and computers. Stray RF signals can cause various artifacts. Narrow-band noise is projected perpendicular to the frequency- encoding direction. Broadband noise disrupts the image over a much larger area. Appropriate site planning, proper installation and RF shielding (Faraday cage) eliminate stray RF interference.\nZero line and star artifacts\nA bright linear signal in a dashed pattern that decreases in intensity across the screen and can occur as a line or star pattern, depending on the position of the patient in the 'phase-frequency space'.  Zero line and star artifacts are due to system noise or any cause of RF pollution within the room (Faraday cage). If this pattern persists, check for sources of system noise such as bad electronics or alternating current line noise, loose connections to surface coils, or any source of RF pollution. If a star pattern is encountered, the manufacturer needs to readjust the system software so that the image is moved off the zero point.\nZipper artifacts\nAlthough less common, zippers are bands through the image centre due to an imperfect Faraday cage, with RF pollution in, but originating from outside, the cage. Residual free induction decay stimulated echo also causes zippers.\nBounce point artifact\nAbsence of signal from tissues of a particular T1 value is a consequence of magnitude sensitive reconstruction in inversion recovery imaging. When the chosen T1 equals 69% of the T1 value of a particular tissue, a bounce point artifact occurs.  Use phase-sensitive reconstruction inversion recovery techniques.\nSurface coil artifacts\nClose to the surface coil the signals are very strong resulting in a very intense image signal (Fig. 10).  Further from the coil the signal strength drops rapidly due to the attenuation with a loss of image brightness and significant shading to the uniformity. Surface coil sensitivity intensifies problems related to RF attenuation and RF mismatching.\nSlice-to-slice interference\nNon-uniform RF energy received by adjacent slices during a multi-slice acquisition is due to cross-excitation of adjacent slices with contrast loss in reconstructed images (Fig. 11). To overcome these interference artifacts, the acquisition of two independent sets of gapped multi-slice images need to be included, and subsequently reordered during display of the full image set.\nArtifact correction\nMotion correction\nGating\nGating, also known as triggering, is a technique that acquires MRI data at a low motion state. An example of this could be acquiring an MRI slice only when the lung capacity is low (i.e. between large breaths). Gating is a very simple solution that can have a very large result.\nGating is best suited for mitigating breathing and cardiac artifacts. This is because these types of motion are repetitive, so we can leverage triggering acquisitions in a 'low motion state'. Gating is used for cine imaging, MRA, free-breathing chest scans, CSF flow imaging, and more.\nIn order to gate correctly, the system needs to have knowledge of the patient's cardiac motion and breathing pattern. This is commonly done by using a pulse oximeter or EKG sensor to read a cardiac signal and/or a bellows to read the breathing signal.\nA big disadvantage to gating is 'dead time', defined as time wasted due to waiting for a high motion state to pass. For example, we do not want to acquire an MRI image while someone is in the process of inhaling, since this would be a high motion state. So, we have many time periods where we are waiting for a high motion state to pass. This is even more prominent when we consider respiratory and cardiac gating together. The windows of time where the respiratory and cardiac motions are low are very infrequent, leading to high dead times. However, the advantage is that images acquired with both cardiac and respiratory gating have a significant improvement in image quality.\nPilot tone\nThe Pilot Tone method involves turning on a constant RF frequency to detect patient motion. More specifically, the MRI machine will detect the pilot tone signal when acquiring an image. The strength of the pilot tone signal at every TR will be proportional to the breathing/motion patterns of the patient. That is, the patient's movements will cause the received constant RF tone to be amplitude modulated.  A very large advantage to the pilot tone is that it requires no contact with the patient.\nExtracting a breathing signal using a pilot tone is simple in theory: One must place a constant frequency signal near the MRI bore, acquire an image, and take an FFT along the readout direction to extract the pilot tone. Technical considerations include choosing the RF frequency. The pilot tone must be detectable by the MRI machine, however must be carefully chosen not to interfere with the MRI image. The pilot tone shows up as a zipper (for a cartesian acquisition).\nThe location of that line is determined by the frequency of the RF tone. For this reason, pilot tone acquisitions usually have slightly large FOVs, to make room for the pilot tone.\nOnce an image has been acquired, the pilot tone signal can be extracted by taking the FFT along the readout direction and plotting the amplitude of the resulting signal. The pilot tone will show up as a line (of varying amplitude) when taking an FFT along the readout direction. The pilot tone method can also be used prospectively to acquire cardiac images.\nThe Pilot Tone method is great for detecting respiratory motion artifacts. This is because there is a very large and distinct modulation due to human breathing patterns. Heart signals are much more subtle and difficult to detect using a pilot tone. Retrospective techniques using the pilot tone are able to increase the level of detail and reduce blurring in free-breathing radial images.\nTAMER\nTargeted Motion Estimation and Reduction (TAMER) is a retrospective motion correction method developed by Melissa Haskell, Stephen Cauley, and Lawrence Wald. The method was first introduced in their paper Targeted Motion Estimation and Reduction (TAMER): Consistency Based Motion Mitigation for MRI using a Reduced Model Joint Optimization, as part of the IEEE Transactions on Medical Imaging Journal. The method corrects motion-related artifacts by acquiring a joint estimation of the desired motion-free image and the associated motion trajectory by minimizing the data consistency error of a SENSE forward model that includes rigid-body subject motion.\nPreliminaries\nThe TAMER Method utilizes the SENSE forward model (described below) that has been modified to include the effects of motion in a 2D multi-shot imaging sequence. Note: the following modified SENSE model is described in detail in Melissa Haskell's doctoral dissertation, Retrospective Motion Correction for Magnetic Resonance Imaging.\nSuppose that we have C coils. Let x  be a nN_{sh} \\times 1 column vector of image voxel values where n  is the number of k space samples acquired per shot and let s  be the nN_{sh}C \\times 1 signal data from C  coils. Let E_{\\theta} \\text{ be an } nN_{sh}C \\times nN_{sh}  encoding matrix for a given M \\times 1 patient motion trajectory vector, \\theta. E_{\\theta} is composed of N_{sh}  many nC \\times nN_{sh} sub-matrices E_{\\theta_i} = U_iFCT_{xy,i}T_{z,i}R_i (encoding matrices for each shot i).\nFor each shot i , we have the sub-matrix E_{\\theta_i} = U_iFCT_{xy,i}T_{z,i}R_i which is the encoding matrix for that particular shot  i where:\nU_i is the nC \\times nN_{sh}C under-sampling operator\nF is the Fourier Encoding Operator\nT_{xy,i} is the in-place translation operator\nTz,i is the  through-plane translation operator\nR_i is the rotation operator\nSENSE Motion Forward Model: s = Ex\nSENSE model Extended to describe a 2D multi-shot imaging sequence: s = E_{\\theta}x \\text{ where } E_{\\theta} = \\begin{pmatrix} E_{\\theta_1}\\\\ E_{\\theta_2} \\\\ . \\\\ . \\\\ . \\\\ E_{\\theta_{Nsh}} \\end{pmatrix}\n\\text{ and } E_{\\theta_i} = U_iFCT_{xy,i}T_{z,i}R_i \\text{ for shot } i = 1, 2, ..., N_{sh}\nThe rigid-body motion forward model is nonlinear and the process of solving for estimations of both the motion trajectory and the image volume is computationally challenging and time-consuming. In the effort to speed up and simplify computations, the TAMER method separates the vector of image voxel values,  x , into a vector of target voxel values,  x_t  , and a vector of fixed voxels,  x_f . Given any choice of target voxels and fixed voxels, we have the following:\nx = \\binom{x_t}{x_f}\ns = s_t + s_f = E_{\\theta}(t)x_t + E_{\\theta}(f) x_f\ns_t = s -  E_{\\theta}(f) x_f =  E_{\\theta}(t)x_t\nNote: The length of x_t only makes up about 5% of the total length of x.\nNow the optimization can be reduced to fitting the signal contribution of the target voxels to the correct target voxel values  x_t  and the correct motion,  \\theta .\nTAMER Algorithm\nThe TAMER algorithm has 3 main stages: Initialization, Jumpstart of Motion Parameter Search, and the Joint Optimization Reduced Model Search.\nInitialization:\nThe first stage of the TAMER algorithm acquires the initial reconstruction of the full image volume,  x_0 , by assuming that all motion parameters are zero. One can solve for  x_0  by minimizing the least squared error of the SENSE forward model without motion i.e. solve the system  (E_0^HE_0)x_0 = E_0^Hs  where  E_0 = UFC  and  E_0^H  is the conjugate transpose of   E_0 . We have discussed the notion of separating the sense model into  s = s_t + s_f = E_{\\theta}(t)x_t + E_{\\theta}(f) x_f ; however, we haven't yet discussed how the target voxels are chosen. Voxels that are strongly coupled together indicate motion. In a motion-free Cartesian acquisition, each voxel would only be coupled to itself, so our goal is to essentially un-couple these voxels. As described in the paper Targeted Motion Estimation and Reduction (TAMER): Consistency Based Motion Mitigation for MRI using a Reduced Model Joint Optimization, as part of the IEEE Transactions on Medical Imaging Journal, the TAMER algorithm converges fastest when choosing target voxels that are highly coupled. The target voxels can be entirely determined by the sequence parameters and coil sensitivities.\nTarget Voxel Selection Process:\n# Group coils based on artifact properties.  The model error is first computed assuming no motion. The model correlation is then computed across all channels. TAMER is applied to groups of coils with the largest correlation artifacts to attain the motion and image estimation.\n# The initial target voxels are selected by first choosing a root voxel (generally the center of the image). Once the root voxel is chosen, the correlation between the root voxel and all other voxels is determined by attaining the column vector of the correlation matrix E^HE corresponding to the root voxel. The magnitude of the entries in this column vector represent the strength of interaction between the root voxel and all of the other voxels. The root voxel along with the voxels that have the strongest interaction with the root voxel are then chosen to be the initial target voxels.\nNote: For each iteration of the TAMER process, the target voxels are selected by shifting the target voxels from the previous iteration perpendicularly to the phase encode direction by a preset amount.\nJumpstart of Motion Parameter Search:\nNow the initial guess of the patient's motion is determined by evaluating the data consistency metric over a range of values for each of the M motion parameters and the best value for each parameter is selected to construct the initial guess.\nJoint Optimization Reduced Model Search:\nWe now have the initial target voxels, motion estimate, and coil groupings. The following procedure is now executed.\nLet \\theta^{(i)} be the motion trajectory estimate for the i^{th}search step. Let i_{max} be the max number of iterations.\nWhile i  \\Delta \\epsilon_{max}\nrepeat the following:\n# Solve for s_{t}^{\\left(i\\right)}\\,\\to s_{t}^{\\left(i\\right)}\\,=\\,s\\,-\\,E_{\\theta^{\\left(i\\right)}}\\left(f\\right)x_{f}=\n\\,E_{\\theta^{\\left(i\\right)}}\\left(t\\right)x_{t}\n# Solve for x_{t}^{\\left(i\\right)}\\,\\to E_{\\theta^{\\left(i\\right)}}^{H}\\left(t\\right)E_{\\theta^{\\left(i\\right)}}\\left(t\\right)\\,x_{t}^{\\left(i\\right)}=\\,E_{\\theta^{\\left(i\\right)}}^{H}\\left(t\\right)x_{f}\n# Set \\epsilon^{(i)} = || s - E_{\\theta^{(i)}}x^{(i)}||\n# Set \\,\\theta^{\\left(i+1\\right)}\\,=\\,\\theta^{\\left(i\\right)}\\,+\\,\\nabla^{\\left(i\\right)}\\,\\to\\,\\,\\nabla^{\\left(i\\right)}\\,=\n\\epsilon^{(i)} - || s - E_{\\left(\\theta ^{\\left(i\\right)}\\,+\\,d\\theta^{\\left(i\\right)}\\right)\\,}x^{\\left(i\\right)}||_2\n# Set i = i + 1\nTAMER: Advantages and Disadvantages\nAdvantages:\n* TAMER retrospectively corrects for motion, so modifications to the MRI exam procedure isn't necessary.\n* TAMER doesn't alter the acquisition procedure, so it can be easily integrated into current clinical MRI scans.\n* TAMER significantly reduces computation of the joint optimization model used to estimate motion parameters and image voxels.\nDisadvantages:\n* Current TAMER implementations have lengthy overall computation times.\n* TAMER requires multi-channel data as the motion parameters need additional degrees of freedom which is provided by the multichannel acquisition.\n* The TAMER algorithm assumes static coil profiles that don't change with the motion of the patient. This assumption would be an issue for larger motion.\nNeural network approaches\nIn recent years, neural networks have generated a great deal of interest by outperforming traditional methods on longstanding problems across many fields. Machine learning, and by extension neural networks, have been used in many facets of MRI — for instance, speeding up image reconstruction, or improving reconstruction quality when working with a lack of data. Neural networks have also been used in motion artifact correction thanks to their ability to learn visual information from data, as well as infer underlying, latent representations in data.\nNAMER\nNetwork Accelerated Motion Estimation and Reduction (NAMER) is a retrospective motion correction technique that utilizes convolutional neural networks (CNNs), a class of neural networks designed to process and learn from visual information such as images. This is a follow-up from the authors of the TAMER paper titled Network Accelerated Motion Estimation and Reduction (NAMER): Convolutional neural network guided retrospective motion correction using a separable motion model. Similar to TAMER, the paper aims to correct for motion-related artifacts by way of estimating a desired motion-free image and optimizing parameters for a SENSE forward model describing the relationship between raw k-space data and image space while factoring in rigid motion.\nSetup\nA SENSE forward model is used to induce synthetic motion artifacts in raw k-space data, allowing us access to both data with motion artifacts, as well as the ground-truth image without motion artifacts. This is important to the NAMER technique, because it utilizes a Convolutional Neural Network (CNN) to frontload image estimation and guide model parameter estimation. Convolutional Neural Networks leverage convolution kernels to analyze visual imagery. Here, a 27-layer network is used with multiple convolution layers, batch normalization, and ReLU activations. It uses a standard ADAM optimizer.\nImage Estimation\nThe CNN attempts to learn the image artifacts from the motion-corrupted input data x. The estimate for these artifacts, denoted as CNN(x), are then subtracted from the motion-corrupted input data x in order to produce a best estimate for the motion-free image:x_{CNN} = x - CNN(x)This serves two purposes: First, it allows the CNN to perform backpropagation and update its model weights by using a mean square error loss function comparing the difference between x_{CNN} and the known ground-truth motion-free image. Second, it gives us a good estimate of the motion-free image that gives us a starting point for model parameter optimization.\nSENSE model parameter optimization\nUsing a CNN effectively allows us to bypass the second stage of TAMER by skipping the joint parameter search. This means that we can focus on solely estimating motion parameters \\theta. Because \\theta is really a vector of multiple, independent parameters, we can parallelize our optimization by estimating each parameter separately.\nOptimizing the Optimization Procedure\nBefore, we used the following to optimize both the image x and parameters \\theta at once. Now, we can optimize solely the \\theta values:\n\\hat{\\theta} = argmin_{\\theta} \\Vert s - E_\\theta x_{CNN} \\Vert_2\nOn top of this, if a multi-shot acquisition was performed, we can estimate the parameters \\theta_n for each of n shots separately, and go even further by estimating the parameters \\theta_{n, l} for each line l in each shot n:\n\\hat{\\theta}_{n, l} = argmin_{\\theta_{n, l}} \\Vert s_{n, l} - E_{\\theta_{n, l}} x_{CNN} \\Vert_2\nThis allows us to massively reduce computation time, from around 50 minutes with TAMER to just 7 minutes with NAMER.\nReconstruction\nThe new model parameters are then used in a standard Least Squares optimization problem to reconstruct an image that minimizes the distance between the k-space data, and the result of applying the SENSE forward model E_{\\hat{\\theta}} under our new parameter estimate \\hat{\\theta} to our best estimate for the motion-free image:[\\hat{x}] = arg\\min_x \\Vert s - E_{\\hat{\\theta}} x \\Vert_2This process is repeated until a desired number of time steps, or when the change in reconstructed image is sufficiently low. The NAMER technique has shown itself to be very effective in correcting for rigid motion artifacts, and converges much faster than other methods including TAMER. This illustrates the power of deep learning in improving results across myriad fields.\nGenerative adversarial networks\nOther more advanced techniques take advantage of generative adversarial networks (GANs) which aim to learn the underlying latent representation of data in order to synthesize new examples that are indistinguishable from real data. Here, two neural networks, a Generator Network and a Discriminator Network, are modelled as agents competing in a game. The Generator Network's goal is to produce synthetic images that are as close as possible to images from the true distribution, while the Discriminator Network's goal is to distinguish generated synthetic images from the true data distribution. Specific to motion artifact correction in MRI, the Generator Network takes in an image with motion artifacts, and outputs an image without motion artifacts. The Discriminator Network then differentiates between the synthesized image and ground truth data. Various studies have shown that GANs perform very well in correcting for motion artifacts.\nRF (B1) Inhomogeneity Correction\nExternal Objects\nB1 inhomogeneity due to constructive or destructive interference from the permittivity of body tissue can be mitigated using external objects with high dielectric constants and low conductivity. These objects, called radiofrequency/dielectric cushion, can be placed over or near the imaging slice to improve B1 homogeneity. The combination of high dielectric constant and having low conductivity allows the cushion to alter the phase of the RF standing waves and has been shown to reduce signal loss due to B1 inhomogeneity. This correction method was shown to have the greatest effect on sequences that suffer from B1 inhomogeneity artifacts but has no effect on those with B0 inhomogeneity. In one study, the dielectric cushion improved image quality for turbo spin echo‐based T2‐weighted sequences but not on gradient echo‐based T2‐weighted sequences.\nCoil Mitigated Corrections\nB1 inhomogeneity has been successfully mitigated by adjusting coil type and configurations.\nReducing the number of coils\nOne method is as simple as using the same transmit and receive coil to improve homogeneity. This method exploits the tradeoff between B1 dependence and coil sensitivity dependence in FLASH sequences and allows the user to select an optimized flip angle that will reduce B1 dependence. By using the same coil for transmitting and receiving, the receiver coil sensitivity can offset some of the nonuniformities in the transmitter coil, reducing the overall RF inhomogeneity. For anatomical studies using the FLASH sequence that can be performed with one transmit and receive coil, this method can be used to reduce B1 inhomogeneity artifacts. However, the method would not be suitable for exams under strict time constraints, since the user first needs to perform flip angle optimization.\nCoil excitation\nModifying the field distribution within the RF coils will create a more homogenous field. This can be done by changing the way that the RF coil is driven and excited. One method uses a four-port RF excitation that applies different phase shifts at each port.\nBy implementing a four-port drive, the power requirement is decreased by 2, SNR is increased by √2, and the overall B1 homogeneity is improved.\nSpiral coil\nChanging the shape of the coils can be used to reduce B1 inhomogeneity artifacts. The use of spiral coil instead of standard coils at higher fields has been shown to eliminate the effects of standing waves in larger samples. This method can be effective when imaging large samples at 4T or higher; however, the proper equipment is required to implement this correction method. Unlike post-processing or sequence modulations, changing the coil shape is not feasible in all scanners.\nParallel excitation with coils\nAnother method to correct for B1 inhomogeneity is to employ the infrastructure in place from a parallel system to generate multiple RF pulses of lower flip angles that, together, can result in the same flip angle as that created using a single transmit coil. This method uses the multiple transmit coils from parallel imaging systems to reduce and better mitigate the RF power deposition by relying on shorter RF pulses. One advantage of using parallel excitation with coils is the potential to reduce scan time by combining the multiple short RF pulses and the parallel imaging capabilities to cut scan time. Overall, when this method is used with the correct selection of RF pulses and optimized for a low power deposition, the artifacts from B1 inhomogeneity can be greatly reduced.\nActive Power modulation\nActively modulating the RF transmit power for each slice position compensates for B1 inhomogeneity. This method focuses on inhomogeneity along the axial, or z axis, direction since it is the most dominant in terms of poor homogeneity and least sample dependent.\nPrior to inhomogeneity correction, measurement of the B1 profile along the z-axis of the coil is necessary for calibration. Once calibrated, the B1 data can be used for active transmit power modulation. For a specific pulse sequence, the values of each slice position are pre-determined and the appropriate RF transmitter power scale values are read from a look-up table. Then, while the sequence runs, a real time slice counter varies the attenuation of the RF transmit power.\nThis method is advantageous for reducing artifacts at the source, particularly when accurate flip angle is critical and for increasing signal to noise ratio. Even though this technique can only be used to compensate for the B1 variation along the z-axis in axially acquired images, it's still significant since B1 inhomogeneity is most dominant along this axis.\nB1 insensitive adiabatic pulses\nOne way to achieve perfect spin inversion despite B1 inhomogeneity is to use adiabatic pulses. This correction method works by removing the source of the problem and applying pulses that will not generate flip angle errors. Specific sequences that employ adiabatic pulses for increased flip angle uniformity include a slice selective spin-echo pulse, adiabatic 180 degrees inversion RF pulses, and 180 degrees refocusing pulses.\nImage post-processing\nPost-processing techniques correct for intensity inhomogeneity (IIH) of the same tissue over an image domain. This method applies a filter to the data, typically based on a pre-acquired IIH map of the B1 field. If a map of the IIH in the image domain is known, then the IIH can be corrected by division into the pre-acquired image. This popular model in describing the IIH effect is:\n*  x = \\alpha x'+ \\xi\nWhere  x  is the measured intensity,  x'  is the true intensity,  \\alpha  is the IIH effect and ξ is the noise.\nThis method is advantageous because it can be conducted offline, i.e., the patient is not required to be in the scanner. Therefore, correction time is not an issue. However, this technique does not improve SNR and contrast of the image because it only utilizes information that was already acquired. Since the B1 field was not homogeneous when the images were acquired, the flip angles and subsequent acquired signals are imprecise.\nThe effects of an AI-based image post-scan processing denoising system in brain scans have been demonstrated to be effective in higher image quality and morphometric analysis. Post-scan image processing systems enable noise reduction while retaining contrast. The subsequent image enhancement can be processed with shorter scan times for higher throughput and plausible earlier detection.\nB1 mapping techniques for image post-processing corrections\nTo correct RF inhomogeneity artifacts using post-processing corrections, there are a few methods to map the B1 field. Here is a short description of some common techniques.\nDouble angle method\nA common and robust method that uses the results from two images acquired at flip angles of \\alpha and 2\\alpha. The B1 map is then constructed using a ratio of the signal intensities of these two images. This method, although robust and accurate, requires a long TR and long scan time; therefore, the method is not optimal for imaging regions susceptible to motion.\nPhase map method\nSimilar to the double angle method, the phase map method uses two images; however, this method relies on the accrual of phase to determine the real flip angle of each spin. After applying a 180 degree rotation about the x-axis followed by a 90 degree rotation about the y axis, the resulting phase is then used to map the B1 field. By obtaining two images and subtracting one from the other, any phase from B0 inhomogeneity can be removed and only phase accumulated by the inhomogeneous RF field will be mapped. This method can be used to map 3D volumes but requires a long scan time, making it unsuitable for some scanning requirements.\nDual Refocusing Echo Acquisition Mode (DREAM)\nThis method is a multislice B1 mapping technique. DREAM can be used to acquire a 2D B1 map in 130 ms, making it insensitive to motion and feasible for scans that require breath holds, such as cardiac imaging. The short acquisition also reduces effects of chemical shifts and susceptibility. Additionally, this method requires low SAR rates. Although not as accurate as the double angle method, DREAM achieves reliable B1 mapping during short acquisitions. T\nReferences\n}}"
    }
  ]
}