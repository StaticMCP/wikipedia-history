{
  "content": [
    {
      "type": "text",
      "text": "# Cell software development\n\nSoftware development for the Cell microprocessor involves a mixture of conventional development practices for the PowerPC-compatible PPU core, and novel software development challenges with regard to the functionally reduced SPU coprocessors.\nLinux on Cell\nAn open source software-based strategy was adopted to accelerate the development of a Cell BE ecosystem and to provide an environment to develop Cell applications, including a GCC-based Cell compiler, binutils and a port of the Linux operating system.\nOctopiler\nOctopiler is IBM's prototype compiler to allow software developers to write code for Cell processors.\nSoftware portability\nAdapting VMX for SPU\nDifferences between VMX and SPU\nThe VMX (Vector Multimedia Extensions) technology is conceptually similar to the vector model provided by the SPU processors, but there are a number of significant differences.\n{| class=\"wikitable\" style=\"margin: 1em auto 1em auto\"\n|+ VMX to SPU Comparisonunfinished\n! feature || VMX || SPU\n|-\n! word size\n| 32 bits || 32 bits\n|-\n! number of registers\n| 32  || 128\n|-\n! register width\n| 128-bit quadword  || 128-bit quadword\n|-\n! integer formats\n| 8, 16, 32  || 8, 16, 32, 64\n|-\n! saturation support\n| yes  || no\n|-\n! byte ordering\n| big (default), little  || big endian\n|-\n! floating point modes\n| Java, non-Java || single precision, IEEE double\n|-\n! Memory alignment\n| quadword only || quadword only\n|}\nThe VMX Java mode conforms to the Java Language Specification 1 subset of the default IEEE Standard, extended to include IEEE and C9X compliance where the Java standard falls silent. In a typical implementation, non-Java mode converts denormal values to zero but Java mode traps into an emulator when the processor encounters such a value.\nThe IBM PPE Vector/SIMD manual does not define operations for double-precision floating point, though IBM has published material implying certain double-precision performance numbers associated with the Cell PPE VMX technology.\nIntrinsics\nCompilers for Cell provide intrinsics to expose useful SPU instructions in C and C++. Instructions that differ only in the type of operand (such as a, ai, ah, ahi, fa, and dfa for addition) are typically represented by a single C/C++ intrinsic which selects the proper instruction based on the type of the operand.\nPorting VMX code for SPU\nA substantial amount of VMX (Altivec) code developed for IBM Power microprocessors, particularly under the PowerPC version of macOS, can potentially be adapted for use on the SPU. The feasibility of porting depends on the extent of VMX-specific features usedâ€”ranging from straightforward to impractical. However, key workloads typically map well to the SPU architecture.\nIn some cases, existing VMX code can be ported directly. If the VMX code is highly generic (makes few assumptions about the execution environment) the translation can be relatively straightforward. The two processors specify a different binary code format, so recompilation is required at a minimum. Even where instructions exist with the same behaviors, they do not have the same instruction names, so this must be mapped as well. IBM's development toolkit includes compiler intrinsics that automate much of this mapping.\nIn multiple cases, however, a directly equivalent instruction does not exist. The workaround might be obvious or it might not. For example, if saturation behavior is required on the SPU, it can be coded by adding additional SPU instructions to accomplish this (with some loss of efficiency). At the other extreme, if Java floating-point semantics are required, this is almost impossible to achieve on the SPU processor. To achieve the same computation on the SPU might require that an entirely different algorithm be written from scratch.\nThe most important conceptual similarity between VMX and the SPU architecture is supporting the same vectorization model. For this reason, most algorithms adapted to Altivec will usually adapt successfully to the SPU architecture as well.\nLocal store exploitation\nTransferring data between the local stores of different SPUs can have a large performance cost. The local stores of individual SPUs can be exploited using a variety of strategies.\nApplications with high locality, such as dense matrix computations, represent an ideal workload class for the local stores in Cell BE.\nStreaming computations can be efficiently accommodated using software pipelining of memory block transfers using a multi-buffering strategy.\nThe software cache offers a solution for random accesses.\nMore sophisticated applications can use multiple strategies for different data types.\nReferences\n* [http://www.research.ibm.com/cell/ The Cell Project at IBM Research]\n* [http://cag.csail.mit.edu/crg/papers/eichenberger05cell.pdf Optimizing Compiler for a CELL Processor]\n* [https://dx.doi.org/10.1147/sj.451.0059 Using advanced compiler technology to exploit the performance of the Cell Broadband Engine architecture]\n* [http://domino.research.ibm.com/comm/research_projects.nsf/pages/cellcompiler.index.html Compiler Technology for Scalable Architectures]"
    }
  ]
}