{
  "content": [
    {
      "type": "text",
      "text": "# Exploration problem\n\nIn robotics, the exploration problem deals with the use of a robot to maximize the knowledge over a particular area. The exploration problem arises in robotic mapping and search & rescue situations, where an environment might be dangerous or inaccessible to humans.\nOverview\nThe exploration problem naturally arises in situations in which a robot is utilized to survey an area that is dangerous or inaccessible for humans. The field of robotic explorations draws from various fields of information gathering and decision theory, and have been studied as far back as the 1950s.\nThe earliest work in robotic exploration was done in the context of simple finite state automata known as bandits, where algorithms were designed to distinguish and map different states in a finite-state automaton. Since then, the primary emphasis has been shifted to the robotics system development domain, where exploration-algorithms guided robot have been used to survey volcanos, search and rescue, and abandoned mines mapping. Current state of the art system include advanced techniques on active localization, simultaneous localization and mapping (SLAM) based exploration, and multi-agent cooperative exploration.\nInformation gain\nThe key concept in the exploration problem is the notion of information gain, that is, the amount of knowledge acquired while pushing the frontiers. A probabilistic measure of information gain is defined by the entropy\n: H_p(x)=-\\int p(x) \\log p(x) \\, dx.\nThe function H_p(x) is maximized if p is a uniform distribution and minimized when p is a point mass distribution. By minimizing the expected entropy of belief, information gain is maximized as\n: I_b(u) = H_p(x)-E_z \\left[ H_b(x'|z,u) \\right].\nSee also\n* Kidnapped robot problem\n* Wake-up robot problem\nReferences"
    }
  ]
}