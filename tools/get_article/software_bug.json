{
  "content": [
    {
      "type": "text",
      "text": "# Software bug\n\nA software bug is a design defect (bug) in computer software. A computer program with many or serious bugs may be described as buggy.\nThe effects of a software bug range from minor (such as a misspelled word in the user interface) to severe (such as frequent crashing).\nIn 2002, a study commissioned by the US Department of Commerce's National Institute of Standards and Technology concluded that \"software bugs, or errors, are so prevalent and so detrimental that they cost the US economy an estimated $59&nbsp;billion annually, or about 0.6 percent of the gross domestic product\".\nSince the 1950s, some computer systems have been designed to detect or auto-correct various software errors during operations.\nHistory\nTerminology\nMistake metamorphism (from Greek meta = \"change\", morph = \"form\") refers to the evolution of a defect in the final stage of software deployment. Transformation of a mistake committed by an analyst in the early stages of the software development lifecycle, which leads to a defect in the final stage of the cycle has been called mistake metamorphism.\nDifferent stages of a mistake in the development cycle may be described as mistake,anomaly, fault, failure, error, exception, crash, glitch, bug, defect, incident, or side effect.\nExamples\nSoftware bugs have been linked to disasters.\n* Software bugs in the Therac-25 radiation therapy machine were directly responsible for patient deaths in the 1980s.\n* In 1996, the European Space Agency's US$1&nbsp;billion prototype Ariane 5 rocket was destroyed less than a minute after launch due to a bug in the on-board guidance computer program.\n* In 1994, an RAF Chinook helicopter crashed, killing 29; was initially blamed on pilot error, but was later thought to have been caused by a software bug in the engine-control computer.\n* Buggy software caused the early 21st century British Post Office scandal.\nControversy\nSometimes the use of bug to describe the behavior of software is contentious due to perception. Some suggest that the term should be abandoned; contending that bug implies that the defect arose on its own and push to use defect instead since it more clearly indicates they are caused by a human.\nSome contend that bug may be used to cover up an intentional design decision. In 2011, after receiving scrutiny from US Senator Al Franken for recording and storing users' locations in unencrypted files,\nApple called the behavior a bug. However, Justin Brookman of the Center for Democracy and Technology directly challenged that portrayal, stating \"I'm glad that they are fixing what they call bugs, but I take exception with their strong denial that they track users.\"\nPrevention\nin France]]\nPreventing bugs as early as possible in the software development process is a target of investment and innovation.\nLanguage support\nNewer programming languages tend to be designed to prevent common bugs based on vulnerabilities of existing languages. Lessons learned from older languages such as BASIC and C are used to inform the design of later languages such as C# and Rust.\nA compiled language allows for detecting some typos (such as a misspelled identifier) before runtime which is earlier in the software development process than for an interpreted language.\nLanguages may include features such as a static type system, restricted namespaces and modular programming. For example, for a typed, compiled language (like C):\nfloat num = \"3\";\nis syntactically correct, but fails type checking since the right side, a string, cannot be assigned to a float variable. Compilation fails  forcing this defect to be fixed before development progress can resume. With an interpreted language, a failure would not occur until later at runtime.\nSome languages exclude features that easily lead to bugs, at the expense of slower performance  the principle being that it is usually better to write simpler, slower correct code than complicated, buggy code. For example, Java does not support pointer arithmetic which can be very fast but may lead to memory corruption or segmentation faults if not used with great caution.\nSome languages include features that add runtime overhead in order to prevent common bugs. For example, many languages include runtime bounds checking and a way to recover from out-of-bounds errors instead of crashing.\nTechniques\nStyle guidelines and defensive programming can prevent easy-to-miss typographical errors (typos).\nFor example, most C-family programming languages allow the omission of braces around an instruction block if there's only a single instruction. The following code executes function  only if  is true:\nif (condition)\nfoo();\nBut this code always executes :\nif (condition);\nfoo();\nUsing braces - even if they're not strictly required - reliably prevents this error:\nif (condition) {\nfoo();\n}\nEnforcement of conventions may be manual (i.e. via code review) or via automated tools such as linters.\nSpecification\nSome contend that writing a program specification, which states the intended behavior of a program, can prevent bugs. Others, however, contend that formal specifications are impractical for anything but the shortest programs, because of problems of combinatorial explosion and indeterminacy.\nSoftware testing\nOne goal of software testing is to find bugs. Measurements during testing can provide an estimate of the number of likely bugs remaining. This becomes more reliable the longer a product is tested and developed.\nAgile practices\nAgile software development may involve frequent software releases with relatively small changes. Defects are revealed by user feedback.\nWith test-driven development (TDD), unit tests are written while writing the production code, and the production code is not considered complete until all tests have been written and complete successfully.\nStatic analysis\nTools for static code analysis help developers by inspecting the program text beyond the compiler's capabilities to spot potential problems. Although in general the problem of finding all programming errors given a specification is not solvable (see halting problem), these tools exploit the fact that human programmers tend to make certain kinds of simple mistakes when writing software.\nInstrumentation\nTools to monitor the performance of the software as it is running, either specifically to find problems such as bottlenecks or to give assurance as to correct working, may be embedded in the code explicitly (perhaps as simple as a statement saying PRINT \"I AM HERE\"), or provided as tools. It is often a surprise to find that most of the time is taken by a piece of code, and this removal of assumptions might cause the code to be rewritten.\nOpen source\nOpen source development allows anyone to examine source code. A school of thought popularized by Eric S. Raymond as Linus's law says that popular open-source software has more chance of having few or no bugs than other software, because \"given enough eyeballs, all bugs are shallow\". This assertion has been disputed, however: computer security specialist Elias Levy wrote that \"it is easy to hide vulnerabilities in complex, little understood and undocumented source code,\" because, \"even if people are reviewing the code, that doesn't mean they're qualified to do so.\" An example of an open-source software bug was the 2008 OpenSSL vulnerability in Debian.\nDebugging\nDebugging can be a significant part of the software development lifecycle. Maurice Wilkes, an early computing pioneer, described his realization in the late 1940s that\n“a good part of the remainder of my life was going to be spent in finding errors in my own programs”.\nTypically, the first step in locating a bug is to reproduce it reliably. If unable to reproduce the issue, a programmer cannot find the cause of the bug and therefore cannot fix it.\nSome bugs are revealed by inputs that may be difficult to reproduce. One cause of the Therac-25 radiation machine deaths was a bug (specifically, a race condition) that occurred only when the machine operator very rapidly entered a treatment plan; it took days of practice to become able to do this, so the bug did not manifest in testing or when the manufacturer attempted to reproduce it. Other bugs may stop occurring whenever the setup is augmented to help find the bug, such as running the program with a debugger; these are called heisenbugs (humorously named after the Heisenberg uncertainty principle).\nSometimes, a bug is not an isolated flaw, but represents an error of thinking or planning on the part of the programmers. Often, such a logic error requires a section of the program to be overhauled or rewritten. a process known as code refactoring.\nA code review, stepping through the code and imagining or transcribing the execution process, may often find errors without ever reproducing the bug as such.\nA program known as a debugger can help a programmer find faulty code by examining the inner workings of a program, such as executing code line-by-line and viewing variable values.\nAs an alternative to using a debugger, code may be instrumented with logic to output debug information to trace program execution and view values. Output is typically to console, window, log file or a hardware output, potentially driving an indicator LED.\nSince the 1990s, particularly following the Ariane 5 Flight 501 disaster, interest in automated aids to debugging rose, such as static code analysis by abstract interpretation.\nIn an embedded system, the software is often modified to work around a hardware bug since software modifications can be cheaper and less disruptive than modifying the hardware.\nManagement\nproject data). A new bug is initially unconfirmed. Once reproduced, it is changed to confirmed. Once the issue is resolved, it is changed to fixed.]]\nBugs are managed via activities like documenting, categorizing, assigning, reproducing, correcting and releasing the corrected code.\nTools are often used to track bugs and other issues with software. Typically, different tools are used by the software development team to track their workload than by customer service to track user feedback.\nA tracked item is often called bug, defect, ticket, issue, feature, or for agile software development, story or epic. Items are often categorized by aspects such as severity, priority and version number(s) affected.\nIn a process sometimes called triage, choices are made for each bug about whether and when to fix it based on information such as the bug's severity and priority and external factors such as development schedules. Triage generally does not include an investigation into the cause. Triage may occur regularly and minimally consists of reviewing new bugs since the previous triage, possibly extending to all open bugs. Attendees may include the project manager, the development manager, the test manager, the build manager, and technical experts.\nSeverity\nSeverity is a measure of impact the bug has. This impact may be data loss, financial, loss of goodwill and wasted effort. Severity levels are not standardized, but differ by context such as industry and tracking tool. For example, a crash in a video game has a different impact than a crash in a bank server. Severity levels might be crash or hang, no workaround (user cannot accomplish a task), has workaround (user can still accomplish the task), visual defect (a misspelling for example), or documentation error. Another example set of severities: critical, high, low, blocker, trivial. The severity of a bug may be a separate category to its priority for fixing, or the two may be quantified and managed separately.\nA bug severe enough to delay the release of the product is called a show stopper.\nPriority\nPriority describes the importance of resolving the bug in relation to other bugs. Priorities might be numerical, such as 1 through 5, or named, such as critical, high, low, and deferred. The values might be similar or identical to severity ratings, even though priority is a different aspect.\nPriority may be a combination of the bug's severity with the level of effort to fix. A bug with low severity but easy to fix may get a higher priority than a bug with moderate severity that requires significantly more effort to fix.\nPatch\nBugs of sufficiently high priority may warrant a special release which is sometimes called a patch.\nMaintenance release\nA software release that emphasizes bug fixes may be called a maintenance release  to differentiate it from a release that emphasizes new features or other changes.\nKnown issue\nIt is common practice to release software with known, low-priority bugs or other issues.  Possible reasons include but are not limited to:\n* A deadline must be met and resources are insufficient to fix all bugs by the deadline\n* The bug is already fixed in an upcoming release, and it is not of high priority\n* The changes required to fix the bug are too costly or affect too many other components, requiring a major testing activity\n* It may be suspected, or known, that some users are relying on the existing buggy behavior; a proposed fix may introduce a breaking change\n* The problem is in an area that will be obsolete with an upcoming release; fixing it is unnecessary\n* \"It's not a bug, it's a feature\" A misunderstanding exists between expected and actual behavior or undocumented feature\nImplications\nThe amount and type of damage a software bug may cause affects decision-making, processes and policy regarding software quality. In applications such as human spaceflight, aviation, nuclear power, health care, public transport or automotive safety, since software flaws have the potential to cause human injury or even death, such software will have far more scrutiny and quality control than, for example, an online shopping website. In applications such as banking, where software flaws have the potential to cause serious financial damage to a bank or its customers, quality control is also more important than, say, a photo editing application.\nOther than the damage caused by bugs, some of their cost is due to the effort invested in fixing them. In 1978, Lientz et al. showed that the median of projects invest 17 percent of the development effort in bug fixing. In 2020, research on GitHub repositories showed the median is 20%.\nCost\nIn 1994, NASA's Goddard Space Flight Center managed to reduce their average number of errors from 4.5 per 1,000 lines of code (SLOC) down to 1 per 1000 SLOC.\nAnother study in 1990 reported that exceptionally good software development processes can achieve deployment failure rates as low as 0.1 per 1000 SLOC. This figure is iterated in literature such as Code Complete by Steve McConnell, and the NASA study on Flight Software Complexity. Some projects even attained zero defects: the firmware in the IBM Wheelwriter typewriter which consists of 63,000 SLOC, and the Space Shuttle software with 500,000 SLOC.\nBenchmark\nTo facilitate reproducible research on testing and debugging, researchers use curated benchmarks of bugs:\n* the Siemens benchmark\n* ManyBugs is a benchmark of 185 C bugs in nine open-source programs.\n* Defects4J is a benchmark of 341 Java bugs from 5 open-source projects. It contains the corresponding patches, which cover a variety of patch type.\nTypes\nSome notable types of bugs:\nDesign error\nA bug can be caused by insufficient or incorrect design based on the specification. For example, given that the specification is to alphabetize a list of words, a design bug might occur if the design does not account for symbols; resulting in incorrect alphabetization of words with symbols.\nArithmetic\nNumerical operations can result in unexpected output, slow processing, or crashing.\nSuch a bug can be from a lack of awareness of the qualities of the data storage such as a loss of precision due to rounding, numerically unstable algorithms, arithmetic overflow and underflow, or from lack of awareness of how calculations are handled by different software coding languages such as division by zero which in some languages may throw an exception, and in others may return a special value such as NaN or infinity.\nControl flow\nA control flow bug, or logic error, is characterized by code that does not fail with an error, but does not have the expected behavior, such as infinite looping, infinite recursion, incorrect comparison in a conditional such as using the wrong comparison operator, and the off-by-one error.\nInterfacing\n* Incorrect API usage.\n* Incorrect protocol implementation.\n* Incorrect hardware handling.\n* Incorrect assumptions of a particular platform.\n* Incompatible systems. A new API or communications protocol may seem to work when two systems use different versions, but errors may occur when a function or feature implemented in one version is changed or missing in another. In production systems which must run continually, shutting down the entire system for a major update may not be possible, such as in the telecommunication industry or the internet. In this case, smaller segments of a large system are upgraded individually, to minimize disruption to a large network. However, some sections could be overlooked and not upgraded, and cause compatibility errors which may be difficult to find and repair.\n* Incorrect code annotations.\nConcurrency\n* Deadlock  a task cannot continue until a second finishes, but at the same time, the second cannot continue until the first finishes.\n* Race condition  multiple simultaneous tasks compete for resources.\n* Errors in critical sections, mutual exclusions and other features of concurrent processing. Time-of-check to time-of-use (TOCTOU) is a form of unprotected critical section.\nResourcing\n* Null pointer dereference.\n* Using an uninitialized variable.\n* Using an otherwise valid instruction on the wrong data type (see packed decimal/binary-coded decimal).\n* Access violations.\n* Resource leaks, where a finite system resource (such as memory or file handles) become exhausted by repeated allocation without release.\n* Buffer overflow, in which a program tries to store data past the end of allocated storage. This may or may not lead to an access violation or storage violation. These are frequently security bugs.\n* Excessive recursion which—though logically valid—causes stack overflow.\n* Use-after-free error, where a pointer is used after the system has freed the memory it references.\n* Double free error.\nSyntax\n* Use of the wrong token, such as performing assignment instead of equality test. For example, in some languages  will set the value of x to 5 while  will check whether x is currently 5 or some other number. Interpreted languages allow such code to fail. Compiled languages can catch such errors before testing begins.\nTeamwork\n* Unpropagated updates; e.g. programmer changes \"myAdd\" but forgets to change \"mySubtract\", which uses the same algorithm. These errors are mitigated by the Don't Repeat Yourself philosophy.\n* Comments out of date or incorrect: many programmers assume the comments accurately describe the code.\n* Differences between documentation and product.\nIn politics\n\"Bugs in the System\" report\nThe Open Technology Institute, run by the group, New America, released a report \"Bugs in the System\" in August 2016 stating that U.S. policymakers should make reforms to help researchers identify and address software bugs. The report \"highlights the need for reform in the field of software vulnerability discovery and disclosure.\" One of the report's authors said that Congress has not done enough to address cyber software vulnerability, even though Congress has passed a number of bills to combat the larger issue of cyber security.\nGovernment researchers, companies, and cyber security experts are the people who typically discover software flaws. The report calls for reforming computer crime and copyright laws.\nIn popular culture\n* In video gaming, the term \"glitch\" is sometimes used to refer to a software bug. An example is the glitch and unofficial Pokémon species MissingNo.\n* In both the 1968 novel 2001: A Space Odyssey and the corresponding film of the same name, the spaceship's onboard computer, HAL 9000, attempts to kill all its crew members. In the follow-up 1982 novel, 2010: Odyssey Two, and the accompanying 1984 film, 2010: The Year We Make Contact, it is revealed that this action was caused by the computer having been programmed with two conflicting objectives: to fully disclose all its information, and to keep the true purpose of the flight secret from the crew; this conflict caused HAL to become paranoid and eventually homicidal.\n* In the English version of the Nena 1983 song 99 Luftballons (99 Red Balloons) as a result of \"bugs in the software\", a release of a group of 99 red balloons are mistaken for an enemy nuclear missile launch, requiring an equivalent launch response and resulting in catastrophe.\n* In the 1999 American comedy Office Space, three employees attempt (unsuccessfully) to exploit their company's preoccupation with the Y2K computer bug using a computer virus that sends rounded-off fractions of a penny to their bank account—a long-known technique described as salami slicing.\n* The 2004 novel The Bug, by Ellen Ullman, is about a programmer's attempt to find an elusive bug in a database application.\n* The 2008 Canadian film Control Alt Delete is about a computer programmer at the end of 1999 struggling to fix bugs at his company related to the year 2000 problem.\nSee also\n*\n*\n*\n*\n*\n* , which classifies a bug as either a defect or a nonconformity\n* List of software bugs\n*\n*\n*\n*\n*\n*\n*\n*\nReferences\nExternal links\n* \"[https://nvd.nist.gov/cwe.cfm Common Weakness Enumeration]\" – an expert webpage focus on bugs, at NIST.gov\n* [https://opensourceforu.com/2010/10/joy-of-programming-types-of-bugs BUG type of Jim Gray] – another Bug type\n*\n* \"[https://web.archive.org/web/19970430003658/http://www.waterholes.com/~dennette/1996/hopper/bug.htm The First Computer Bug!]\" – an email from 1981 about Adm. Hopper's bug\n* \"[http://dl.acm.org/citation.cfm?doid=2931037.2931074 Toward Understanding Compiler Bugs in GCC and LLVM]\". A 2016 study of bugs in compilers"
    }
  ]
}