{
  "content": [
    {
      "type": "text",
      "text": "# Discovery Net\n\nDiscovery Net is one of the earliest examples of a scientific workflow system allowing users to coordinate the execution of remote services based on Web service and Grid Services (OGSA and Open Grid Services Architecture) standards.\nThe system was designed and implemented at Imperial College London as part of the Discovery Net pilot project funded by the UK e-Science Programme (). Many of the concepts pioneered by Discovery Net have been later incorporated into a variety of other scientific workflow systems.\nHistory\nThe Discovery Net system was developed as part of the Discovery Net pilot project (2001–2005), a £2m research project funded by the EPSRC under the UK e-Science Programme ().\nThe research on the project was conducted at Imperial College London as a collaboration between the Departments of Computing, Physics, Biochemistry and Earth Science & Engineering. Being a single institution project, the project was unique compared to the other 10 pilot projects funded by the EPSRC which were all multi-institutional.\nThe aims of the Discovery Net project were to investigate and address the key issues in developing of an e-Science platform for scientific discovery from the data generated by a wide variety of high throughput devices.\nIt originally considered requirements from applications in life science, geo-hazard monitoring, environmental modelling and renewable energy. The project successfully delivered on all its objectives including the development of the Discovery Net workflow platform and workflow system. Over the years the system evolved to address applications in many other areas including bioinformatics, cheminformatics, health informatics, text mining and financial and business applications.\nScientific workflow system\nThe Discovery Net system developed within the project is one of the earliest examples of scientific workflow systems. It is an e-Science platform based on a workflow model supporting the integration of distributed data sources and analytical tools thus enabling the end-users to derive new knowledge from devices, sensors, databases, analysis components and computational resources that reside across the Internet or grid.\nArchitecture and workflow server\nThe system is based on a multi-tier architecture, with a workflow server providing a number of supporting functions needed for workflow authoring and execution, such as integration and access to remote computational and data resources, collaboration tools, visualisers and publishing mechanisms. The architecture itself evolved over the years focusing on the internals of the workflow server (Ghanem et al. 2009) to support extensibility over multiple application domains as well as different execution environments.\nVisual workflow authoring\nDiscovery Net workflows are represented and stored using DPML (Discovery Process Markup Language), an XML-based representation language for workflow graphs supporting both a data flow model of computation (for analytical workflows) and a control flow model (for orchestrating multiple disjoint workflows).\nAs with most modern workflow systems, the system supported a drag-and-drop visual interface enabling users to easily construct their applications by connecting nodes together.\nWithin DPML, each node in a workflow graph represents an executable component (e.g.\na computational tool or a wrapper that can extract data from a particular data source). Each\ncomponent has a number of parameters that can be set by the user and also a number of input\nand output ports for receiving and transmitting data.\nEach directed edge in the graph represents a connection from an output port, namely the tail of the edge, to an\ninput port, namely the head of the edge. A port is connected if there is one or more connections\nfrom/to that port.\nIn addition, each node in the graph provides metadata describing the input and output ports\nof the component, including the type of data that can be passed to the component and parameters of the service that a user might want to change. Such information is used for the verification of\nworkflows and to ensure meaningful chaining of components. A connection between an input\nand an output port is valid only if the types are compatible, which is strictly enforced.\nSeparation between data and control flows\nA key contribution of the system is its clean separation between the data flow and control flow models of computations within a scientific workflows. This is achieved through the concept of embedding enabling complete data flow fragments to be embedded with a block-structured fragments of control flow constructs. This results both in simpler workflow graphs compared to other scientific workflow systems, e.g. Taverna workbench and the Kepler scientific workflow system and also provides the opportunity to apply formal methods for the analysis of their properties.\nData management and multiple data models\nA key feature of the design of the system has been its support for data management within the workflow engine itself. This is an important feature since scientific experiments typically generate and use large amounts of heterogeneous and distributed data sets. The system was thus designed to support persistence and caching of intermediate data products and also to support scalable workflow execution over potentially large data sets using remote compute resources.\nA second important aspect of the Discovery Net system is based on a typed workflow language and its extensibility to  support arbitrary data types defined by the user. Data typing simplifies workflow scientific workflow development, enhances optimization of workflows and enhances error checking for workflow validation . The system included a number of default data types for the purpose of supporting data mining in a variety if scientific applications. These included a relational model for tabular data, a bioinformatics data model (FASTA) for representing gene sequences and a stand-off markup model for text mining based on the Tipster architecture.\nEach model has an associated set of data import and export components, as well as specific\nvisualizers, which integrate with the generic import, export and visualization tools already\npresent in the system. As an example, chemical compounds represented in the widely used\nSMILES (Simplified molecular input line entry specification) format can be imported inside data tables, where they can be rendered adequately using either a three-dimensional representation or its structural formula. The relational model also serves as the base data model for data integration, and is used for the majority of generic\ndata cleaning and transformation tasks.\nApplications\nThe system won the \"Most Innovative Data Intensive Application Award\" at the ACM SC02 (Supercomputing 2002) conference and exhibition, based on a demonstration of a fully interactive distributed genome annotation pipeline for  a Malaria genome case study. Many of the features of the system (architecture features, visual front-end, simplified access to remote Web and Grid Services and inclusion of a workflow store) were considered novel at the time, and have since found their way into other academic and commercial systems, and especially features found in bioinformatics workflow management systems.\nBeyond the original Discovery Net project, the system has been used in a large number of scientific applications, for example the BAIR: Biological Atlas of Insulin Resistance project funded by the Wellcome Trust and also in a large number of projects funded by both the EPSRC and BBSRC in the UK. The Discovery Net technology and system have also evolved into commercial products though the Imperial College spinout company InforSense Ltd, which further extended and applied the system in a wide variety of commercial applications as well as through further research projects, including SIMDAT, TOPCOMBI, BRIDGE and ARGUGRID.\nSee also\n* Apache Taverna\nReferences\n#\n#\n# Jameel Syed, Moustafa Ghanem, Yike Guo. Discovery processes: representation and re-use. Proceedings of the First UK e-Science All-hands Conference, Sheffield, UK. September, 2002.\n# Nikolaos Giannadakis, Moustafa Ghanem, Yike Guo. Information integration for e-Science. Proceedings of the First UK e-Science All-hands Conference, Sheffield, UK. September, 2002.\n#\n#\n#\n#\n# Moustafa Ghanem, Yike Guo, Anthony Rowe. Integrated data and text mining in support of bioinformatics. Proceedings of the 3rd UK e-Science All-hands Conference AHM 2004, Nottingham, UK. September, 2004.\n# Vasa Curcin, Moustafa Ghanem, Yike Guo. SARS analysis on the Grid. Proceedings of the 3rd UK e-Science All-hands Conference AHM 2004, Nottingham, UK. September, 2004\n# Peter Au, Vasa Curcin, Moustafa Ghanem, Nikolaos Giannadakis, Yike Guo, Mohammad Jafri, Michelle Osmond, Anthony Rowe, Jameel Syed, Patrick Wendel, Yong Zhang. Why Grid-based data mining matters? Fighting natural disasters on the Grid: From SARS to land slides. Proceedings of the 3rd UK e-Science All-hands Conference AHM 2004. September, 2004\n#\n# Moustafa Ghanem, Vasa Curcin, Yike Guo, Neil Davis, Rob Gaizauskas, Yikun Guo, Henk Harkema, Ian Roberts, Jonathan Ratcliffe. GoTag: A case study in using a shared UK e-Science infrastructure. 4th UK e-Science All Hands Meeting 2005. September, 2005\n# Neil Davis, Henk Harkema, Rob Gaizauskas, Yikun Guo, Moustafa Ghanem, Tom Barnwell, Yike Guo, Jonathan Ratcliffe. Three Approaches to GO-Tagging Biomedical Abstracts. CEUR Workshop Proceedings. April, 2006.\n#\n# Moustafa Ghanem, Nabeel Azam, Mike Boniface. Workflow Interoperability in Grid-based Systems. Cracow Grid Workshop 2006. October, 2006\n# Vasa Curcin, Moustafa Ghanem, Yike Guo, Kostas Stathis, Francesca Toni. Building next generation Service-Oriented Architectures using argumentation agents. 3rd International Conference on Grid Services Engineering and Management (GSEM 2006). Springer Verlag. September, 2006.\n# Patrick Wendel, Arnold Fung, Moustafa Ghanem, Yike Guo. Designing a Java-based Grid scheduler using commodity services. Proceedings of the UK e-Science All Hands Meeting 2006. Nottingham, UK, September 2006.\n# Qiang Lu, Xinzhong Li, Moustafa Ghanem, Yike Guo, Haiyan Pan. Integrating R into Discovery Net. Proceedings of the UK e-Science All Hands Meeting 2006. September, 2006.\n#\n#\n#\n# Vasa Curcin, Moustafa Ghanem, Yike Guo, John Darlington. Mining adverse drug reactions with e-science workflows. Proceedings of the 4th Cairo International Biomedical Engineering Conference, 2008. CIBEC 2008. December, 2008.\n#\n#\n#\n# Antje Wolf, Martin Hofmann-Apitius, Moustafa Ghanem, Nabeel Azam, Dimitrios Kalaitzopoulos, Kunqian Yu, Vinod Kasam. DockFlow - A prototypic PharmaGrid for virtual screening integrating four different docking tools. In Proceedings of HealthGrid 2009 Volume 147, pp.&nbsp;3–12 Studies in Health Technology and Informatics May, 2009\nExternal links\n* List of e-Science Pilot Projects funded by the EPSRC \"https://web.archive.org/web/20100723012926/http://www.epsrc.ac.uk/about/progs/rii/escience/Pages/fundedprojects.aspx\"\n* SIMDAT \"http://www.simdat.org/\".\n* The BRIDGE Project \"http://www.bridge-grid.eu/ \"\n* The ARGUGRID Project \"http://www.argugrid.eu/ \"\n* BAIR project: \"https://web.archive.org/web/20100430111119/http://www.bair.org.uk/\"\n* InforSense Ltd. \"https://web.archive.org/web/20100328015758/http://www.inforsense.com/\""
    }
  ]
}