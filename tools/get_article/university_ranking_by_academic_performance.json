{
  "content": [
    {
      "type": "text",
      "text": "# University Ranking by Academic Performance\n\nThe University Ranking by Academic Performance (URAP) is a university ranking developed by the Informatics Institute of Middle East Technical University. Since 2010, it has been publishing annual national and global college and university rankings for top 2000 institutions.  The scientometrics measurement of URAP  is based on data obtained from the Institute for Scientific Information via Web of Science and inCites. For global rankings, URAP employs indicators of research performance including the number of articles, citation, total documents, article impact total, citation impact total, and international collaboration. In addition to global rankings, URAP publishes regional rankings for universities in Turkey using additional indicators such as the number of students and faculty members obtained from Center of Measuring, Selection and Placement ÖSYM.\nMethodology\nURAP gathers data from international bibliometric databases such as Web of Science and InCites provided by the Institute for Scientific Information. URAP uses data of 2,500 Higher Education Institutions (HEI) with highest number of articles published. The overall score of each HEI is based on its performance over several indicators. Of 2500 selected HEIs, the top 2000 are included in the rankings published by URAP. Field based rankings are performed on 23 fields based on Australia ERA.\nIndicators\nURAP uses 6 main indicator to measure the academic performance. These indicators are number of articles, citation, total documents, article impact total, citation impact total, and international collaboration. The raw bibliometric data underlying URAP's 6 main indicators have highly skewed distribution. To address this issue, the median of the indicators have been used. The Delphi system was conducted with a group of experts to assign weighting scores to the indicators. Total score of 600 is distributed to indicators. URAP uses additional indicators for ranking universities in Turkey including  the number of students and faculty members.\nThe following table shows the indicators used for global rankings in URAP as of 2014.\n{| class=\"wikitable\"\n|-\n! Indicator\n! Objective\n! Weight (out of 600)\n! Source\n|-\n| Number of Articles\n| Scientific Productivity\n| %21\n| InCites\n|-\n| Citation\n| Research Impact\n| %21\n| InCites\n|-\n| Total Documents\n| Scientific Productivity\n| %10\n| InCites\n|-\n| Article Impact Total\n| Research Quality\n| %18\n| InCites\n|-\n| Citation Impact Total\n| Research Quality\n| %15\n| InCites\n|-\n| International Collaboration\n| International Acceptance\n| %15\n| InCites\n|}\nNumber of articles\nNumber of articles is used as a measure of current scientific productivity which includes articles indexed by Web of Science. This indicator covers articles, reviews and notes. The weight of this indicator in the overall ranking is %21.\nCitation\nCitation, as an indicator in URAP ranking, is a measure of research impact. It is scored according to the total number of citations received. The weight of this indicator in the overall ranking is %21.\nTotal documents\nTotal documents is the measure of sustainability and continuity of scientific productivity. The total document count covers all scholarly literature provided by the Web of Science database, including conference papers, reviews, letters, discussions, scripts, and journal articles. The weight of this indicator in the overall ranking is %10.\nArticle Impact Total (AIT)\nArticle Impact Total (AIT) is a measure of scientific productivity adjusted by the ratio of institution's Citation Per Publication (CPP) to the world CPP in 23 subject areas. The ratio of the institution's CPP and the world CPP indicates whether the institution is performing above or below the world average in that field. This ratio is multiplied by the number of publications in that field and then summed across the 23 fields, as shown in the following formula:\nAIT = \\sum_{i=1}^{23} \\Bigg[ \\Bigg( \\frac{CPP_i}{CPP\\_{World_i}} \\Bigg) * Articles_i \\Bigg]\nThe weight of this indicator in the overall ranking is %18.\nCitation Impact Total (CIT)\nCitation Impact Total (CIT) is a measure of research impact corrected by the institution's normalized CPP with respect to the world CPP in 23 subject areas. The ratio of the institution's CPP and the world CPP indicates whether the institution is performing above or below the world average in that field. This ratio is multiplied by the number of citations in that field and then summed across the 23 fields, as shown in the following formula:\nCIT = \\sum_{i=1}^{23} \\Bigg[ \\Bigg( \\frac{CPP_i}{CPP\\_{World_i}} \\Bigg) * Citations_i \\Bigg]\nThe weight of this indicator in the overall ranking is %15.\nInternational collaboration\nInternational Collaboration is a measure of global acceptance of the institution.  International collaboration data, which is based on the total number of published studies conducted  in collaboration with foreign universities, is obtained from InCites.  The weight of this indicator in the overall ranking is %15.\nCurrent rankings\nGlobal ranking\n{| class=\"sortable wikitable\"\n|+ University Ranking by Academic Performance—Top 50\n|-\n!Institution\n!2021-22\n!2020-21\n!2019–20\n!2018–19\n!2017–18\n!2016–17\n!2015–16\n!2014–15\n|-\n| Harvard University\n|1\n|1||1||1||1||1||1||1\n|-\n| University of Toronto\n|2\n|2||2||2||2||2||2||2\n|-\n| University College London\n|3\n|4||3||5||6||5||6||6\n|-\n| Stanford University\n|4\n|3||4||4||5||4||8||7\n|-\n| University of Oxford\n|5\n|5||5||3||3||3||3||3\n|-\n| Johns Hopkins University\n|6\n|6||6||6||8||6||4||4\n|-\n| University of Cambridge\n|7\n|7||7||7||9||8||5||5\n|-\n| University of Michigan\n|8\n|8||8||9||11||10||10||10\n|-\n| University of Washington\n|9\n|10||9||10||12||11||11||11\n|-\n| Tsinghua University\n|10\n|12||12||18||25||38||48||58\n|-\n| Shanghai Jiao Tong University\n|11\n|18||19||24||32||39||50||59\n|-\n| Imperial College London\n|12\n|13||13||11||16||15||15||15\n|-\n| University of Paris-Saclay\n|13\n|9||94||91||80||87||70||69\n|-\n| University of Pennsylvania\n|14\n|15||14||15||14||13||13||13\n|-\n| Zhejiang University\n|15\n|20||20||31||33||34||42||46\n|-\n| University of California, Los Angeles\n|16\n|16||15||13||13||12||12||12\n|-\n| Massachusetts Institute of Technology\n|17\n|11||11||8||7||7||7||9\n|-\n| Sorbonne University\n|18\n|14||10||17||4||26||26||25\n|-\n| Columbia University\n|19\n|17||16||14||15||14||14||14\n|-\n| University of Sydney\n|20\n|24||24||23||26||27||29||30\n|-\n| University of Copenhagen\n|21\n|19||18||16||17||16||16||22\n|-\n| Peking University\n|22\n|21||21||22||29||33||44||48\n|-\n| University of Melbourne\n|23\n|25||23||26||30||31||30||29\n|-\n| University of Paris\n|24\n|23||97||95||87||85||78||76\n|-\n| University of California, San Diego\n|25\n|26||22||19||18||17||17||16\n|-\n| University of California, San Francisco\n|26\n|30||31||28||24||22||19||18\n|-\n| National University of Singapore\n|27\n|32||28||30||27||29||32||34\n|-\n| Cornell University\n|28\n|28||29||25||23||25||25||24\n|-\n| University of British Columbia\n|29\n|29||27||27||21||21||22||20\n|-\n| Yale University\n|30\n|27||26||21||20||19||20||21\n|-\n| University of São Paulo\n|31\n|33||33||38||36||40||35||31\n|-\n| Monash University\n|32\n|37||39||46||53||57||62||64\n|-\n| University of California, Berkeley\n|33\n|22||17||12||10||9||9||8\n|-\n| University of Queensland\n|34\n|35||35||39||40||41||43||51\n|-\n| Sun Yat-sen University\n|35\n|48||60||83||93||99||113||116\n|-\n| Duke University\n|36\n|34||34||33||28||24||24||23\n|-\n| University of Tokyo\n|37\n|31||25||20||19||18||18||17\n|-\n| KU Leuven\n|38\n|38||37||42||41||23||23||38\n|-\n| University of New South Wales\n|39\n|42||44||52||60||71||74||78\n|-\n| University of Amsterdam\n|40\n|40||48||51||63||61||61||61\n|-\n| Ohio State University\n|41\n|39||38||36||38||37||33||32\n|-\n| Huazhong University of Science and Technology\n|42\n|49||56||81||94||111||135||155\n|-\n| University of Pittsburgh\n|43\n|43||40||35||35||32||31||28\n|-\n| Karolinska Institute\n|44\n|50||51||48||51||53||60||57\n|-\n| Fudan University\n|45\n|54\n|58\n|62\n|68\n|74\n|90\n|94\n|-\n| University of Chicago\n|46\n|36||30||29||22||20||21||19\n|-\n| Northwestern University\n|47\n|46||45||43||46||38||37||37\n|-\n| Utrecht University\n|48\n|45||42||40||45||44||37||35\n|-\n| Seoul National University\n|49\n|51\n|47\n|49\n|44\n|50\n|36\n|42\n|-\n| University of Minnesota\n|50\n|44||32||32||31||28||27||27\n|}\nRankings by field\n*https://urapcenter.org/Rankings/2020-2021/fields\nCommentary and reception\nURAP covers considerably more institutions than other major ranking systems. In a section about URAP in  “Where Are the Global Rankings Leading Us? An Analysis of Recent Methodological Changes and New Developments” published in  the European Journal of Education it is mentioned that ”While it is less well-known than SRG, ARWU, THE, and QS, it is interesting because it published a list of 2000 universities, while the above rankings cover a maximum of 700 universities.”  This is also mentioned in  the “EUA report on Ranking for 2013 “ published by the European University Association. It indicates that URAP, along with SCImago ranking system, “fill an important gap in the rankings market in that their indicators measure the performance of substantially more universities, up to 2000 in the case of URAP and over 3000 in SCImago, compared to only 400 in THE, 500 in SRC ARWU, NTU ranking and CWTS Leiden, and around 700 in QS.”\nURAP is mentioned as one of the four ranking systems that solely measure the academic performance. The other three are Performance Ranking of Scientific Papers for World Universities, CWTS Leiden Ranking, and SCImago Institutions Rankings. URAP excludes teaching indicators, such as student quality and teaching performance, from global rankings and only covers research-oriented indicators. In the  “International Benchmarking in UK higher Education” report  of the Higher Education Statistics Agency, URAP is listed among the benchmarking resources  for measuring academic. In the same report, URAP is categorized in the  “whole university rankings” along with Times Higher Education World University Rankings (THE), QS World University Rankings, Academic Ranking of World Universities (ARWU),  CHE Excellence Rankings, RatER Global University Ranking of World Universities, Webometrics Ranking of World Universities,  2010 World University Ranking, SIR World Report, CWTS Leiden Ranking, U-Multirank,  European Research Ranking, Performance Ranking of Scientific Papers for World Universities,  Human Resources & Labor Review (HRLR), and Professional Classification of Higher Education Institutions.\nURAP in Research, Books, and Reports\nURAP is mentioned and used in  several studies based on, or referring to,  global rankings. In the “World University Ranking Systems: An Alternative Approach Using Partial Least Squares Path Modeling” article, published in the Journal of Higher Education Policy and Management, Urap is incorporated in the suggested model as one of the nine major worldwide university ranking systems along with ARWU, QS, Times, Webometrics, Taiwan. Leiden, SIR, and CWUR. In the same article, URAP is categorized among the ranking systems that are based solely on publication performance. The other ranking systems in the same category are Performance Ranking of Scientific Papers for World Universities, CWTS Leiden Ranking, and SCImago Institutions Rankings.\nThe following is a list of some of the books, peer-reviewed articles, and conference proceedings  that have covered URAP or have incorporated it in their models or comparisons.\n* Where Are the Global Rankings Leading Us? An Analysis of Recent Methodological Changes and New Developments, European Journal of Education\n* World university ranking systems: an alternative approach using partial least squares path modelling, Journal of Higher Education Policy and Management\n*  Sustainable Development and Quality Assurance in Higher Education: Transformation of Learning and Society\n*  Determinants of University Choice: A Study on Economics Departments in Turkey,  Journal of Higher Education.\n* Collecting University Rankings for Comparison Using Web Extraction and Entity Linking Techniques, Information and Communication Technologies in Education, Research, and Industrial Applications.\n* URAP-TR: a national ranking for Turkish universities based on academic performance, Scientometrics.\n* Global University Rankings and Their Impact, EUA Report in Rankings 2013, European University Association.\n* Contributions of Turkish academicians supervising PhD dissertations and their universities to economics: an evaluation of the 1990–2011 period, Scientometrics.\n* A Type-2 Fuzzy MCDM Method for Ranking Private Universities in İstanbul, Proceedings of the World Congress on Engineering, 2014.\n* Adoption of Web 2.0 in academic libraries of top African universities, The Electronic Library.\n* Examining Job Description to Develop Job Performance Indicators for Higher Education Institution Based on MBNQA Education Criteria, Journal of Education & Vocational Research.\n* Software Quality in Academic Curriculum: A Case Study in Turkey, 12th International Conference on Computational Science and Its Applications (ICCSA).\n* University Ranking Lists:A directory., 2013 Report, Division of Analysis and Evaluation, University of Gothenburg.\n* The \"ASERF E News Bulletin on Education\" published by Apeejay Stya Education Research Foundation compares the ranking results of THE with other ranking systems, including URAP and QS, for the top 10 universities in some countries.\nURAP in Press\n* Thomson Reuters partners with Times on university rankings\n* Press release of University of Tübingen, released on 03.04.2013, covered the ranking of the university based in URAP.\n* Turkey and Arab states announce new HE collaboration, University World News\n* Power and responsibility – The growing influence of global rankings, University World News\n*  10 Turkish universities rank among top 500, Hurriyet Daily News\n* The report of inclusion of five Romanian universities in international rankings based on QS, URAP, U-maltirank, and other ranking systems.\nURAP in university reports and websites\nAnnual URAP ranking results are used by a number of listed universities to indicate their academic performance. The following is a short list of links to university pages  that has mentioned URAP results either independently or in conjunction with other ranking results.\n* The comparison of the latest results and previous results of URAP, along with other ranking systems, Provided by the Polytechnic University of Catalonia.\n* The profile of the rankings of Newcastle University from 2010 to 2014 and the current ranking results according to URAP and other ranking systems.\n* URAP ranking results for top 16 universities of Thailand for 2013-2014 for Mahidol University . The report also includes the results for 2012-2013 and the results of all major ranking systems\n* The report of the global standing of Seoul National University including the URAP results for 2014-2015\n* On page 32 of the \"Annual Report for the year ended March 31, 2013\" of the University of Calgary has used URAP results for 2012 to compare the university with its top 5 peers.\n* The report of the ranking of  University of Pittsburgh based on URAP results since 2010.\n* News report of the ranking of University College Dublin based in URAP and QS.\n* Global ranking in 2011 of the Griffith University based in ARWU, QS, THE, Leiden, and URAP.\n* On page 6 of the \"Facts and Figures\" report published by the University of Erlangen-Nuremberg  URAP result is used to justify that their ranking in other systems is not a \"one-off success story\".\nCriticism\nThe indicators used in URAP are absolute values and size-dependent making it biased towards larger institutions.\nAccording to the  “EUA report on Ranking for 2013“ published by the European University Association,  URAP disregards books, excludes studies in arts and humanities areas, and under-represents social sciences. Furthermore,  URAP does not employ any compensation for different publication cultures due to the lack of field-normalization of the results of bibliometric indicators. The report further states that “The results of the indicator on citation numbers in particular, as well as those on publication counts, are thus skewed towards the natural sciences and especially medicine.” It also states that excluding teaching indicators by URAP makes its  focus solely on research-oriented institutions.\nThe “University Ranking Lists: A directory” report  published by the Division for Analysis and Evaluation of the University of Gothenburg points out  a problem that might arise from including more than 500 institutions in the ranking system. It states that “It [URAP] lists 2000 universities, and the purpose is to provide a ranking that covers not only institutions in the Western elite group. This purpose contrasts starkly with other ranking producers’ decisions not to publish more than the 400-500 top positions of their lists, since they do not consider their methods reliable below that level. [URAP] do not comment this problem.”\nSee also\n*College and university rankings\nNotes\nNotes and references\nExternal links\n*[https://urapcenter.org/ Official Website]"
    }
  ]
}