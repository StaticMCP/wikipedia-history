{
  "content": [
    {
      "type": "text",
      "text": "# Draft:Software engineering analytics\n\nSoftware engineering analytics refers to the practice of collecting, measuring, and analysing data related to the process of software development, with the goal of improving engineering efficiency, quality, and predictability. It encompasses a range of metrics, tools, and methodologies used by engineering leaders and development teams to monitor productivity, identify bottlenecks, and inform decision-making.\nSoftware engineering analytics draws from fields including software metrics, project management, DevOps, and data analytics. Modern implementations often integrate directly with source control systems, issue trackers, and continuous integration/continuous deployment (CI/CD) pipelines to provide real-time insights into engineering workflows.\nHistory\nThe concept evolved from early software metrics research in the 1970s and 1980s, which focused on measures such as lines of code and function points. In the 1990s, methodologies like Capability Maturity Model Integration (CMMI) incorporated measurement into process improvement frameworks.\nIn the 2010s, the rise of Agile and DevOps practices shifted focus toward continuous measurement and improvement. Google’s \"Four Keys\" research and the publication of the DevOps Research and Assessment (DORA) metrics provided standardised indicators—deployment frequency, lead time for changes, mean time to recovery, and change failure rate—that became widely adopted benchmarks.\nBy the early 2020s, venture-backed startups began offering commercial platforms that automate data collection and analysis for engineering teams. These include workflow-focused platforms such as LinearB and AI-driven solutions such as WorkWeave.\nMetrics\nCommon metrics in software engineering analytics include:\nProductivity and velocity: Cycle time, throughput, and sprint burndown rates.\nQuality: Defect rates, escaped bugs, and test coverage.\nDelivery performance: DORA metrics.\nCollaboration: Code review turnaround, pull request size, and reviewer participation.\nAI-assisted development impact: Output share from AI-generated code, code review efficiency improvements.\nTools\nSoftware engineering analytics tools integrate with platforms such as GitHub, GitLab, Bitbucket, Jira, and CI/CD systems. They often include dashboards, workflow automation, and alerting systems to help teams respond to issues in real time.\nProminent examples include:\nLinearB: A workflow analytics and automation platform.\nWorkWeave: An AI-driven developer productivity platform that benchmarks output and quality using machine learning.\nOpen source tools such as SonarQube and custom in-house analytics pipelines.\nChallenges\nThe field faces several challenges:\nMetric misuse: Overemphasis on output-based measures can lead to gaming behaviours.\nData quality: Incomplete or inconsistent source data can distort insights.\nCultural adoption: Developers may view analytics as surveillance rather than as a means of improvement.\nContextual interpretation: Metrics need to be analysed alongside qualitative context to avoid misleading conclusions.\nRecent developments\nRecent trends in software engineering analytics include:\nIntegration of generative artificial intelligence to assess code quality and estimate effort.\nIndustry-wide benchmarking to compare team performance across organisations.\nIncreased focus on developer experience metrics alongside traditional delivery performance.\nPrivacy-preserving analytics to address concerns about individual monitoring.\nSee also\nReferences"
    }
  ]
}