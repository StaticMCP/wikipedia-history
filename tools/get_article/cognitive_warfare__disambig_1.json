{
  "content": [
    {
      "type": "text",
      "text": "# Cognitive warfare__disambig_1\n\nCognitive warfare consists of any military activities designed to affect attitudes and behaviors. It is an extension of information warfare using propaganda and disinformation.\nNATO General Paolo Ruggiero distinguishes it from other information-related activities by its objectives: \"Its goal is not what individuals think, but rather, the way they think.\" Exponents of cognitive warfare aim to influence human thought, reasoning, sense-making, decision-making, and behavior, through the manipulation of information and use of machine learning structures which distribute information on the internet.\nConcept\nDefinition\nThe academic community has not yet reached a complete consensus on the definition of \"cognitive warfare.\" Oliver Backes and Andrew Swab from Harvard University's Belfer Center define cognitive warfare as \"a strategy aimed at changing the way a target population thinks, and thereby changing its behavior.\" Alonso Bernal and others from Johns Hopkins University define cognitive warfare as \"the weaponization of public opinion by external entities, with the goal of influencing the public and/or government policy, or undermining government actions and/or the stability of government institutions.\" Lin Zhengrong of Taiwan's National Defense University stated that the term \"cognitive warfare\" first appeared in a report by the North Atlantic Treaty Organization (NATO). In that report, cognitive warfare is defined as a new domain of competition that goes beyond traditional domains such as land, sea, and air. It is described as \"an unconventional mode of warfare that exploits individual psychological biases and reflexive thinking, using technological networks to manipulate human cognition, induce changes in thought, and thereby cause negative impacts\". Major General Robert H. Scales, former commandant of the U.S. Army War College, once summarized NATO's operational philosophy by stating: \"Victory will be defined more by the mastery of the human and cultural domain than by the occupation of geographic high ground.\" Liang Xiaobo of the National University of Defense Technology believes that cognitive warfare is an important form of public opinion propaganda, psychological persuasion, and ideological struggle, based on modern theories and science, aimed at gaining the initiative over people's thoughts, beliefs, and values.\nAccording to Lin Bozhou, a scholar at the Institute for National Defense and Security Research, in 1999 scholars from People's Liberation Army (PLA) academies proposed the concept of \"unrestricted warfare\", advocating the use of all means to enable the weak to defeat the strong and to force the enemy to concede to one's interests. In 2003, the Chinese Communist Party (CCP) incorporated the \"Three Warfares\" theory into the ''Political Work Regulations of the People's Liberation Army''. In 2014, military research institutions introduced the concept of \"cognitive dominance\", emphasizing ideological manipulation, influence operations, and strategic information warfare; this demonstrated that the CCP's use of cognitive and psychological tactics against the people of Taiwan is grounded in a certain theoretical framework.【戰略快評】洞悉中共認知作戰手法 慎防敘事陷阱. [https://www.ydn.com.tw/news/newsInsidePage?chapterID=1570218 ] *Youth Daily*. March 8, 2023 [April 18, 2023]. (original content [https://web.archive.org/web/20230423020805/https://www.ydn.com.tw/news/newsInsidePage?chapterID=1570218 archived] on April 23, 2023).\nThis type of warfare is also referred to as \"influence operation\", \"cognitive domain operations\", or \"cognitive domain warfare\".\nRelationship to other types of warfare\nScholars believe that \"cognitive warfare\" is a subordinate concept within the frameworks of grey-zone warfare or hybrid warfare.\n* Some viewpoints argue that cognitive warfare is a component of information warfare, and that information warfare itself is a part of hybrid warfare.\n* Some scholars conversely argue that information warfare is a subordinate concept within cognitive warfare.\nCognitive warfare may encompass multiple domains, including traditional propaganda warfare, psychological warfare, ideological warfare, and legal warfare. Compared to \"information warfare\", which can target decision-makers through online social media and physical interpersonal networks (Ventre 2016; Libicki 2020; Prier 2020; Di Pietro, Caprolu, Cresci 2021), and distort and manipulate voters' cognition and emotions (de Buitrago 2019; Serrano-Puche 2021),, and distort and manipulate voters' cognition and emotions, \"cognitive warfare\" not only focuses on media manipulation but also extends into the field of neuroscience, aiming to influence brain functions beyond conventional mass media channels. Among the various related concepts, it is currently only \"cognitive warfare\" that employs neuroscience as a weapon in practical applications, specifically targeting and influencing the cognitive functions of the brain.\nIn cognitive warfare, information serves as a weapon of combat. In such operations, information can be real or partially true and partially false; it does not necessarily have to be entirely \"fake news\". Leaked documents from within the government or inappropriate remarks and actions by political figures can be enough to trigger social division. Regarding the distinction between cognitive warfare and information warfare, Rajesh Tembarai Krishnamachari states that \"cognitive warfare\" is a mode of operation aimed at influencing the adversary's consciousness and behavior. It involves the use of various means such as media, social media, culture, and politics to manipulate and influence both the public and the adversary's awareness. \"Information warfare\", as a component of cognitive warfare, focuses on the use of information and technologies—such as media, social media, the internet, and electronic and digital technologies—to impact the adversary's consciousness and behavior. Liang Xiaobo and other scholars have also pointed out that cognitive warfare largely relies on language as its primary medium to exert influence.\nObjectives and downstream effects\n\"Destabilization\" and \"influence\" are the basic objectives of cognitive warfare, which subsequently spread dissatisfaction or encourage particular beliefs and actions in a society, so that the enemy destroys itself from within; this makes it impossible to resist, deter, or divert the attacker's objectives. In addition to attempting to change the way people think, cognitive warfare also seeks to change the way the audience feels and behaves; if successful, it will likely shape and influence the beliefs and behaviours of an individual or group in favour of the attacker's tactical or strategic objectives. In the most extreme cases, it may cause an entire society to fall apart and no longer have the collective will to resist the attacker, which in turn allows the attacker to subdue the society without resorting to the threat of overt force.\nDestabilization\nThe first basic goal of cognitive warfare is to destabilize the social stability of the target population by destroying its existing unity and trust in society – through, for example, \"negative emotional mobilization\", causing it to become obsessed with internal problems and to lose productivity.\nThe methods of destabilization include accelerating existing divisions within the group, or introducing new ideas and concepts to pit different groups against each other and intensify polarization.\nEffect\nThe second basic goal of cognitive operations is to influence the target population. The attacker manipulates the target group's cognition and understanding of their surroundings, prompts the target group to act in a way that is beneficial to the attacker's purposes, and ultimately causes the target group to resonate with something. Targets of influence the general public, military personnel, and leaders or figures in military, political, or business fields.\nAccording to cerebral nerve scientists, since it is the brain that is responsible for emotions that influence human judgment, humans are prone to distortions in their perceptions and decisions in situations where they feel stress and fear. In terms of dissemination effects, according to a joint study by the Academia Sinica in Taiwan in the journal Global Security Studies published by the University of Oxford, the effects of cognitive warfare are complex, increasing the cognitive processing costs to the brain even if the audience's brain does not pick up on the false information. Under repeated exposure and repeated stimulation of false messages, audiences may reduce the psychological cost of acceptance, and those who lack sufficient knowledge about public affairs may be more vulnerable, relying on external messages.\nDownstream effects\nAccording to Masakowski, the objectives of cognitive warfare are to shape and control an enemy's cognitive thinking and decision-making; to manipulate and degrade a nation's values, emotions, national spirit, cultural traditions, historical beliefs, and political will; to achieve adversarial strategic geopolitical objectives without fighting; to influence human and societal reasoning, thinking, emotions, etc. aligned with specific objectives; and to degrade a population's trust in their institutions. Masakowski states that this allows for the weakening and disruption of military, political, and societal cohesion and the undermining or threatening of democracy. Masakowski alleges that cognitive warfare has also been used by authoritarian societies to restructure society and groom populations to accept \"continuous surveillance\" and that this allows these authoritarian societies to \"remove individuals/outliers who resist and insist on freedom of speech, independent thinking, etc.\"\nModus operandi\nCommon types\nCommon cognitive warfare styles include:\n* Media: Using the media or relevant Key Opinion Leaders (KOLs), such as news stories, advertisements, movies, television shows, and publications, in order to promote one's views and opinions.\n* Social media manipulation: Through social media platforms such as TikTok, Xiaohongshu, Twitter, Facebook, Instagram, etc., and related key opinion leaders, attempts are made to manipulate and influence public opinion and behavior. The ability to secure the internet, social media, or software has been recognized as a key to national security in the cognitive domain and has become the main battleground for international cognitive warfare. By controlling and utilizing whitelisted associated accounts in social media, and using falsely generated fake personal and media accounts to promote favorable information.\n* Intelligence manipulation: To achieve the effects of polarization, incitement, and intimidation by altering, falsifying, and disseminating false or inaccurate information and intelligence in order to influence the enemy's decisions, actions, or public opinion in the public sphere. When such information is mixed with part of the real news, it will make it more difficult for outsiders to recognize the truth, easier to convince the public, and more difficult to clarify the facts.\n* Cultural influence: Influencing the enemy's ideology and values through language and culture, such as music, film, and art. It has been argued that since there are differences in cultural traditions, religious beliefs, customs, psychological perceptions, and thinking patterns among different countries and nations, and discrepancies or even hostility among pluralistic ethnic groups within a country, it is important for the attacker to construct and master the cultural cognitive models of different countries or target groups. Strengthening research on the basic cultural characteristics and cognitive behaviors of enemy military personnel, and on the basic perceptions and attitudes of different communities of the target group, including the general population and non-governmental organizations, on common important and sensitive issues, is a key measure for cognitive warfare.\n* Political propaganda: Influencing the awareness and behavior of target audiences through political advocacy, such as speeches, declarations, demonstrations, public relations, public diplomacy, policy reports, and campaign advertisements.\nScientific and technological enhancement\nWith the use of Artificial Intelligence (AI), cognitive warfare can collect and analyze a wide range of data and information on different target groups and specific individuals through the use of big data analysis, computing power, smartphones, social media platforms, etc. to try to simulate and calculate the target's thinking, mental and emotional cognition, social behavior, public opinion, etc. Burke et al. (2020), in this regard, also argued that AI and big-data analytics technologies play a key role in the People's Republic of China's strategic guidelines for winning cognitive warfare. In addition, the Cambridge Analytica technology can be used as a means to summarize groups with different attitudes, preferences, and positions through the collection of personal information and political inclinations, and to provide different information separately, so as to link target groups with the same preferences together and form an Echo chamber\".\nTransmission route\nMediums\nCognitive warfare is achieved by an attacker providing content to the attacked object through a conduit. The mediums of communication are diverse, including literature distributed during wars since ancient times, while modern cognitive warfare is often through social media such as TikTok, Twitter, and YouTube. Scholar Puma Shen believes that the medium of communication should not be the focus when studying cognitive operations, but instead the key focus should be the process of the channel and the methods used. In 2022, scholars in Taiwan suggested that the news dissemination nodes of cognitive warfare may have been expanded from specific people, online opinion leaders, organizations, or other channels to countries, and that studies have demonstrated that news dissemination nodes such as \"local collaborators\" or internet celebrities are the key pathways.\nCourse of events\nCategorized by communication process and attack motivation, cognitive combat can be divided into human, financial, and information flows, which have different responses. Human traffic is motivated by driving ideology, and attackers organize people who disseminate information (e.g., users of social media), assist in disseminating specific information (which may, but not necessarily, be generated by the attacker) to an audience, or engage in cyber-propaganda and take-downs. Financial flows are motivated by indirect investment, meaning that the attacker only provides funds to sponsor the disseminator of the information, and the generation and dissemination of the information is \"outsourced\" to the disseminator, usually in the form of \"conspiracy theories\" or \"storytelling\". Information flow refers to the generation and dissemination of information by the attackers themselves, usually through the establishment of information-dessimination nodes, the production of fake news, or the production of videos, graphics, and memes that are easy to disseminate to the network community to attract a large audience; the motivation is to achieve the direct manipulation of information.\nIn the case of international transnational communication involving cultural and linguistic differences, for cognitive warfare Liang believes that multimedia channels should be used to combine the language and culture of the target audience with the cultural and ideological connotations of the attacker country, and that national and private experts and scholars, opinion leaders, and the general public should be used to make the issues \"multi-point, multi-position, multi-dimensional\" and spread them simultaneously. These people should be familiar with foreign languages, international communications, and cross-cultural interactions, and they can use various issues to provide opinions, build contacts, and accumulate fans or supporters in the public sphere, and at critical moments they can influence their supporters to achieve specific effects.\nResponse\nDisclosure control and training\nDue to the rapid dissemination of information on the internet, it is possible to break through previous limits of time and location, and it is often difficult to identify the source and the authenticity of information. One solution is enacting legislation to regulate tech giants or requiring online platforms to reveal the flow of sponsorship money from advertising, live streaming, and other forms of online communication, so that audiences can understand the source of the revenue as well as possible impacts. In practice, it is also difficult to establish regulations to trace the source of individual financial flows, so the Australian government, for example, regularly reports publicly on the activities of \"offshore forces\". In 2022, the French National Assembly also established the Commission for the Investigation of Foreign Interference, which investigates attempts by foreign governments, enterprises, groups, and individuals to influence or bribe domestic political parties, leadership hierarchies, or opinion leaders through political or economic means. In 2023, the European Union announced plans to establish an \"Information Sharing and Analysis Center\" to centralize and analyze cases of information manipulation by foreign forces. There are also scholars such as Silverstein (2019) who advocate that governments should ethically regulate the use of neuroscience as a weapon. In addition, the attacked target needs to be aware that cognitive combat is taking place; it needs to be capable of observing and adapting before deciding to take action (OODA loop).\nGovernments in some countries or regions have prohibited the use of specific community software by public officials on computers and cell phones in government agencies, or are considering revising regulations to standardize the information equipment used in public agencies. They also seek to enable enterprises to cooperate in assuming their corporate social responsibility and to increase the their information security capabilities. government departments can also publicize the issue through the mass media and set up dedicated investigation units and information clarification mechanisms. At the same time, it is important to strengthen the \"media literacy\" of the general public and enhance their understanding of the boundaries of freedom of expression so as to respond more effectively to \"hate speech\" and controversial information that is a mixture of truth and falsehood. The military defense and national security units can counteract \"cognitive warfare\"-related concerns through intelligence detection and acquisition, education and training in information interpretation, and detailing appropriate response attitudes. Some commentators believe governmental authorities should take the initiative on countermeasures by \"exposing\" and \"cracking down on nodes\", and raising the public's \"digital citizenship awareness\".\nTo combat international transnational cognitive warfare, governments can also create and coordinate specialized agencies to train professional and foreign-language personnel to spot and counteract disinformation, and can coordinate with allied countries for assistance, training, and support.\nMedia literacy and civic engagement\nIn the public sphere, civil society needs to be made to understand the boundaries of freedom of expression in order to recognize the fine line between freedom of expression and national security. In order to improve the public's information-identification and cognitive abilities, education is necessary to improve media literacy and critical thinking in all sectors of society. Citizens should receive news from multiple sources, compare relevant information from different sources, and attempt to dispel myths. A trusted and credible \"third-party organization\" can be established. Fact-checking mechanisms by citizen groups for sober information are needed, as well as enhanced cooperation with non-governmental organizations (NGOs). At the same time, attempts should be made to establish a variety of niche media that express different positions and pluralistic viewpoints so that different values can be voiced.\nPublic denunciation and public awareness are ways to counteract \"local collaborators\" who assist in spreading misinformation.\nCognitive warfare and information warfare\nAccording to Masakowski, cognitive warfare evolves as an extension of information warfare (IW) and psychological operations (PsyOps). Operations in the information environment are traditionally conducted in five core capabilities - electronic warfare (EW), psychological operations (PSYOPs), military deception (MILDEC), operational security (OPSEC), and computer network operations (CNO). Information warfare aims at controlling the flow of information in support of traditional military objectives, mainly to produce lethal effects on the battlefield.\nAccording to Masakowski and NATO Gen Ruggiero, cognitive warfare degrades the capacity to know and to produce foreknowledge, thus transforming the understanding and interpretations of situations by individuals and in the mass consciousness, and it has multiple applications, including commercial, political, and covert information warfare and cognitive warfare military operations.\nThe Chinese military refers to operations in the cognitive domain as \"cognitive domain operations (CDO)\".\nProfiling and polarization\nUsing a psychological and psychographic profile, an influence campaign can be created and adjusted in real-time by A.I. machine-learning models until the desired cognitive and behavioral effects on the individual or population are achieved. The U.S. Army and Marine Corps counterinsurgency strategy calls for the use of automated biometric systems to separate insurgents and foreign fighters from the general population. In doing so, this helps counter-insurgents leverage the population and the operational environment against the threat network.\nDecades of peer-reviewed research show that echo chambers, in the physical world and online, cause political polarization, extremism, confusion, cognitive dissonance, negative emotional responses (e.g., anger and fear), reactance, microaggressions, and third-person effects.\nThese psychological perseverance mechanisms such as confirmation bias can be very problematic. Nyhan & Reifler (2010) found that even attempting to correct false beliefs often reinforces rather than dispels these beliefs among those who hold them most strongly. This is known as the backfire effect – \"in which corrections actually increase misperceptions\".\nCases\nUSA\nAccording to Reuters, beginning in 2019 U.S. President Donald Trump authorized the CIA to conduct a covert operation on Chinese social media. The project began in 2019 and was aimed at guiding public opinion against the Chinese government. Three former officials told Reuters that the CIA set up a small team of agents using false identities to spread negative comments about the Chinese government and leak defamatory information to overseas media. Two former officials pointed out that these operations in China were aimed at inciting senior leaders and forcing the government to spend a lot of effort on searching for cyber intrusion operations. Chinese Foreign Ministry spokesman Wang Wenbin responded that the United States had been spreading false information about China in an organized and planned manner for many years, which had become an important means of the United States' cognitive warfare against China.\nIn June 2024, Reuters exposed the U.S. Department of Defense's efforts to discredit China's Sinovac vaccine in the Philippines during the COVID-19 pandemic by spreading false information. The report said that the U.S. military used fake online accounts posing as Filipinos to fabricate false statements on the social platform X (formerly Twitter), creating a wave of vaccine boycotts. The report stated that the U.S. military's efforts to discredit China's vaccines probably began in the spring of 2020 and continued for a period of time after Biden took office. It was ordered to stop in the spring of 2021. A senior official involved in the operation revealed that \"we don't look at it from a public health perspective... but rather study how to discredit China\".\nThe Intercept, a U.S. investigative organization, pointed out that the U.S. Department of Defense used Twitter to assist in propaganda activities. Internal Twitter documents showed that at the request of U.S. government departments, a large number of Twitter accounts were whitelisted. These whitelisted accounts were used by the U.S. Department of Defense to carry out online propaganda abroad, attempting to shape public opinion about Yemen, Syria, Iraq, and Kuwait.\nThese whitelisted accounts were initially openly affiliated with U.S. government departments, but the U.S. Department of Defense later changed its strategy to hide its relationship with these accounts. Although Twitter executives noticed this, they did not shut down these accounts.\nNathaniel Kahler, then an employee working for the U.S. Central Command, sent a request email to Twitter on behalf of the company's public policy team on July 26, 2017, asking for approval to verify an account and whitelist some Arabic-speaking accounts to amplify specific messages. Among these whitelisted accounts, @yemencurrent was used to promote the U.S. drone strike announcement in Yemen, emphasizing that the U.S. drone strike was \"accurately\" used to kill terrorists and promote U.S. and Saudi-backed attacks on Houthi terrorists in Yemen.\nThe Stanford Internet Observatory and Graphika jointly released a report entitled \"Unheard Voice: Evaluating Five Years of Pro-Western Covert Influence Operations\", stating that there is an interconnected network of accounts on Twitter, Facebook, Instagram, and five other social platforms in the United States that use inducement strategies to promote pro-Western rhetoric in the Middle East and Central Asia. This propaganda promotes the interests of the United States and its allies while opposing countries including Russia, China, and Iran. These accounts mainly criticize Russia for the deaths of innocent civilians during its invasion of Ukraine and the war atrocities committed by the Russian army.\nSome activities also promote the spread of anti-extremist information. The accounts used in the propaganda against Central Asia are almost entirely concentrated in China. These fake characters and media accounts mainly focus on the Xinjiang re-education camps and the genocide of ethnic minorities such as Muslims.\nAccording to the New York Post, in October 2020 Joe Biden's presidential campaign urged Mike Morell, who had been the CIA director during the Obama administration, to help Biden organize a joint letter of 50 intelligence officials, saying that the New York Post's report on Biden's son Hunter Biden's laptop was fake news from Russia. In a private testimony to the House Judiciary Committee, Morell talked about the Hunter Biden laptop controversy on October 17, 2020. Afterwards, the joint open letter was handed over to the American political news company Politico, which published an article titled \"Hunter Biden story is Russian disinformation, dozens of former officials say\" on October 19, claiming that contrary to the New York Posts report \"dozens of former intelligence officials believe that it is Russian information warfare and has all the typical characteristics of Russian information warfare\". Twitter eventually banned the New York Posts report in the critical weeks before the election, and Facebook also restricted users' access to the full report. At a hearing, Republicans accused Twitter of collaborating with government agencies and news media to suppress the New York Post. Twitter executives admitted that suppressing the report was \"wrong\", but denied that the U.S. government was involved in suppressing the New York Post report. In an interview, Facebook founder Mark Zuckerberg said that the restrictive measures on the New York Post report were based on a warning from the FBI. After the New York Post report was published, the FBI contacted the Facebook team and warned them that Russia had interfered in the 2016 election (by spreading false information). Facebook believed that the report fit this pattern and ultimately chose to limit the scope of the report and the ranking weight of the New York Post.\nOperation Mockingbird originated in the early days of the Cold War and was a large-scale program carried out by the CIA to control the media and ultimately influence public opinion.\nRussia\nAccording to a report by the U.S. State Department, Russia's information warfare system consists of five parts: government communication platforms for publishing information, state-funded global information distribution channels, the cultivation of agent resources, weaponized social media, and the use of online fake news. Silverstein (2019) believes that Russia interfered in the U.S. presidential election and the UK's Brexit referendum through cognitive operations, and according to Connell and Vogler's research (2017), Russia's cyber warfare uses cognitive manipulation as a key element. A report released in 2023 by the British intelligence agency Government Communications Headquarters (GCHQ) stated that countries such as Russia and Iran often carry out various types of cyber attacks to spread fake news. Peter Zalmayev, a Ukrainian journalist and director of the non-profit organization Eurasian Democracy Initiative, said that before Russia annexed Crimea in 2014, it had already begun to spread false information in Ukraine, including false statements that undermined Ukraine's sovereignty and denied its status as a sovereign state, and created information confusion to prevent the spread of facts. Shen Boyang believes that Russia used cognitive warfare in the Russo-Ukrainian War.\nChina\nParticipants\nMain articles: Internet commentators and Office of the Central Cyberspace Affairs Commission\nThe Chinese Communist Party (CCP) has employed a large number of 50 Cent Party accounts to post favorable information and comments about the People's Republic of China. These commentators and online operatives are often referred to by outsiders as the \"50 Cent Party\" (wumao dang), a term used to describe individuals allegedly paid by the CCP to manipulate online discourse.\nThese commentators typically pose as ordinary internet users, posting pro-CCP and pro-government remarks, attacking critics of the CCP, or using other information dissemination strategies to influence, guide, and fabricate public opinion online.\nOn February 27, 2014, the CCP General Secretary Xi Jinping, in a speech at the first meeting of the Central Cyberspace Affairs Commission, emphasized the need to \"innovate and improve online propaganda, apply the rules of internet communication, promote the main theme, inspire positive energy (Zheng nengliang), vigorously foster and practice the core socialist values, and master the timing, degree, and effectiveness of online public opinion guidance to create a clean and upright cyberspace\".\nTactics used\nAccording to The Economist, the People's Republic of China has conducted sustained psychological warfare against Taiwan for many years. Other scholars have also discussed how the Chinese Communist Party employs cognitive warfare tactics to influence the people of targeted countries. The main methods of such operations include military intimidation, exerting influence through bilateral exchanges, interference via religious influence, and the spread of disinformation and content farms online. These tactics generally follow a common pattern: direct or indirect threats, applying psychological pressure on those who oppose its policies, attracting target groups, and creating distractions. As of 2023, such operations have also included establishing front companies, hiring freelance writers around the world, and actively recruiting protest participants.\nThe term \"unrestricted warfare\" as used in PLA research is roughly equivalent to hybrid warfare and the \"Three Warfares\"—cognitive warfare, psychological warfare, and legal warfare (lawfare)—and all can fall under the broader umbrella of information warfare. However, scholar Puma Shen (2021) argues that these traditional classifications fail to encompass newer developments by the Chinese government, such as \"digital authoritarianism\" (e.g., Huawei's global exports) and the collection (or import) of overseas personal data. Additionally, scholar Cheng Deying (2022) asserts that the Chinese Communist Party's cognitive warfare against Taiwan no longer differentiates between peacetime and wartime and has become pervasive.\nIn the case of China's cognitive warfare against Taiwan, U.S. official Matthew Pottinger publicly stated that China has invested massive resources into conducting cognitive warfare against Taiwan, and these efforts may already be yielding results.【社論】團結對抗威權 反制中共認知作戰. [https://web.archive.org/web/20230330070213/https://www.ydn.com.tw/news/newsInsidePage?chapterID=1560233&type=forum ] Youth Daily. [January 4, 2025]. (original content [https://www.ydn.com.tw/news/newsInsidePage?chapterID=1560233&type=forum archived] on March 30, 2023). A 2022 report titled China Security Report published by the Japan Ministry of Defense think tank, the National Institute for Defense Studies, noted that mainland China launched over 1.4 billion cyberattacks against Taiwan within a year and attempted to recruit personnel from multinational corporations and military-related sectors.\nIn Canada, then-Federal Member of Parliament and House of Commons of Canada on National Defense John McKay, along with Michel Juneau-Katsuya, former Director of the Asia-Pacific region at the Canadian Security Intelligence Service, publicly stated that the People's Republic of China has been conducting extensive infiltration and influence operations within Canada, prompting increased national vigilance. Scholars such as Kelton have also asserted that the PRC is carrying out cognitive warfare operations in Australia and New Zealand as well.\nAccording to a 2021 research report by Paul Cheron, a scholar at France's Ministry of Armed Forces think tank the Institute for Strategic Research at the Military School (IRSEM), and national security expert Jean-Baptiste Jeangène Vilmer, titled \"Chinese Influence Operations – A Machiavelli Moment\", the People's Republic of China has invested heavily in disseminating disinformation to achieve two main objectives: to undermine the democracy of Taiwan and to condition the Taiwanese public into accepting the Chinese Communist Party's eventual annexation. This disinformation is often concentrated in the military domain, aiming to convince the Taiwanese people that an invasion by the PRC is ultimately inevitable, while simultaneously justifying potential military actions initiated by the PRC.\nIn their 2023 co-authored work ''U.S.-Taiwan Relations – Will China's Challenge Lead to a Crisis?, Ryan Hass, a senior fellow at the Brookings Institution, Bonnie Glaser, director of the Asia Program at the German Marshall Fund, and Richard C. Bush, former Chairman of the American Institute in Taiwan, argue that in addition to the increasingly apparent military threat posed by the PRC, Taiwan is also facing a growing crisis in the form of political warfare by the Chinese Communist Party, which is gradually eroding the will of the Taiwanese people. They caution that this latter aspect is often overlooked, yet if left unaddressed, it may ultimately cause even greater harm to U.S. interests.\nNetwork news\nThe V-Dem Research Project, a transnational academic survey, found in 2019 that Taiwan was the most vulnerable to foreign fake news in the world. According to the 2022 Beijing Global Media Influence Report released by the U.S. human rights organization Freedom House, Taiwan faces a large amount of fake news from mainland China, and the influence of the People's Republic of China on the media of Taiwan continues to expand. A research report released by the University of Gothenburg in Sweden in 2023 also pointed out that for ten consecutive years Taiwan has been the country most affected by foreign fake news in the world, and most of this fake news is related to the People's Republic of China. The Taiwanese Army once analyzed the controversial news spread by the People's Liberation Army of China. The content types mainly include: creating a psychological atmosphere of \"military reunification,\" undermining the prestige of the Taiwanese government, and attempting to disrupt the morale of the army and the people. Among them, deliberate disruption morale comprised the majority of the content.\nPaul Cheron and Jean-Baptiste Jeangène Vilmer pointed out that the CCP's propaganda system usually starts with the official media releasing false news, then using fake Taiwanese social media accounts to collect and reprint it. Taiwanese news media will then quote and spread the false news without verification, making it difficult for readers to identify the source of the news information. Taiwan's national security units have also discovered the \"four-level structure of spreading rumors\" used by online water armies to influence online public opinion: first, using \"disposable\" fake social media accounts to post articles, then sharing screenshots of the article content through Facebook fan pages managed by people outside Taiwan, and then using a large number of dummy accounts in the third level to expand the spread, and finally a large number of dummy accounts to share to more well-known public Facebook groups to increase exposure and induce Taiwanese people to continue to spread it on commonly used social media. In March 2020, Facebook disclosed that it had shut down more than 60 accounts of the People's Republic of China's cyber forces that were posing as Taiwanese users and spreading false information about the coronavirus to Taiwan. In May 2023, Facebook's parent company, Meta, removed more than 100 fake accounts posing as American and European organizations from its platforms Facebook and Instagram. The network of related accounts operated in a similar way to the methods used by Russia during the 2016 U.S. presidential election. In 2022 the Ministry of Justice Investigation Bureau cracked down on a case in which controversial and false information was released through social media platforms in an attempt to influence the perception of the Taiwanese people.\nSee also\n* Political warfare\n* Three warfares\nReferences"
    }
  ]
}