{
  "content": [
    {
      "type": "text",
      "text": "# Lex (software)\n\n| latest release version =\n| latest release date    =\n| programming language   = C\n| operating system       = Unix, Unix-like, Plan 9\n| platform               = Cross-platform\n| genre                  = Command\n| license                = Plan 9: MIT License\n| website                =\n}}\nLex is a computer program that generates lexical analyzers (\"scanners\" or \"lexers\"). It is commonly used with the yacc parser generator and is the standard lexical analyzer generator on many Unix and Unix-like systems. An equivalent tool is specified as part of the POSIX standard.\nLex reads an input stream specifying the lexical analyzer and writes source code which implements the lexical analyzer in the C programming language.\nIn addition to C, some old versions of Lex could generate a lexer in Ratfor.\nHistory\nLex was originally written by Mike Lesk and Eric Schmidt and described in 1975.\nIn the following years, Lex became the standard lexical analyzer generator on many Unix and Unix-like systems. In 1983, Lex was one of several UNIX tools available for Charles River Data Systems' UNOS operating system under Bell Laboratories license.\nAlthough originally distributed as proprietary software, some versions of Lex are now open-source. Open-source versions of Lex, based on the original proprietary code, are now distributed with open-source operating systems such as OpenSolaris and Plan 9 from Bell Labs. One popular open-source version of Lex, called flex, or the \"fast lexical analyzer\", is not derived from proprietary coding.\nStructure of a Lex file\nThe structure of a Lex file is intentionally similar to that of a yacc file: files are divided into three sections, separated by lines that contain only two percent signs, as follows:\n*The definitions section defines macros and imports header files written in C. It is also possible to write any C code here, which will be copied verbatim into the generated source file.\n*The rules section associates regular expression patterns with C statements. When the lexer sees text in the input matching a given pattern, it will execute the associated C code.\n*The C code section contains C statements and functions that are copied verbatim to the generated source file. These statements presumably contain code called by the rules in the rules section. In large programs it is more convenient to place this code in a separate file linked in at compile time.\nExample of a Lex file\nThe following is an example Lex file for the flex version of Lex. It recognizes strings of numbers (positive integers) in the input, and simply prints them out.\n/*** Definition section ***/\n%{\n/* C code to be copied verbatim */\n#include\n%}\n%%\n/*** Rules section ***/\n/* [0-9]+ matches a string of one or more digits */\n[0-9]+  {\n/* yytext is a string containing the matched text. */\nprintf(\"Saw an integer: %s\\n\", yytext);\n}\n.|\\n    {   /* Ignore all other characters. */   }\n%%\n/*** C Code section ***/\nint main(void)\n{\n/* Call the lexer, then quit. */\nyylex();\nreturn 0;\n}\nIf this input is given to flex, it will be converted into a C file, . This can be compiled into an executable which matches and outputs strings of integers. For example, given the input:\nabc123z.!&*2gj6\nthe program will print:\nSaw an integer: 123\nSaw an integer: 2\nSaw an integer: 6\nUsing Lex with other programming tools\nUsing Lex with parser generators\nLex, as with other lexical analyzers, limits rules to those which can be described by regular expressions. Due to this, Lex can be implemented by a finite-state automata as shown by the Chomsky hierarchy of languages. To recognize more complex languages, Lex is often used with parser generators such as Yacc or Bison. Parser generators use a formal grammar to parse an input stream.\nIt is typically preferable to have a parser, one generated by Yacc for instance, accept a stream of tokens (a \"token-stream\") as input, rather than having to process a stream of characters (a \"character-stream\") directly. Lex is often used to produce such a token-stream.\nScannerless parsing refers to parsing the input character-stream directly, without a distinct lexer.\nLex and make\nmake is a utility that can be used to maintain programs involving Lex. Make assumes that a file that has an extension of .l is a Lex source file. The make internal macro LFLAGS can be used to specify Lex options to be invoked automatically by make.\nSee also\n*Flex lexical analyser\n*Yacc\n*Ragel\n*re2c\n*PLY (Python Lex-Yacc)\n*Comparison of parser generators\nReferences\nExternal links\n*[http://www.mactech.com/articles/mactech/Vol.16/16.07/UsingFlexandBison/ Using Flex and Bison at Macworld.com]\n*\n*"
    }
  ]
}