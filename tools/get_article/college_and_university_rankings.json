{
  "content": [
    {
      "type": "text",
      "text": "# College and university rankings\n\nCollege and university rankings order higher education institutions based on various criteria, with factors differing depending on the specific ranking system. These rankings can be conducted at the national or international level, assessing institutions within a single country, within a specific geographical region, or worldwide. Rankings are typically conducted by magazines, newspapers, websites, governments, or academics.\nIn addition to ranking entire institutions, specific programs, departments, and schools can be ranked. Some rankings consider measures of wealth, excellence in research, selective admissions, and alumni success. Rankings may also consider various combinations of measures of specialization expertise, student options, award numbers, internationalization, graduate employment, industrial linkage, historical reputation and other criteria.\nCriticism\nThe interpretation, accuracy, and usefulness of rankings have been criticized. The expanding diversity in rating methodologies and accompanying criticisms of each indicate the lack of consensus in the field. Further, it seems possible to game the ranking systems through excessive self-citations or by researchers supporting each other in surveys.\nUNESCO has even questioned whether rankings \"do more harm than good,\" noting that while \"Rightly or wrongly, they are perceived as a measure of quality and so create intense competition between universities all over the world\".\nCritics argue that rankings can divert universities' attention away from teaching and social responsibility towards the type of scientific research valued by indicators used for ranking exercises. There have also been concerns that by applying a limited set of criteria to world universities, and given the strong desire to feature in the top 200 universities, rankings actually encourage the homogenization of higher education institutions, making them less responsive and less relevant to their immediate contexts. The fact that rankings are also said to favour the advantage enjoyed by the 200 best-ranked institutions has important implications for equity.\nGlobal rankings\nSeveral organizations produce worldwide university rankings, including the following. The three longest established and most influential global rankings are those produced by Quacquarelli Symonds (QS), Times Higher Education (THE) and Shanghai Ranking Consultancy (the Academic Ranking of World Universities; ARWU). All of these, along with other global rankings, primarily measure the research performance of universities rather than their teaching. They have been criticized for being \"largely based on what can be measured rather than what is necessarily relevant and important to the university\", and the validity of the data available globally has been questioned.  As of 2021, across the three most popular global rankings, \"the majority of the top-ten globally ranked institutions are located in southern England, California, the tri-state area (New York, New Jersey, Connecticut), and nearby Massachusetts.\"\nWhile some rankings attempt to measure teaching using metrics such as staff to student ratio, the Higher Education Policy Institute has pointed out that the metrics used are more closely related to research than teaching quality, e.g. \"Staff to student ratios are an almost direct measure of research activity\", and \"The proportion of PhD students is also to a large extent an indication of research activity\". Inside Higher Ed similarly states \"these criteria do not actually measure teaching, and none even come close to assessing the quality of impact\". Many rankings are also considered to contain biases towards the natural sciences and, due to the bibliometric sources used, towards publication in English-language journals. Some rankings, including ARWU, also fail to make any correction for the sizes of institutions, so a large institution is ranked considerably higher than a small institution with the same quality of research. Other compilers, such as Scimago and U.S. News & World Report, use a mix of size-dependent and size-independent metrics.\nSome compilers, notably QS, THE, and U.S. News, use reputational surveys. The validity of these has been criticized: \"Most experts are highly critical of the reliability of simply asking a rather unrandom group of educators and others involved with the academic enterprise for their opinions\"; \"methodologically [international surveys of reputation] are flawed, effectively they only measure research performance and they skew the results in favor of a small number of institutions.\"\nHowever, despite the criticism, much attention is paid to global rankings, particularly ARWU, QS, and THE. Some countries, including Denmark and the Netherlands, use university rankings as part of points-based immigration programs, while others, such as Russia, automatically recognize degrees from higher-ranked universities. India's University Grants Commission requires foreign partners of Indian universities to be ranked in the top 500 of the THE or ARWU ranking, while Brazil's Science Without Borders program selected international partner institutions using the THE and QS rankings.\nMajor international rankings\nQS World University Rankings\nThe QS World University Rankings are a ranking of the world's top universities produced by Quacquarelli Symonds published annually since 2004. In 2024, they ranked 1500 universities, with the Massachusetts Institute of Technology, Imperial College London, University of Oxford, Harvard University and University of Cambridge taking the top 5 spots.\nThe QS rankings should not be confused with the Times Higher Education World University Rankings. From 2004 to 2009 the QS rankings were published in collaboration with Times Higher Education and were known as the Times Higher Education-QS World University Rankings. In 2010 QS assumed sole publication of rankings produced with this methodology when Times Higher Education split from QS in order to create a new rankings methodology in partnership with Thomson Reuters. The QS rankings were previously published in the United States by U.S. News & World Report as the \"World's Best Universities\". However, in 2014, U.S. News & World Report launched their own international university ranking titled \"Best Global Universities\". The inaugural ranking was published in October 2014.\nIn 2023, for the 20th edition of the QS World University Rankings, released on 28 June 2023, QS following an 18 months long consultation involving representatives of the global higher education sector, students and the QS Rankings Global Advisory Board (established in 2010), introduced its largest-ever methodological enhancement, introducing three new metrics: Sustainability, Employment Outcomes and International Research Network, each worth 5% of a university's possible score.  The results draw on the analysis of 17.5m academic papers (bibliometric data provided by data from Scopus,) which informs the \"Citation per Faculty\" indicator and represent 20 percent of the overall score. The results also draw on the expert opinions of over 144,000 academic faculty and over 98,000 international employers. These two indicators are worth 30 percent and 15 percent of a university's possible score respectively. The QS rankings also incorporate faculty/student ratios (10 percent of the overall score) and international staff and student numbers (5 percent each of the overall score). The detailed methodology is available online.\nQS Asian University Rankings\nThe QS World University Rankings expanded its portfolio in 2009 to incorporate the Asian University Rankings.\nThis expansion was executed in collaboration with The Chosun Ilbo newspaper, based in South Korea. By 2023, the rankings had grown to feature 760 universities. The eligibility criteria for these rankings were anchored in the United Nations M49 Standard. These criteria update led to the inclusion of five Central Asian nations - Kazakhstan, Uzbekistan, Kyrgyzstan, Tajikistan, and Turkmenistan - as well as Iran. For the first time in eight years, a Singaporean institution did not take the regional top spot, nor did Singapore occupy two of the top three positions. The city-state's hegemony at the top of the table was interrupted by the rise of China's premier institutions, particularly Peking University, the new regional leader, breaking the National University of Singapore's four-year run as Asia's number one university. NUS fell to second place while China's Tsinghua University came third. Nanyang Technological University dropped to fifth place. China (Mainland) was the region's most represented location, with 128 listed universities, followed by India with 118 and Japan with 106.  Although the Asian University Rankings share some core metrics with the QS World University Rankings, there are variations in the weightings. Additionally, the methodology  for the Asian rankings integrates region-specific indicators. Notably, these include metrics such as the percentage of staff with PhDs and data on inbound and outbound exchange students.\nQS Latin American & Caribbean University Rankings\nThe QS Latin American University & The Caribbean Rankings were published for the first time in 2011. The methodology was developed in consultation with experts from the region. Evaluating the region's institutions based on academic and employer recognition, research output, resources and internationalisation, the 2024 edition of the rankings lists 430 institutions across 25 locations. Universidade de São Paulo tops the table, usurping Pontificia Universidad Católica de Chile which comes second while Brazil's Universidade Estadual de Campinas places third. Brazil is the most represented nation with 97 listed universities, followed by Mexico with 63 and Colombia with 61.\nQS Arab Region Universities Rankings\nThe first-ever QS Arab Region University Rankings is released in 2014. Evaluating institutions based on global recognition, research prowess, teaching resources and internationalisation (methodology), the 2024 edition of the ranking is the largest ever, showcasing 223 institutions from 18 member countries of the Arab League. King Fahd University of Petroleum & Minerals topped the table, climbing from third place in the previous edition. King Saud University came second while Qatar University placed third. The previous year's leader, King Abdulaziz University (KAU), dropped to fifth, after spending four consecutive years in the top spot. Egypt was the most represented higher education system, with 36 featured universities, followed by Saudi Arabia with 34 and Iraq with 24.\nThe top ten universities in the Arab world: Qatar University (Doha, Qatar); King Saud University (Riyadh, Saudi Arabia); Sultan Qaboos University (Muscat, Oman); the American University of Beirut (Beirut, Lebanon); the American University of Sharjah (Sharjah, United Arab Emirates); the University of Jordan (Amman, Jordan); United Arab Emirates University (Al Ain, United Arab Emirates); King Fahd University of Petroleum and Minerals (Dhahran, Saudi Arabia); Khalifa University (Abu Dhabi, United Arab Emirates); and King Abdulaziz University (Jeddah, Saudi Arabia).\nComparative reviews of ranking systems note differing indicators and weights. Arab-region scholars have proposed alternative methodologies for global and Arab rankings and argue that current schemes underweight contextual differences and display bias against Arab institutions. They recommend re calibrating indicators and weights.\nQS Ranking by Subject\nThe  QS World University Rankings by Subject was first published in 2011, featuring 26 disciplines. The latest edition showcases over 1,500 universities and specialist higher education institutions across 55 different subjects, grouped into 5 faculty (broad subject) areas.\nTimes Higher Education World University Rankings\nTimes Higher Education World University Rankings}}\nFrom 2004 to 2009 Times Higher Education (THE), a British publication, published the annual Times Higher Education–QS World University Rankings in association with Quacquarelli Symonds (QS). THE published a table of the top 200 universities and QS ranked approximately 500 online, in book form, and via media partners. On 30 October 2009, THE broke with QS and joined Thomson Reuters to provide a new set of world university rankings, called Times Higher Education World University Rankings. The 2015/16 edition of the Times Higher Education World University Rankings rank the world's 800 best universities, while the 2016/17 installment will rank the world's top 980.\nOn 3 June 2010, Times Higher Education revealed the methodology which they proposed to use when compiling the new world university rankings. The new methodology included 13 separate performance indicators, an increase from the six measures employed between 2004 and 2009. After further consultation the criteria were grouped under five broad overall indicators to produce the final ranking. THE published its first rankings using its new methodology on 16 September 2010, a month earlier than previous years. THE also kick-started THE 100 Under 50 ranking and Alma Mater Index.\nThe Globe and Mail in 2010 described the Times Higher Education World University Rankings as \"arguably the most influential\".\nResearch published by professors at the University of Michigan in 2011 demonstrated that the early Times Higher Education Supplement rankings were disproportionately influential in establishing the status order of world research universities.\nTimes Higher Education World Reputation Rankings\nThis ranking was published for the first time in March 2011. The rankings are based on a survey of (for 2016) 10,323 academics from 133 countries, who are asked to talk the top universities in their field for teaching and for research.\nAcademic Ranking of World Universities\nAcademic Ranking of World Universities}}\nThe Academic Ranking of World Universities (ARWU) compiled originally by the Shanghai Jiao Tong University and now maintained by the ShanghaiRanking Consultancy, has provided annual global rankings of universities since 2003, making it the earliest of its kind. ARWU does not rely on surveys and school submissions. Among other criteria, ARWU includes the number of articles published by Nature or Science and the number of Nobel Prize winners and Fields Medalists (mathematics). Harvard and Stanford have topped the ranking for years.\nOne of the primary criticisms of ARWU methodology is that it is biased towards the natural sciences and English language science journals over other subjects. Moreover, the ARWU is known for \"relying solely on research indicators\", and \"the ranking is heavily weighted toward institutions whose faculty or alumni have won Nobel Prizes\": it does not measure \"the quality of teaching or the quality of humanities.\"\nOther global rankings\nAggregate Ranking of Top Universities\nThe Aggregate Ranking of Top Universities (ARTU) is a meta-ranking that positions global universities based on World University Rankings by THE, QS, and ARWU. ARTU is produced by UNSW Sydney and published annually since 2019, with retrospective rankings available for 2012 to 2018. In 2024, ARTU ranked 471 universities and featured the Top 400 for publication, with MIT securing first place, followed by Harvard and Oxford in second and third place, respectively.\nThe criteria for ARTU is the sum of world rank across the 3 rankings (=THE+QS+ARWU) with universities excluded if they do not have a distinct rank in THE, QS, and ARWU. Since 2012, United States has the highest number of ARTU Top 200 universities, while Switzerland has the most ARTU Top 200 universities per capita. Meanwhile, Hong Kong, now surpassing Switzerland—which traditionally led on a per capita basis—has the highest number of ARTU Top 200 universities per capita.\nSince 2022, ARTU has included Gross Domestic Product (GDP) and Research & Development (R&D) expenditure as modifiers to determine country level performance and return on investment. Hong Kong and Australia come out on top for GDP and R&D respectively for most ARTU Top 200 universities adjusted by these indicators.\nAcademic Influence\nAcademic Influence creates global and U.S.-centric rankings of colleges, universities, and disciplinary programs by evaluating the combined influence of a school's faculty within and across fields of study. Using machine-learning technology developed with funding from the Defense Advanced Research Projects Agency, Academic Influence searches and collates open-source data from such massive publicly available data sources as Wikipedia, Wikidata, Crossref, Semantic Scholar, IPEDS, and BLS. Academic Influence gives weight in its rankings to citations of peer-reviewed articles, chapters, and books by influential academics worldwide. It thereby attempts to map and objectively measure the influence of a school's thought leadership through its students, faculty, staff, and alumni. Academic Influence allows users to create rankings on the fly through its dynamic schools and people tools, which can be filtered by discipline, country, and period. Tech entrepreneur and computer scientist Erik J. Larson co-founded Academic Influence.\nCenter for World University Rankings\nThe Center for World University Rankings (CWUR) is based in the United Arab Emirates and publishes global university rankings measuring the quality of education and training for students as well as the prestige of the faculty members and the quality of their research. Samplings do not come from surveys and university data submissions. Instead, the rankings rely more on outcome-based samplings, coupled with a Subject ranking in 227 subject categories. The Subject portion of the ranking is based on the number of research articles in top-tier journals with data obtained from Clarivate Analytics. In the United States, the CWUR evaluates and ranks over 1,300 universities and 2,000 worldwide.\nLeiden Ranking\nThe Centre for Science and Technology Studies at Leiden University maintains a European and worldwide ranking of the top 500 universities according including the number and impact of Web of Science-indexed publications per year. The rankings compare research institutions by taking into account differences in language, discipline and institutional size. Multiple ranking lists are released according to various bibliometric normalization and impact indicators, including the number of publications, citations-per-publication, and field-averaged impact per publication.\nPerformance Ranking of Scientific Papers for World Universities\nThe Performance Ranking of Scientific Papers for World Universities was produced until 2012 by the Higher Education Evaluation and Accreditation Council of Taiwan (HEEACT). The indicators were designed to measure both long-term and short-term research performance of research universities.\nThis project employed bibliometrics to analyze and rank the performance of the 500 top universities and the top 300 universities in six fields. HEEACT further provides subject rankings in science and technology fields. It also ranked the top 300 universities across ten science and technology fields.\nThe ranking included eight indicators. They were: articles published over the prior 11 years; citations of those articles, \"current\" articles, current citations, average citations, \"H-index\", number of \"highly cited papers\" and high impact journal articles. They represented three criteria of scientific papers performance: research productivity, research impact, and research excellence.\nThe 2007 ranking methodology was alleged to have favored universities with medical schools, and in response, HEEACT added assessment criteria. The six field-based rankings are based on the subject categorization of WOS, including Agriculture & Environment Sciences (AGE), Clinical Medicine (MED), Engineering, Computing & Technology (ENG), Life Sciences (LIFE), Natural Sciences (SCI) and Social Sciences (SOC). The ten subjects include Physics, Chemistry, Mathematics, Geosciences, Electrical Engineering, Computer Science, Mechanical Engineering, Chemical Engineering (including Energy & Fuels), Materials Sciences, and Civil Engineering (including Environmental Engineering). The ranking was produced by National Taiwan University since 2012 and also known as NTU Ranking.\nReuters World's Top 100 Innovative Universities\nThe ranking uses a methodology with 10 metrics. The process cross-references the 500 academic and government organizations with the greatest number of published articles in scholarly journals as indexed in the Thomson Reuters Web of Science Core Collection database against how many patents and patent equivalents each organization filed in the same period in the Derwent World Patents Index and the Derwent Innovations Index. The remaining 70 institutions were mostly universities and were ranked using criteria such as frequency of patent applications granted, the number of filed patents, frequency of those patents being cited, as well as how many of their papers were cited by patents or co-authored by an industry author. The ranking has the Asia-Pacific edition featuring top 75 institutions across the region  and top 25 most innovative governmental institutions in the world. Currently, the last available edition of the ranking dates back to 2019.\nRound University Ranking\nRound University Ranking, or abbreviated RUR Rankings is a world university ranking, assessing effectiveness of 750 leading universities in the world based on 20 indicators distributed among 4 key dimension areas: teaching, research, international diversity, financial sustainability. The ranking has international coverage and is intended to become a tool of choice of the university for the key stakeholders of higher education: applicants, students, representatives of the academic community, university management. The RUR Rankings publisher is an independent RUR Rankings Agency, geographically located in Moscow, Russia.\nRUR is aimed to provide a transparent, comprehensive analytical system for benchmarking and evaluating universities across the borders to the widest possible audience: students, analysts, decision-makers in the field of higher education development both at individual institutional and at the national level.\nSCImago Institutions Rankings\nThe SCImago Institutions Rankings (SIR) since 2009 has published its international ranking of worldwide research institutions, the SIR World Report. The SIR World Report is the work of the SCImago Research Group, a Spain-based research organization consist of members from the Spanish National Research Council (CSIC), University of Granada, Charles III University of Madrid, University of Alcalá, University of Extremadura and other education institutions in Spain.\nThe ranking measures areas such as research output, international collaboration, normalized impact, and publication rate.\nU-Multirank\nU-Multirank, a European Commission supported feasibility study, was undertaken to contribute to the European Commission objective of enhancing transparency about the different missions and the performance of higher education institutions and research institutes. At a press conference in Brussels on 13 May 2011, the U-Multirank was officially launched by Androulla Vassiliou, Commissioner for Higher Education and Culture saying: U-Multirank \"will be useful to each participating higher education institution, as a planning and self-mapping exercise. By providing students with clearer information to guide their study choices, this is a fresh tool for more quality, relevance and transparency in European higher education.\"\nUniversity Ranking by Academic Performance\nThe University Ranking by Academic Performance, abbreviated as URAP, was developed in the Informatics Institute of Middle East Technical University. Since 2010, it has been publishing annual national and global college and university rankings for top 2000 institutions. The scientometrics measurement of URAP is based on data obtained from the Institute for Scientific Information via Web of Science and inCites. For global rankings, URAP employs indicators of research performance including the number of articles, citation, total documents, article impact total, citation impact total, and international collaboration. In addition to global rankings, URAP publishes regional rankings for universities in Turkey using additional indicators such as the number of students and faculty members obtained from Center of Measuring, Selection and Placement ÖSYM.\nU.S. News & World Report Best Global Universities Rankings\nU.S. News & World Report Best Global University Ranking}}\nU.S. News & World Report inaugural Best Global Universities ranking was launched on 28 October 2014, and it was based on data and metrics provided by Thomson Reuters, and are thus methodologically different from the criteria traditionally used by U.S. News to rank American institutions. Universities are judged on factors such as global research reputation, publications, and the number of highly cited papers. U.S. News also publishes region-specific and subject-specific global rankings based on this methodology.\nThe annual U.S. News Best Global Universities rankings were produced to provide insight into how universities compare globally. As an increasing number of students are planning to enroll in universities outside of their own country, the Best Global Universities rankings – which focus specifically on schools' academic research and reputation overall and not on their separate undergraduate or graduate programs – can help those students accurately compare institutions around the world.\nThe Best Global Universities rankings also provide insight into how U.S. universities – which U.S. News has been ranking separately for more than 30 years – stand globally. All universities can now benchmark themselves against schools in their own country and region, become more visible on the world stage and find top schools in other countries to consider collaborating with.\nThe overall Best Global Universities rankings encompass the top 750 institutions spread out across 57 countries – up from the top 500 universities in 49 countries ranked last year. The first step in producing these rankings, which are powered by Thomson Reuters InCitesTM research analytics solutions, involved creating a pool of 1,000 universities that was used to rank the top 750 schools. In comparison with U.S. News Best Colleges Ranking, the Global University Ranking is focused on the research power and faculty resources for students, while the National Ranking is only focused on undergraduate studies. Therefore, for graduate studies and international students, the Best Global Universities Ranking is a much better reference than National University Ranking.\nInside Higher Ed noted that U.S. News is entering into the international college and university rankings area that is already \"dominated by three major global university rankings\": the Times Higher Education World University Rankings, the Academic Ranking of World Universities, and the QS World University Rankings.  U.S. News' chief data strategist Robert Morse stated: \"We're well-known in the field for doing academic rankings so we thought it was a natural extension of the other rankings that we're doing.\"\nMorse pointed out that U.S. News as \"the first American publisher to enter the global rankings space\", given Times Higher Education and QS are both British, while the Academic Ranking of World universities is Chinese.\nWebometrics\nThe Webometrics Ranking of World Universities is produced by Cybermetrics Lab (CCHS), a unit of the Spanish National Research Council (CSIC), the main public research body in Spain. It offers information about more than 12,000 universities according to their web presence (an assessment of the scholarly contents, visibility, and impact of universities on the web). The ranking is updated every January and July.\nThe Webometrics Ranking or Ranking Web is built from a database of over 30,000 higher education institutions. The top 12,000 universities are shown in the main ranking and more are covered in regional lists.\nThe ranking started in 2004 and is based on a composite indicator that includes both the volume of the Web content and the visibility and impact of web publications according to the number of external links they received. A wide range of scientific activities appears exclusively on academic websites and is typically overlooked by bibliometric indicators.\nWebometric indicators measure institutional commitment to Web publication. Webometric results show a high correlation with other rankings. However, North American universities are relatively common in the top 200, while small and medium-size biomedical institutions and German, French, Italian, and Japanese universities were less common in the top ranks. Possible reasons include publishing via independent research councils (CNRS, Max Planck, CNR) or the large amount of non-English Web content, which is less likely to be linked.\nThe Three University Missions\nThe Three University Missions Moscow International University Ranking (shortly MosIUR) is produced by Association of Rating Makers, a non-commercial organization based in Moscow. The Three University Missions ranking evaluates the quality of education, scientific work, and the universities' contribution to society. The ranking uses 17 criteria divided into three groups: Education, Research, and University and Society.\nThe shortlist of the Moscow International University Ranking aims to provide the widest possible representation of the leading multi-profile universities all over the world, the quota being assigned to each country with regard to that country's contribution to the global economy. MosIUR shortlists those universities that achieved leading positions in other global university rankings and/or national academic rankings listed in IREG Inventory of National Rankings, and, in some cases, also those universities showing the highest research productivity. MosIUR does not consider narrow-focused higher education institutions.\nThe latest Moscow Ranking issue featured 1800 higher education institutions globally.\nSpecific rankings\nEduniversal\nThis university ranking is owned by the French consulting company and rating agency SMBG. It ranks masters and MBA in its 9 geographical regions (the 5 continents).\nHuman Resources & Labor Review\nThe Human Resources & Labor Review (HRLR) publishes a human competitiveness index & analysis annually by Asia First Media—now part of Destiny Media, previously ChaseCareer Network (ChaseCareer.Net). This system is based on Human Resources & Labour Review Indexes, the HRI and LRI, which measure the performance of top 300 universities' graduates.\nIn 2004, a couple of educational institutions voiced concerns at several events in regard to the accuracy and effectiveness of ranking bodies or lists. The HRLR ranking was pioneered in late 2005 within a working group in response to those concerns. The team was founded in January 2007, in London, and started compiling and processing data, resulting in the first lists in 2007–2008. The ranking concept is later being adopted for Alumni score on ARWU and many other rankings.\nThe new HRLR ranking innovative methods sparked intense interest from many institutions and inspired several other ranking lists and scoring which are based on professional, alumni, executives, competitiveness, human capital-oriented aspects. Nevertheless, HRLR remains to be the leader in university ranking with innovative and comprehensive approaches, and not relying merely on those aforementioned aspects.\nSimilarly, a study proposed two additional figures of merit that could be added to any ranking system to gauge \"administrative efficiency\" (administrative  bloat): 1) ratio of administrators to faculty members and 2) the ratio of students to administrators. Both values can be acquired from free publicly available databases  to determine if universities are preferentially investing more in administration rather than the education of their students. The concern for administrative bloat has become so large that Yale University professors have started a petition in 2025 to freeze administrative hires.\nNature Index\nThe Nature Index tracks the affiliations of high-quality scientific articles published in 68 science journals independently chosen by the scientific community as the journals scientists would most like to publish their best research in. Updated monthly, the Nature Index presents research reports of approximately 9,000 parent institutions worldwide presenting a page of output statistics for each institution along with information on institutions collaborating with the institution in the publication of Index articles. Each of the approximately 60,000 articles in the Index has a dedicated article page with social and mainstream media coverage tracked by Altmetric. League tables of the output of institutions can be generated on the fly on a global, regional, or country basis and by broad subject area as well as by article count and fractional article count. Compare with other metrics of science (e.g., Impact Factor, h-index), Nature Index is the prominent scientific journal ranking with global reputation on original natural science and life science research.\nProfessional Ranking of World Universities\nMines ParisTech: Professional Ranking of World Universities}}\nIn contrast to academic rankings, the Professional Ranking of World Universities established in 2007 by the École nationale supérieure des mines de Paris measures the efficiency of each university at producing leading business professionals. Its main compilation criterion is the number of Chief Executive Officers (or equivalent) among the Fortune Global 500. This ranking has been criticized for placing five French universities into the top 20.\nDefunct rankings\nG-factor\nG-factor ranks university and college web presence by counting the number of links only from other university websites, using Google search engine data. G-factor is an indicator of the popularity or importance of each university's website from the combined perspectives of other institutions. It claims to be an objective peer review of a university through its website—in social network theory terminology, G-factor measures the centrality of each university's website in the network of university websites.\nGlobal University Ranking\nGlobal University Ranking measures over 400 universities using the RatER, an autonomous, non-commercial, Russian rating agency supported by Russia's academic society. The methodology pools universities from ARWU, HEEACT, Times-QS and Webometrics and a pool of experts formed by project officials and managers to determine the rating scales for indicators in seven areas. It considers academic performance, research performance, faculty expertise, resource availability, socially significant activities of graduates, international activities, and international opinion. Each expert independently evaluates these performance indicators for candidate universities. The rating is the average of the expert evaluations. This ranking raised questions when it placed Russian Moscow State University in fifth place, ahead of Harvard and Cambridge.\nHigh Impact Universities: Research Performance Index\nThe High Impact Universities Research Performance Index (RPI) is a 2010 Australian initiative that studies university research performance. The pilot project involved a trial of over 1,000 universities or institutions and 5,000 constituent faculties (in various disciplines) worldwide. The top 500 results for universities and faculties were reported on the project website. The project promotes simplicity, transparency and fairness. The assessment analyzes research performance as measured by publications and citations. Publication and citation data are drawn from Scopus. The project uses standard bibliometric indicators, namely the 10-year g-index and h-index. RPI equally weighs contributions from the five faculties. The five faculty scores are normalized to place them onto a common scale. The normalized scores are then averaged to arrive at a final RPI.\nNewsweek\nIn August 2006, the American magazine Newsweek published a ranking of the Top 100 Global Universities, using selected criteria from ARWU and the Times Higher Education-QS rankings, with the additional criterion of the number of volumes in the library. It formed part of a special issue including an article from Tony Blair, then prime minister of the UK, but has not been repeated. It considered openness and diversity as well as distinction in research. The ranking has been continued since its merger with The Daily Beast, and currently uses data from the Times Higher Education World Rankings, Webometrics world college rankings from public-research outlet Consejo Superior de Investigaciones Científicas in Spain, and the Shanghai Ranking Consultancy in order to compile its results.\nRegional and national rankings\nRegional and national rankings are carried out in Africa, Asia, Europe, North America, South America and Oceania.\nAsia\nQS's Asian University Rankings use some of the same data as the QS World University Rankings alongside other material, such as the number of exchange students attending or traveling from each university. The rankings list the top 350 universities in Asia. Similarly, the THE Asia University Rankings \"use the same 13 performance indicators as the THE World University Rankings, but they are recalibrated to reflect the attributes of Asia's institutions.\"\nChina\nUniversity rankings in China are ordered by different standards and made by various organizations, including:\n* BCUR, by Shanghai Jiao Tong University\n* Wu Shulian, published in the name of the Chinese Academy of Management Science\n* Netbig, the higher education internet information company\n* CUAA, by Airuishen (a company) in the name of Chinese Universities Alumni Association, etc.\nIndia\nThe National Institutional Ranking Framework is initiated by the Ministry of Human Resource Development of the Government of India, to rank all institutions of higher education in India. Magazines such as Youth Incorporated Magazine, India Today, Outlook, Mint, The Week, Dataquest, Careers360 and Electronics For You conduct annual rankings for the major disciplines.\nJapan\nThe Times Higher Education Supplement (The Thes) is publishing Japan University Rankings once a year, using a balanced scorecard approach, with 16 individual performance indicators combining to create an overall score that reflects the broad strength of an institution. Data for the rankings come from a variety of sources. These include self-submitted data from the institutions as well as data gathered from Elsevier, Benesse Corporation, Nikkei Human Resources, the Japanese government and the Times Higher Education Academic Reputation Survey.\nOn the other hand, some of the ranking systems in Japan rank universities by the difficulty of their entrance exams, called \"Hensachi\". One example of such a ranking is Going broke universities - Disappearing universities by Kiyoshi Shimano. In addition to this, there's the other example of rankings using \"Hensachi\", GTZ. It is released by Benesse Corporation and describes to which deviation value class (S1 to D3) each university belongs.\nJapanese preparatory school Kawaijuku also released the Japan's Top 30 University Rankings in Natural Sciences and Technology for MEXT's GLOBAL 30 Project in 2001.\nPakistan\nPakistan's Higher Education Commission annually ranks domestic universities.\nPhilippines\nAcademic rankings in the Philippines are conducted by the Professional Regulation Commission and the Commission on Higher Education, based on accreditations, academic designations and the average passing rates in board tests.\nSouth Korea\nKorean Council for University Education, established in 2009, evaluates universities in South Korea.\nEurope\nEuropean Union\nThe European Commission compiled a list of the 22 universities in the EU with the highest scientific impact. This ranking was compiled as part of the Third European Report on Science & Technology Indicators, prepared by the Directorate General for Science and Research of the European Commission in 2003 (updated 2004). It only explicitly considers the European Union's top institutions, but comparisons with the rest of the world are provided in the full report. The report said, \"University College London comes out on top in both publications (the number of scientific publications produced by the university) and citations (the number of times those scientific publications are cited by other researchers)\" however the table lists the top scoring university as \"Univ London\" implying that the authors counted the scientific output of the entire University of London, rather than its constituent colleges.\nIn this ranking, the EU's top two universities were Cambridge and Oxford, as in the Jiao Tong and Times rankings. This ranking stresses the scientific quality of the institution, as opposed to its size or perceived prestige. Thus smaller, technical universities, such as Eindhoven (Netherlands) and the Technical University Munich (Germany) are ranked third and fourth, behind Cambridge, and followed by the University of Edinburgh. The report does not provide a direct comparison between EU and universities in the rest of the world, although it does compute a scientific impact score, which is measured against the world average.\nIn December 2008, the European Commission published a call for tenders, inviting bidders to design and test a new multi-dimensional university ranking system with global outreach. The first results of the envisaged pilot project were promised for the first half of 2011.\nAnother approach to classify the European research area is offered by 'European Research Ranking'. This ranking is based on publicly available data from the European Commissions project and funding database CORDIS to estimate the funding and networking performance of European research institutions.\nAustria\nSome Austrian universities, including all Austrian Universities of Applied Sciences, take part in the CHE University Ranking.\nBulgaria\nThe Bulgarian University Ranking System, maintained by the Bulgarian Ministry of Education, compares academic programs in accredited domestic higher education institutions. The system ranks programs based on more than 50 indicators, such as teaching and learning conditions, scientific research, career development opportunities, prestige, and material resources.\nDenmark\nIn Denmark, the think-tank CEPOS conduct an annual survey and ranking of higher education at study program level and institution level, based on entry salary, career development, drop-out rates, and program completion rates.\nFrance\nEduniversal provides rankings of undergraduate and graduate degrees of French universities in some areas.\nLe Nouvel Observateur occasionally offer rankings of \"Grandes écoles\" and their preparatory schools, the \"Prépas\", and of universities' undergraduate degrees in some areas. The French government also uses the Shanghai ranking as its national ranking for French universities and Grandes écoles.\nGermany\nSince 1998, the Centre for Higher Education (CHE) has published the CHE University Ranking, a comprehensive ranking of German and Austrian universities.\nThe CHE also publishes a \"ResearchRanking\" showing the research strengths of German universities. The CHE ResearchRanking is based on the research-related data of the University Ranking.\nIreland\nThe Sunday Times ranks Irish universities based on a mix of criteria, including secondary school examination scores, graduation rates, staff-student ratio, research efficiency, accommodation, nontraditional students, athletics and sports facilities.\nItaly\nEvery year, the newspaper , in collaboration with CENSIS, compiles a ranking of Italian universities.\nFurthermore, the ministerial Agency for the Evaluation of University and Research (ANVUR) publishes every five years a detailed analysis regarding the entirety of the higher education institutions in the country, with a range of grades from D to A.\nNorth Macedonia\nThe Academic Ranking of World Universities (ARWU) compiled a ranking of Macedonian Higher Education Institutions (HEIs) commissioned by the country's Ministry of Education and Science in February 2011 and released it on 16 February 2012. Nineteen qualified HEIs were included in the ranking. The ranking used 19 indicators of academic performance and competitiveness, covering major mission aspects of HEIs such as teaching, research and social service. It is the first university ranking in North Macedonia.\nNetherlands\nMost Dutch universities take part in the CHE UniversityRanking.\nPoland\nA popular ranking of Polish higher education institutions is annually published by education magazine Perspektywy.\nRomania\nThe Ad Astra association of Romanian scientists ranked Romanian universities in 2006 and 2007.\nRussian Federation\nSeveral bodies rank Russian universities, including RIA Novosti / Forbes, independent rating agency RatER, Interfax (in cooperation with Ekho Moskvy) and the Russian journal Finance.\nRIA Novosty / Forbes rankings are conducted under the supervision of Public Chamber of Russia in cooperation with State University – Higher School of Economics. This ranking is considered the most objective system. It covers 476 higher education institutions and is based on the average score of the Unified State Examination that is required to enter a university. The ranking has separate sub-rankings for different subjects and clusters of universities.\nRIA Novosty rankings do not align with other local and international rankings such as Academic Ranking of World Universities and QS World University Rankings which take into account inherited reputation from the Soviet Union.\nRatER publishes annual rankings based on representation of university graduates in governmental, education and business elite.\nInterfax annually ranks \"classical\" (or multi-faculty) universities and higher education institutions specialising in law. Interfax' methodology quantifies several qualitative factors such as research, teaching standards, public opinion and social and international activity.\nFinance produces an integrated ranking of higher education institutions specialising in economics and finance. The Journal uses the average score of the Unified State Examination, the number of CFO graduates and the consolidated turnover of companies where graduate CFOs are employed.\nSpain\nNational rankings for Spanish universities include the \"50 carreras\" (50 degrees) from the \"El Mundo\" newspaper, the CSIC or the IAIF ranking of the UCM.\nSweden\nIn Sweden, the Confederation of Swedish Enterprise (Svenskt Näringsliv) conduct an annual survey and ranking of higher education at study program level, based on entry salary, career development, internationalization, and degree of academic-business collaboration.\nSwitzerland\nThe swissUp Ranking ranked Swiss university and polytechnic students until 2004. The swissUp Ranking is no longer conducted. Some universities from the German-speaking part of Switzerland, such as ISFOA Lugano take part in the CHE UniversityRanking.\nTurkey\nThe URAP Research Laboratory of the Middle East Technical University assesses academic output of Turkish universities, as well as about 300 institutes of higher education worldwide. Their methodology focuses only on article and citation indicators in an attempt to minimize the impact of subjective data.\nUkraine\nUkraine's Ministry of Education and Science performs official yearly university evaluations. Zerkalo Nedeli newspaper published the top 200–ranked Ukrainian universities in 2007. Kyiv Student Council ranks universities on criteria of student satisfaction.\nUnited Kingdom\nThere are three major rankings of universities in the United Kingdom published by commercial companies: The Times and Sunday Times Good University Guide, The Complete University Guide and The Guardian University Guide. Since 2008, Times Higher Education has compiled a \"Table of Tables\" which combines the results of the 3 national league tables. For 2017, the top 5 universities were Cambridge University, Oxford University, University of St Andrews, and Imperial College London and Durham University in joint fourth.\nThe Research Excellence Framework was the successor to the Research Assessment Exercise in 2014. It is used by the UK government to evaluate the research quality of British universities and determine the distribution of future research funding. In 2014, the top five universities for research power as compiled by Research Fortnight were University of Oxford, University College London, University of Cambridge, University of Edinburgh and University of Manchester.\nThe Research Assessment Exercises (RAE) were the UK government's evaluation of research quality in British Universities. Each subject, called a unit of assessment, was ranked by a peer review panel. The rankings were used in the allocation of government funding. The last assessment was made in 2008. The RAE provided quality ratings for research across all disciplines. Panels used a standard scale for each submission. Ratings ranged from 1 to 5, according to the quantity of work that was judged to reach national or international levels of excellence. Participating institutions receive grants from one of the four higher education funding bodies in England, Scotland, Wales and Northern Ireland. The top three universities in the 2008 RAE exercise were London School of Economics, Cambridge University and Oxford University.\nThe Quality Assurance Agency for Higher Education (QAA) assesses undergraduate teaching. QAA is an independent body established by the UK's higher education institutions in 1997. QAA was under contract to the Higher Education Funding Council for England to assess quality for English universities. This replaced Teaching Quality Assessments (TQAs) which aimed to assess the administrative, policy and procedural framework within which teaching took place and did not directly assess teaching quality. This inspection-based system was replaced by a system of information provision, including a national student survey. QAA publishes scores which have been used by the league table industry. The first Teaching Excellence Framework is to be published in 2017; this is a rating system (giving gold, silver or bronze ratings to higher education providers) rather than a ranking as such.\nNorth America\nCanada\n''Maclean's'', a Canadian news magazine, publishes an annual ranking of Canadian universities, called the Maclean's University Rankings. Ranking criteria include student body characteristics, classes, faculty, finances, library, and reputation. The rankings are split into three categories: schools that focus on undergraduate studies with few to no graduate programs, schools that have both extensive undergraduate studies and an extensive selection of graduate programs and schools that have a professional medical program and a selection of graduate programs.\nThe University of Calgary produced a formal study examining the ranking methodology, illuminating the factors that determined its rank and criticizing certain aspects of the methodology. The University of Alberta, the University of Toronto and University of Manitoba have expressed displeasure over the ranking system.\nA notable difference between rankings in the United States and ''Maclean's rankings, however, is that Maclean's'' excludes privately funded universities. However, the majority of Canada's institutions, including the best-known, are publicly funded.\nBeginning in September 2006, over 20 Canadian universities, including several of the most prestigious and largest universities such as the University of Toronto, University of British Columbia, University of Alberta, Concordia University, McMaster University and Dalhousie University, jointly refused to participate. University of Alberta president Indira Samarasekera wrote that ''Maclean's initially filed a \"Freedom of Information\" request but that it was \"too late\" for the universities to respond. Samarasekera further stated, \"Most of [the universities] had already posted the data online, and we directed Maclean's'' staff to our Web sites. In instances where the magazine staff couldn't find data on our Web site, they chose to use the previous year's data.\"\nMexico\nEstudio Comparativo de Universidades Mexicanas\nMexican institutions have been compared in the Estudio Comparativo de Universidades Mexicanas (ECUM) produced within the Universidad Nacional Autónoma de México (UNAM). ECUM provides data on institutional participation in articles on ISI Web of Knowledge–indexed journals; faculty participation in each of Mexico's three-level National Researchers System (SNI); graduate degrees within National Council of Science and Technology's (CONACYT) register of quality graduate programs; and number of academic research bodies (cuerpos academicos) according to the Secretariat of Public Education (SEP) program PROMEP.\nECUM provides online access to data for 2007 and 2008 through ExECUM. Institutional data can be visualized through three options:\n* A selection of the most prominent 58 universities (43 publics and 13 privates). This selection accounts for more than 60 percent of undergraduate and graduate enrollments. It includes public federal universities (UNAM, Instituto Politécnico Nacional, Universidad Autónoma Metropolitana, Universidad Pedagógica Nacional, Universidad del Ejército y la Fuerza Aérea, Colegio de México, Universidad Autónoma de Chapingo, Universidad Autónoma Agraria Antonio Narro); 35 public state universities (UPES), and a group of private institutions that feature within ECUM's selected classification data.\n* Result tables for the top 20 institutions in each of the data labels in this study. These include some of the selected universities in addition to the rest of Mexico's higher education institutions, as well as institutes, centers and other research producing organizations.\n* A personalized selection from more than 600 institutions. These are classified by institutional type, institutional gatherings, by activity sector alphabetically.\nExECUM allows users to establish comparison types and levels which they consider relevant. Data is presented in raw form with virtually no derived indicators. Users can relate variables and build indicators according to their own analytical perspectives.\nBased on this comparative study project, ECUM's creator, the Dirección General de Evaluación Institucional, published reports providing an analysis of the data for 2007 and 2008.\nUnited States\nOceania\nAustralia\nThe Good Universities Guide and Excellence in Research for Australia annually rank domestic universities.\nSouth America\nQS University Rankings: Latin America\nQS Quacquarelli Symonds, in addition to their QS World University Rankings, publish an annual ranking of the top 300 universities in Latin America. The eighth instalment, released for the 2016/17 academic year, places the Universidade de São Paulo as the region's best university.\nArgentina\nIn Argentina the National Commission for University Evaluation and Accreditation ranks higher education programs by evaluation and accreditation.\nBrazil\nThe latest ranking, the [http://ruf.folha.uol.com.br/rankings/rankingdeuniversidades/ Ranking Universitário Folha (RUF)] website (in Portuguese), was created by the newspaper . This ranking is based on the combination of four indicators: education quality, research quality, market assessment and an innovation indicator.\nChile\nIn Chile the \"Comisión Nacional de Acreditación\" (National Commission of Accreditation of the Universities) manages evaluation and accreditation. It also ranks universities according to accreditation levels. Other commercial rankings are made by research magazines, including Qué Pasa and América Economía. ''Qué Pasa's ranking evaluates perception and quality following surveys of approximately 1,000 employers across the country. América Economía'' ranking considers quality of students, quality of teachers, rating of professors by student, research productivity, internationalization, integration with the community, student life quality and inclusion of students from lower social strata.\nSee also\n* MBA Programme rankings\nSources\nNotes and references"
    }
  ]
}