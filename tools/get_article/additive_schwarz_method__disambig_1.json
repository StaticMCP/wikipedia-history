{
  "content": [
    {
      "type": "text",
      "text": "# Additive Schwarz method__disambig_1\n\nIn mathematics, the additive Schwarz method, named after Hermann Schwarz, solves a boundary value problem for a partial differential equation approximately by splitting it into boundary value problems on smaller domains and adding the results.\nOverview\nPartial differential equations (PDEs) are used in all sciences to model phenomena. For the purpose of exposition, we give an example physical problem and the accompanying boundary value problem (BVP). Even if the reader is unfamiliar with the notation, the purpose is merely to show what a BVP looks like when written down.\n{{block indent | em = 1.5 | text =\n(Model problem) The heat distribution in a square metal plate such that the left edge is kept at 1 degree, and the other edges are kept at 0 degree, after letting it sit for a long period of time satisfies the following boundary value problem:\n\\begin{align}\n&f_{xx}(x,y) + f_{yy}(x,y) = 0 \\\\\n&f(0,y) = 1; \\; f(x,0) = f(x,1) = f(1,y) = 0\n\\end{align}\nwhere  is the unknown function,  and  denote the second partial derivatives with respect to  and , respectively.\n}}\nHere, the domain is the square .\nThis particular problem can be solved exactly on paper, so there is no need for a computer. However, this is an exceptional case, and most BVPs cannot be solved exactly. The only possibility is to use a computer to find an approximate solution.\nSolving on a computer\nA typical way of doing this is to sample  at regular intervals in the square . For instance, we could take 8 samples in the  direction at , and 8 samples in the  direction at similar coordinates. We would then have 64 samples of the square, at places like (0.2,0.8) and (0.6,0.6). The goal of the computer program would be to calculate the value of  at those 64 points, which seems easier than finding an abstract function of the square.\nThere are some difficulties, for instance it is not possible to calculate  knowing f at only 64 points in the square. To overcome this, one uses some sort of numerical approximation of the derivatives, see for instance the finite element method or finite differences. We ignore these difficulties and concentrate on another aspect of the problem.\nSolving linear problems\nWhichever method we choose to solve this problem, we will need to solve a large linear system of equations. The reader may recall linear systems of equations from high school, they look like this:\n}}\n6a - 3b = -3\nThis is a system of 2 equations in 2 unknowns ( and ). If we solve the BVP above in the manner suggested, we will need to solve a system of 64 equations in 64 unknowns. This is not a hard problem for modern computers, but if we use a larger number of samples, even modern computers cannot solve the BVP very efficiently.\nDomain decomposition\nWhich brings us to domain decomposition methods. If we split the domain  into two subdomains  and , each has only half of the sample points. So we can try to solve a version of our model problem on each subdomain, but this time each subdomain has only 32 sample points. Finally, given the solutions on each subdomain, we can attempt to reconcile them to obtain a solution of the original problem on .\nSize of the problems\nIn terms of the linear systems, we're trying to split the system of 64 equations in 64 unknowns into two systems of 32 equations in 32 unknowns. This would be a clear gain, for the following reason. Looking back at system , we see that there are 6 important pieces of information. They are the coefficients of a and b (2,5 on the first line and 6,−3 on the second line), and the right hand side (which we write as 12,−3). On the other hand, if we take two \"systems\" of 1 equation in 1 unknown, it might look like this:\n2a = 12\n-3b = -3\nWe see that this system has only 4 important pieces of information. This means that a computer program will have an easier time solving two 1×1 systems than solving a single 2×2 system, because the pair of 1×1 systems are simpler than the single 2×2 system. While the 64×64 and 32×32 systems are too large to illustrate here, we could say by analogy that the 64×64 system has 4160 pieces of information, while the 32×32 systems each have 1056, or roughly a quarter of the 64×64 system.\nDomain decomposition algorithm\nUnfortunately, for technical reasons it is usually not possible to split our grid of 64 points (a 64×64 system of linear equations) into two grids of 32 points (two 32×32 systems of linear equations) and obtain an answer to the 64×64 system. Instead, the following algorithm is what actually happens:\n# Begin with an approximate solution of the 64×64 system.\n# From the 64×64 system, create two 32×32 systems to improve the approximate solution.\n# Solve the two 32×32 systems.\n# Put the two 32×32 solutions \"together\" to improve the approximate solution to the 64×64 system.\n# If the solution isn't very good yet, repeat from 2.\nThere are two ways in which this can be better than solving the base 64×64 system. First, if the number of repetitions of the algorithm is small, solving two 32×32 systems may be more efficient than solving a 64×64 system. Second, the two 32×32 systems need not be solved on the same computer, so this algorithm can be run in parallel to use the power of multiple computers.\nIn fact, solving two 32×32 systems instead of a 64×64 system on a single computer (without using parallelism) is unlikely to be efficient. However, if we use more than two subdomains, the picture can change. For instance, we could use four 16×16 problems, and there's a chance that solving these will be better than solving a single 64×64 problem even if the domain decomposition algorithm needs to iterate a few times.\nA technical example\nHere we assume that the reader is familiar with partial differential equations.\nWe will be solving the partial differential equation\n{{NumBlk||u_{xx} + u_{yy} = f|}}\nWe impose boundedness at infinity.\nWe decompose the domain  into two overlapping subdomains  × R}} and  × R}}. In each subdomain, we will be solving a BVP of the form:\n\\begin{align}\nu_{xx}^{(j)} + u_{yy}^{(j)} &= f \\;\\; \\text{ in } H_j \\\\\nu^{(j)}(x_j, y) &= g(y)\n\\end{align}\nwhere  and  and taking boundedness at infinity as the other boundary condition. We denote the solution  of the above problem by . Note that  is bilinear.\nThe Schwarz algorithm proceeds as follows:\n#Start with approximate solutions  and  of the PDE in subdomains  and  respectively. Initialize  to 0.\n#Calculate  with .\n#Increase  by one and repeat 2 until sufficient precision is achieved.\nSee also\n*Domain decomposition method\n*Schwarz alternating method\nReferences\n*\n*\nExternal links\n* [http://www.ddm.org The official Domain Decomposition Methods page]"
    }
  ]
}