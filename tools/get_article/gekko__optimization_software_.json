{
  "content": [
    {
      "type": "text",
      "text": "# Gekko (optimization software)\n\n| operating_system       =\n| genre                  = Technical computing\n| license                = MIT\n| website                =\n}}\nThe GEKKO Python package solves large-scale mixed-integer and differential algebraic equations with nonlinear programming solvers (IPOPT, APOPT, BPOPT, SNOPT, MINOS). Modes of operation include machine learning, data reconciliation, real-time optimization, dynamic simulation, and nonlinear model predictive control. In addition, the package solves Linear programming (LP), Quadratic programming (QP), Quadratically constrained quadratic program (QCQP), Nonlinear programming (NLP), Mixed integer programming (MIP), and Mixed integer linear programming (MILP). GEKKO is available in Python and installed with pip from PyPI of the Python Software Foundation.\npip install gekko\nGEKKO works on all platforms and with Python 2.7 and 3+. By default, the problem is sent to a public server where the solution is computed and returned to Python. There are Windows, MacOS, Linux, and ARM (Raspberry Pi) processor options to solve without an Internet connection. GEKKO is an extension of the APMonitor Optimization Suite but has integrated the modeling and solution visualization directly within Python. A mathematical model is expressed in terms of variables and equations such as the Hock & Schittkowski Benchmark Problem #71 used to test the performance of nonlinear programming solvers. This particular optimization problem has an objective function \\min_{x\\in\\mathbb R}\\; x_1 x_4 (x_1+x_2+x_3)+x_3 and subject to the inequality constraint x_1 x_2 x_3 x_4 \\ge 25 and equality constraint {x_1}^2 + {x_2}^2 + {x_3}^2 + {x_4}^2=40. The four variables must be between a lower bound of 1 and an upper bound of 5. The initial guess values are x_1 = 1, x_2=5, x_3=5, x_4=1. This optimization problem is solved with GEKKO as shown below.\nfrom gekko import GEKKO\nm = GEKKO()  # Initialize gekko\n# Initialize variables\nx1 = m.Var(value=1, lb=1, ub=5)\nx2 = m.Var(value=5, lb=1, ub=5)\nx3 = m.Var(value=5, lb=1, ub=5)\nx4 = m.Var(value=1, lb=1, ub=5)\n# Equations\nm.Equation(x1 * x2 * x3 * x4 >= 25)\nm.Equation(x1 ** 2 + x2 ** 2 + x3 ** 2 + x4 ** 2 == 40)\nm.Minimize(x1 * x4 * (x1 + x2 + x3) + x3)\nm.solve(disp=False)  # Solve\nprint(\"x1: \" + str(x1.value))\nprint(\"x2: \" + str(x2.value))\nprint(\"x3: \" + str(x3.value))\nprint(\"x4: \" + str(x4.value))\nprint(\"Objective: \" + str(m.options.objfcnval))\nApplications of GEKKO\nApplications include cogeneration (power and heat), drilling automation, severe slugging control, solar thermal energy production, solid oxide fuel cells, flow assurance, Enhanced oil recovery, Essential oil extraction, and Unmanned Aerial Vehicles (UAVs). There are many other references to APMonitor and GEKKO as a sample of the types of applications that can be solved. GEKKO is developed from the National Science Foundation (NSF) research grant #1547110  and is detailed in a Special Issue collection on combined scheduling and control. Other notable mentions of GEKKO are the listing in the Decision Tree for Optimization Software, added support for APOPT and BPOPT solvers, projects reports of the online Dynamic Optimization course from international participants. GEKKO is a topic in online forums where users are solving optimization and optimal control problems. GEKKO is used for advanced control in the Temperature Control Lab (TCLab) for process control education at 20 universities.\nMachine learning\nOne application of machine learning is to perform regression from training data to build a correlation. In this example, deep learning generates a model from training data that is generated with the function 1-\\cos(x). An artificial neural network with three layers is used for this example. The first layer is linear, the second layer has a hyperbolic tangent activation function, and the third layer is linear. The program produces parameter weights that minimize the sum of squared errors between the measured data points and the neural network predictions at those points. GEKKO uses gradient-based optimizers to determine the optimal weight values instead of standard methods such as backpropagation. The gradients are determined by automatic differentiation, similar to other popular packages. The problem is solved as a constrained optimization problem and is converged when the solver satisfies Karush–Kuhn–Tucker conditions. Using a gradient-based optimizer allows additional constraints that may be imposed with domain knowledge of the data or system.\nfrom gekko import brain\nimport numpy as np\nb = brain.Brain()\nb.input_layer(1)\nb.layer(linear=3)\nb.layer(tanh=3)\nb.layer(linear=3)\nb.output_layer(1)\nx = np.linspace(-np.pi, 3 * np.pi, 20)\ny = 1 - np.cos(x)\nb.learn(x, y)\nThe neural network model is tested across the range of training data as well as for extrapolation to demonstrate poor predictions outside of the training data. Predictions outside the training data set are improved with hybrid machine learning that uses fundamental principles (if available) to impose a structure that is valid over a wider range of conditions. In the example above, the hyperbolic tangent activation function (hidden layer 2) could be replaced with a sine or cosine function to improve extrapolation. The final part of the script displays the neural network model, the original function, and the sampled data points used for fitting.\nimport matplotlib.pyplot as plt\nxp = np.linspace(-2 * np.pi, 4 * np.pi, 100)\nyp = b.think(xp)\nplt.figure()\nplt.plot(x, y, \"bo\")\nplt.plot(xp, yp[0], \"r-\")\nplt.show()\nOptimal control\nOptimal control is the use of mathematical optimization to obtain a policy that is constrained by differential \\left(\\frac{d\\,x_1}{d\\,t}=u\\right), equality \\left(x_1(0) = 1\\right), or inequality \\left(-1 \\le u(t) \\le 1\\right) equations and minimizes an objective/reward function \\left(\\min_u \\frac{1}{2} \\int_0^2 x_1^2(t) \\, dt\\right). The basic optimal control is solved with GEKKO by integrating the objective and transcribing the differential equation into algebraic form with orthogonal collocation on finite elements.\nfrom gekko import GEKKO\nimport numpy as np\nimport matplotlib.pyplot as plt\nm = GEKKO()  # initialize gekko\nnt = 101\nm.time = np.linspace(0, 2, nt)\n# Variables\nx1 = m.Var(value=1)\nx2 = m.Var(value=0)\nu = m.Var(value=0, lb=-1, ub=1)\np = np.zeros(nt)  # mark final time point\np[-1] = 1.0\nfinal = m.Param(value=p)\n# Equations\nm.Equation(x1.dt()  u)\nm.Equation(x2.dt()  0.5 * x1 ** 2)\nm.Minimize(x2 * final)\nm.options.IMODE = 6  # optimal control mode\nm.solve()  # solve\nplt.figure(1)  # plot results\nplt.plot(m.time, x1.value, \"k-\", label=r\"$x_1$\")\nplt.plot(m.time, x2.value, \"b-\", label=r\"$x_2$\")\nplt.plot(m.time, u.value, \"r--\", label=r\"$u$\")\nplt.legend(loc=\"best\")\nplt.xlabel(\"Time\")\nplt.ylabel(\"Value\")\nplt.show()\nSee also\n* APMonitor and Python.\nReferences\nExternal links\n* [https://apmonitor.com/gekko GEKKO Overview with Machine Learning and Optimization]\n* [https://gekko.readthedocs.io/en/latest/ GEKKO Documentation]\n* [https://github.com/BYU-PRISM/GEKKO GEKKO Source Code]\n* [https://pypi.org/project/gekko GEKKO on PyPI] for Python pip install\n* GEKKO is open-source product of [https://www.nsf.gov/awardsearch/showAward?AWD_ID=1547110 National Science Foundation (NSF) research grant 1547110]\n* [http://apmonitor.com/wiki/index.php/Main/APMonitorReferences References to APMonitor and GEKKO] in the literature\n* [https://apmonitor.com/wiki/index.php/Main/GekkoPythonOptimization 18 examples of GEKKO]: machine learning, optimal control, data regression\n* [https://pypistats.org/packages/gekko Gekko Download Statistics]"
    }
  ]
}