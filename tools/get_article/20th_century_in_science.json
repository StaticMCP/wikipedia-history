{
  "content": [
    {
      "type": "text",
      "text": "# 20th century in science\n\nScience advanced dramatically during the 20th century. There were new and radical developments in the physical, life and human sciences, building on the progress made in the 19th century.\nThe development of post-Newtonian theories in physics, such as special relativity, general relativity, and quantum mechanics led to the development of nuclear weapons.  New models of the structure of the atom led to developments in theories of chemistry and the development of new materials such as nylon and plastics.  Advances in biology led to large increases in food production, as well as the elimination of diseases such as polio.\nA massive amount of new technologies were developed in the 20th century.  Technologies such as electricity, the incandescent light bulb, the automobile and the phonography, first developed at the end of the 19th century, were perfected and universally deployed.  The first airplane flight occurred in 1903, and by the end of the century large airplanes such as the Boeing 777 and Airbus A330 flew thousands of miles in a matter of hours.  The development of the television and computers caused massive changes in the dissemination of information.\nAstronomy and spaceflight\nduring the first moonwalk in 1969. The relatively young aerospace engineering industries rapidly grew in the 66 years after the Wright brothers first flight.]]\n* A much better understanding of the evolution of the universe was achieved, its age (about 13.8 billion years) was determined, and the Big Bang theory on its origin was proposed and generally accepted.\n* The age of the Solar System, including Earth, was determined, and it turned out to be much older than believed earlier: more than 4&nbsp;billion years, rather than the 20 million years suggested by Lord Kelvin in 1862.\n* The planets of the Solar System and their moons were closely observed via numerous space probes. Pluto was discovered in 1930 on the edge of the Solar System, although in the early 21st century, it was reclassified as a dwarf planet (planetoid) instead of a planet proper, leaving eight planets.\n* No trace of life was discovered on any of the other planets in the Solar System, although it remained undetermined whether some forms of primitive life might exist, or might have existed, somewhere. Extrasolar planets were observed for the first time.\n* In 1969, Apollo 11 was launched towards the Moon and Neil Armstrong and Buzz Aldrin became the first persons from Earth to walk on another celestial body.\n* That same year, Soviet astronomer Victor Safronov published his book Evolution of the protoplanetary cloud and formation of the Earth and the planets. In this book, almost all major problems of the planetary formation process were formulated and some of them solved. Safronov's ideas were further developed in the works of George Wetherill, who discovered runaway accretion.\n* The Space Race between the United States and the Soviet Union gave a peaceful outlet to the political and military tensions of the Cold War, leading to the first human spaceflight with the Soviet Union's Vostok 1 mission in 1961, and man's first landing on another world&mdash;the Moon&mdash;with America's Apollo 11 mission in 1969. Later, the first space station was launched by the Soviet space program. The United States developed the first (and to date only) reusable spacecraft system with the Space Shuttle program, first launched in 1981. As the century ended, a permanent human presence in space was being founded with the ongoing construction of the International Space Station.\n* In addition to human spaceflight, uncrewed space probes became a practical and relatively inexpensive form of exploration. The first orbiting space probe, Sputnik 1, was launched by the Soviet Union in 1957. Over time, a massive system of artificial satellites was placed into orbit around Earth. These satellites greatly advanced navigation, communications, military intelligence, geology, climate, and numerous other fields. Also, by the end of the 20th century, uncrewed probes had visited the Moon, Mercury, Venus, Mars, Jupiter, Saturn, Uranus, Neptune, and various asteroids and comets. The Hubble Space Telescope, launched in 1990, greatly expanded the understanding of the Universe and brought brilliant images to TV and computer screens around the world.\nBiology and medicine\n. His discovery of penicillin had changed the world of modern medicine by introducing the age of antibiotics.]]\n* Genetics was unanimously accepted and significantly developed. The structure of DNA was determined in 1953 by James Watson, Francis Crick, Rosalind Franklin and Maurice Wilkins, following by developing techniques which allow to read DNA sequences and culminating in starting the Human Genome Project (not finished in the 20th century) and cloning the first mammal in 1996.\n* The role of sexual reproduction in evolution was understood, and bacterial conjugation was discovered.\n* The convergence of various sciences for the formulation of the modern evolutionary synthesis (produced between 1936 and 1947), providing a widely accepted account of evolution.\n* Placebo-controlled, randomized, blinded clinical trials became a powerful tool for testing new medicines.\n* Antibiotics drastically reduced mortality from bacterial diseases and their prevalence.\n* A vaccine was developed for polio, ending a worldwide epidemic.  Effective vaccines were also developed for a number of other serious infectious diseases, including influenza, diphtheria, pertussis (whooping cough), tetanus, measles, mumps, rubella (German measles), chickenpox, hepatitis A, and hepatitis B.\n* Epidemiology and vaccination led to the eradication of the smallpox virus in humans.\n* X-rays became powerful diagnostic tool for wide spectrum of diseases, from bone fractures to cancer.  In the 1960s, computerized tomography was invented.  Other important diagnostic tools developed were sonography and magnetic resonance imaging.\n* Development of vitamins virtually eliminated scurvy and other vitamin-deficiency diseases from industrialized societies.\n* New psychiatric drugs were developed.  These include antipsychotics for treating hallucinations and delusions, and antidepressants for treating depression.\n* The role of tobacco smoking in the causation of cancer and other diseases was proven during the 1950s (see British Doctors Study).\n* New methods for cancer treatment, including chemotherapy, radiation therapy, and immunotherapy, were developed. As a result, cancer could often be cured or placed in remission.\n* The development of blood typing and blood banking made blood transfusion safe and widely available.\n* The invention and development of immunosuppressive drugs and tissue typing made organ and tissue transplantation a clinical reality.\n* New methods for heart surgery were developed, including pacemakers and artificial hearts.\n* Cocaine/crack and heroin were found to be dangerous addictive drugs, and their wide usage had been outlawed; mind-altering drugs such as LSD and MDMA were discovered and later outlawed. In many countries, a war on drugs caused prices to soar 10–20 times higher, leading to profitable black market drug dealing, and in some countries (e.g. the United States) to prison inmate sentences being 80% related to drug use by the 1990s.\n* Contraceptive drugs were developed, which reduced population growth rates in industrialized countries, as well as decreased the taboo of premarital sex throughout many western countries.\n* The development of medical insulin during the 1920s helped raise the life expectancy of diabetics to three times of what it had been earlier.\n* Vaccines, hygiene and clean water improved health and decreased mortality rates, especially among infants and the young.\nNotable diseases\n* An influenza pandemic, Spanish Flu, killed anywhere from 20 to 100 million people between 1918 and 1919.\n* A new viral disease, called the Human Immunodeficiency Virus, or HIV, arose in Africa and subsequently killed millions of  people throughout the world. HIV leads to a syndrome called Acquired Immunodeficiency Syndrome, or AIDS. Treatments for HIV remained inaccessible to many people living with AIDS and HIV in developing countries, and a cure has yet to be discovered.\n* Because of increased life spans, the prevalence of cancer, Alzheimer's disease, Parkinson's disease, and other diseases of old age increased slightly.\n* Sedentary lifestyles, due to labour-saving devices and technology, along with the increase in home entertainment and technology such as television, video games, and the internet contributed to an \"epidemic\" of obesity, at first in the rich countries, but by the end of the 20th century spreading to the developing world.\nChemistry\nwas held in Brussels in 1911 and was considered a turning point in the world of physics and chemistry.]]\nIn 1903, Mikhail Tsvet invented chromatography, an important analytic technique. In 1904, Hantaro Nagaoka proposed an early nuclear model of the atom, where electrons orbit a dense massive nucleus. In 1905, Fritz Haber and Carl Bosch developed the Haber process for making ammonia, a milestone in industrial chemistry with deep consequences in agriculture. The Haber process, or Haber-Bosch process, combined nitrogen and hydrogen to form ammonia in industrial quantities for production of fertilizer and munitions. The food production for half the world's current population depends on this method for producing fertilizer. Haber, along with Max Born, proposed the Born–Haber cycle as a method for evaluating the lattice energy of an ionic solid. Haber has also been described as the \"father of chemical warfare\" for his work developing and deploying chlorine and other poisonous gases during World War I.\n, who is best known for measuring the charge on the electron, won the Nobel Prize in Physics in 1923.]]\nIn 1905, Albert Einstein explained Brownian motion in a way that definitively proved atomic theory. Leo Baekeland invented bakelite, one of the first commercially successful plastics. In 1909, American physicist Robert Andrews Millikan – who had studied in Europe under Walther Nernst and Max Planck – measured the charge of individual electrons with unprecedented accuracy through the oil drop experiment, in which he measured the electric charges on tiny falling water (and later oil) droplets. His study established that any particular droplet's electrical charge is a multiple of a definite, fundamental value – the electron's charge – and thus a confirmation that all electrons have the same charge and mass. Beginning in 1912, he spent several years investigating and finally proving Albert Einstein's proposed linear relationship between energy and frequency, and providing the first direct photoelectric support for the Planck constant. In 1923 Millikan was awarded the Nobel Prize for Physics.\nIn 1909, S. P. L. Sørensen invented the pH concept and develops methods for measuring acidity. In 1911, Antonius Van den Broek proposed the idea that the elements on the periodic table are more properly organized by positive nuclear charge rather than atomic weight. In 1911, the first Solvay Conference was held in Brussels, bringing together most of the most prominent scientists of the day. In 1912, William Henry Bragg and William Lawrence Bragg proposed Bragg's law and established the field of X-ray crystallography, an important tool for elucidating the crystal structure of substances. In 1912, Peter Debye develops the concept of molecular dipole to describe asymmetric charge distribution in some molecules.\nIn 1913, Niels Bohr, a Danish physicist, introduced the concepts of quantum mechanics to atomic structure by proposing what is now known as the Bohr model of the atom, where electrons exist only in strictly defined circular orbits around the nucleus similar to rungs on a ladder. The Bohr Model is a planetary model in which the negatively charged electrons orbit a small, positively charged nucleus similar to the planets orbiting the Sun (except that the orbits are not planar) – the gravitational force of the solar system is mathematically akin to the attractive Coulomb (electrical) force between the positively charged nucleus and the negatively charged electrons.\nIn 1913, Henry Moseley, working from Van den Broek's earlier idea, introduces concept of atomic number to fix inadequacies of Mendeleev's periodic table, which had been based on atomic weight. The peak of Frederick Soddy's career in radiochemistry was in 1913 with his formulation of the concept of isotopes, which stated that certain elements exist in two or more forms which have different atomic weights but which are indistinguishable chemically. He is remembered for proving the existence of isotopes of certain radioactive elements, and is also credited, along with others, with the discovery of the element protactinium in 1917. In 1913, J. J. Thomson expanded on the work of Wien by showing that charged subatomic particles can be separated by their mass-to-charge ratio, a technique known as mass spectrometry.\nIn 1916, Gilbert N. Lewis published his seminal article \"The Atom of the Molecule\", which suggested that a chemical bond is a pair of electrons shared by two atoms. Lewis's model equated the classical chemical bond with the sharing of a pair of electrons between the two bonded atoms. Lewis introduced the  \"electron dot diagrams\" in this paper to symbolize the electronic structures of atoms and molecules. Now known as Lewis structures, they are discussed in virtually every introductory chemistry book. Lewis in 1923 developed the electron pair theory of acids and base: Lewis redefined an acid as any atom or molecule with an incomplete octet that was thus capable of accepting electrons from another atom; bases were, of course, electron donors. His theory is known as the concept of Lewis acids and bases. In 1923, G. N. Lewis and Merle Randall published Thermodynamics and the Free Energy of Chemical Substances, first modern treatise on chemical thermodynamics.\nThe 1920s saw a rapid adoption and application of Lewis's model of the electron-pair bond in the fields of organic and coordination chemistry. In organic chemistry, this was primarily due to the efforts of the British chemists Arthur Lapworth, Robert Robinson, Thomas Lowry, and Christopher Ingold; while in coordination chemistry, Lewis's bonding model was promoted through the efforts of the American chemist Maurice Huggins and the British chemist Nevil Sidgwick.\nQuantum chemistry\nSome view the birth of quantum chemistry in the discovery of the Schrödinger equation and its application to the hydrogen atom in 1926.  However, the 1927 article of Walter Heitler and Fritz London is often recognised as the first milestone in the history of quantum chemistry. This is the first application of quantum mechanics to the diatomic hydrogen molecule, and thus to the phenomenon of the chemical bond. In the following years much progress was accomplished by Edward Teller, Robert S. Mulliken, Max Born, J. Robert Oppenheimer, Linus Pauling, Erich Hückel, Douglas Hartree, Vladimir Aleksandrovich Fock, to cite a few.\nStill, skepticism remained as to the general power of quantum mechanics applied to complex chemical systems. The situation around 1930 is described by Paul Dirac:\nHence the quantum mechanical methods developed in the 1930s and 1940s are often referred to as theoretical molecular or atomic physics to underline the fact that they were more the application of quantum mechanics to chemistry and spectroscopy than answers to chemically relevant questions. In 1951, a milestone article in quantum chemistry is the seminal paper of Clemens C. J. Roothaan on Roothaan equations.  It opened the avenue to the solution of the self-consistent field equations for small molecules like hydrogen or nitrogen.  Those computations were performed with the help of tables of integrals which were computed on the most advanced computers of the time.\nIn the 1940s many physicists turned from molecular or atomic physics to nuclear physics (like J. Robert Oppenheimer or Edward Teller). Glenn T. Seaborg was an American nuclear chemist best known for his work on isolating and identifying transuranium elements (those heavier than uranium). He shared the 1951 Nobel Prize for Chemistry with Edwin Mattison McMillan for their independent discoveries of transuranium elements. Seaborgium was named in his honour, making him one of three people, along Albert Einstein and Yuri Oganessian, for whom a chemical element was named during his lifetime.\nMolecular biology and biochemistry\nBy the mid 20th century, in principle, the integration of physics and chemistry was extensive, with chemical properties explained as the result of the electronic structure of the atom; Linus Pauling's book on The Nature of the Chemical Bond used the principles of quantum mechanics to deduce bond angles in ever-more complicated molecules.  However, though some principles deduced from quantum mechanics were able to predict qualitatively some chemical features for biologically relevant molecules, they were, till the end of the 20th century, more a collection of rules, observations, and recipes than rigorous ab initio quantitative methods.\nThis heuristic approach triumphed in 1953 when James Watson and Francis Crick deduced the double helical structure of DNA by constructing models constrained by and informed by the knowledge of the chemistry of the constituent parts and the X-ray diffraction patterns obtained by Rosalind Franklin.  This discovery lead to an explosion of research into the biochemistry of life.\nIn the same year, the Miller–Urey experiment, conducted by Stanley Miller and Harold Urey demonstrated that basic constituents of protein, simple amino acids, could themselves be built up from simpler molecules in a simulation of primordial processes on Earth.  Though many questions remain about the true nature of the origin of life, this was the first attempt by chemists to study hypothetical processes in the laboratory under controlled conditions.[https://www.windows2universe.org/earth/Life/miller_urey.html#:~:text=In%20the%201950's%2C%20biochemists%20Stanley,conditions%20of%20Earth's%20early%20atmosphere. The Miller Urey Experiment – Windows to the Universe]\nIn 1983 Kary Mullis devised a method for the in-vitro amplification of DNA, known as the polymerase chain reaction (PCR), which revolutionized the chemical processes used in the laboratory to manipulate it.  PCR could be used to synthesize specific pieces of DNA and made possible the sequencing of DNA of organisms, which culminated in the extensive Human Genome Project.\nAn important piece in the double helix puzzle was solved by one of Pauling's students Matthew Meselson and Frank Stahl, the result of their collaboration (Meselson–Stahl experiment) has been called as \"the most beautiful experiment in biology\".\nThey used a centrifugation technique that sorted molecules according to differences in weight. Because nitrogen atoms are a component of DNA, they were labelled and therefore tracked in replication in bacteria.\nLate 20th century\nIn 1970, John Pople developed the Gaussian program greatly easing computational chemistry calculations. In 1971, Yves Chauvin offered an explanation of the reaction mechanism of olefin metathesis reactions. In 1975, Karl Barry Sharpless and his group discovered a stereoselective oxidation reactions including Sharpless epoxidation, Sharpless asymmetric dihydroxylation, and Sharpless oxyamination.\nIn 1985, Harold Kroto, Robert Curl and Richard Smalley discovered fullerenes, a class of large carbon molecules superficially resembling the geodesic dome designed by architect R. Buckminster Fuller. In 1991, Sumio Iijima used electron microscopy to discover a type of cylindrical fullerene known as a carbon nanotube, though earlier work had been done in the field as early as 1951.  This material is an important component in the field of nanotechnology. In 1994, Robert A. Holton and his group achieved the first total synthesis of Taxol. In 1995, Eric Cornell and Carl Wieman produced the first Bose–Einstein condensate, a substance that displays quantum mechanical properties on the macroscopic scale.\nEarth science\nIn 1912 Alfred Wegener proposed the theory of Continental Drift.  This theory suggests that the shapes of continents and matching coastline geology between some continents indicates they were joined in the past and formed a single landmass known as Pangaea; thereafter they separated and drifted like rafts over the ocean floor, currently reaching their present position. Additionally, the theory of continental drift offered a possible explanation as to the formation of mountains; Plate Tectonics built on the theory of continental drift.\nUnfortunately, Wegener provided no convincing mechanism for this drift, and his ideas were not generally accepted during his lifetime. Arthur Homes accepted Wegener's theory and provided a mechanism: mantle convection, to cause the continents to move. However, it was not until after the Second World War that new evidence started to accumulate that supported continental drift. There followed a period of 20 extremely exciting years where the Theory of Continental Drift developed from being believed by a few to being the cornerstone of modern Geology. Beginning in 1947 research  found new evidence about the ocean floor, and in 1960 Bruce C. Heezen published the concept of mid-ocean ridges. Soon after this, Robert S. Dietz and Harry H. Hess proposed that the oceanic crust forms as the seafloor spreads apart along mid-ocean ridges in seafloor spreading. This was seen as confirmation of mantle convection and so the major stumbling block to the theory was removed. Geophysical evidence suggested lateral motion of continents and that oceanic crust is younger than continental crust. This geophysical evidence also spurred the hypothesis of paleomagnetism, the record of the orientation of the Earth's magnetic field recorded in magnetic minerals. British geophysicist S. K. Runcorn suggested the concept of paleomagnetism from his finding that the continents had moved relative to the Earth's magnetic poles. Tuzo Wilson, who was a promoter of the sea floor spreading hypothesis and continental drift from the very beginning, added the concept of transform faults to the model, completing the classes of fault types necessary to make the mobility of the plates on the globe function. A symposium on continental drift  was held at the Royal Society of London in 1965  must be regarded as the official start of the acceptance of plate tectonics by the scientific community. The abstracts from the symposium are issued as Blacket, Bullard, Runcorn;1965.In this symposium, Edward Bullard and co-workers showed with a computer calculation how the continents along both sides of the Atlantic would best fit to close the ocean, which became known as the famous \"Bullard's Fit\". By the late 1960s the weight of the evidence available saw Continental Drift as the generally accepted theory.\nOther theories of the causes of climate change fared no better. The principal advances were in observational paleoclimatology, as scientists in various fields of geology worked out methods to reveal ancient climates.  Wilmot H. Bradley found that annual varves of clay laid down in lake beds showed climate cycles. Andrew Ellicott Douglass saw strong indications of climate change in tree rings. Noting that the rings were thinner in dry years, he reported climate effects from solar variations, particularly in connection with the 17th-century dearth of sunspots (the Maunder Minimum) noticed previously by William Herschel and others. Other scientists, however, found good reason to doubt that tree rings could reveal anything beyond random regional variations. The value of tree rings for climate study was not solidly established until the 1960s.\nThrough the 1930s the most persistent advocate of a solar-climate connection was astrophysicist Charles Greeley Abbot. By the early 1920s, he had concluded that the solar \"constant\" was misnamed: his observations showed large variations, which he connected with sunspots passing across the face of the Sun. He and a few others pursued the topic into the 1960s, convinced that sunspot variations were a main cause of climate change. Other scientists were skeptical. Nevertheless, attempts to connect the solar cycle with climate cycles were popular in the 1920s and 1930s. Respected scientists announced correlations that they insisted were reliable enough to make predictions. Sooner or later, every prediction failed, and the subject fell into disrepute.\nMeanwhile Milutin Milankovitch, building on James Croll's theory, improved the tedious calculations of the varying distances and angles of the Sun's radiation as the Sun and Moon gradually perturbed the Earth's orbit. Some observations of varves (layers seen in the mud covering the bottom of lakes) matched the prediction of a Milankovitch cycle lasting about 21,000 years. However, most geologists dismissed the astronomical theory. For they could not fit Milankovitch's timing to the accepted sequence, which had only four ice ages, all of them much longer than 22,000 years.\nIn 1938 Guy Stewart Callendar attempted to revive Arrhenius's greenhouse-effect theory. Callendar presented evidence that both temperature and the  level in the atmosphere had been rising over the past half-century, and he argued that newer spectroscopic measurements showed that the gas was effective in absorbing infrared in the atmosphere. Nevertheless, most scientific opinion continued to dispute or ignore the theory.\nfrom George W. Bush, in 2001]]\nAnother clue to the nature of climate change came in the mid-1960s from analysis of deep-sea cores by Cesare Emiliani and analysis of ancient corals by Wallace Broecker and collaborators. Rather than four long ice ages, they found a large number of shorter ones in a regular sequence. It appeared that the timing of ice ages was set by the small orbital shifts of the Milankovitch cycles. While the matter remained controversial, some began to suggest that the climate system is sensitive to small changes and can readily be flipped from a stable state into a different one.\nScientists meanwhile began using computers to develop more sophisticated versions of Arrhenius's calculations. In 1967, taking advantage of the ability of digital computers to integrate absorption curves numerically, Syukuro Manabe and Richard Wetherald made the first detailed calculation of the greenhouse effect incorporating convection (the \"Manabe-Wetherald one-dimensional radiative-convective model\"). They found that, in the absence of unknown feedbacks such as changes in clouds, a doubling of carbon dioxide from the current level would result in approximately 2&nbsp;°C increase in global temperature.\nBy the 1960s, aerosol pollution (\"smog\") had become a serious local problem in many cities, and some scientists began to consider whether the cooling effect of particulate pollution could affect global temperatures.  Scientists were unsure whether the cooling effect of particulate pollution or warming effect of greenhouse gas emissions would predominate, but regardless, began to suspect that human emissions could be disruptive to climate in the 21st century if not sooner.  In his 1968 book The Population Bomb, Paul R. Ehrlich wrote, \"the greenhouse effect is being enhanced now by the greatly increased level of carbon dioxide... [this] is being countered by low-level clouds generated by contrails, dust, and other contaminants ... At the moment we cannot predict what the overall climatic results will be of our using the atmosphere as a garbage dump.\"\nA 1968 study by the Stanford Research Institute for the American Petroleum Institute noted:\nIn 1969, NATO was the first candidate to deal with climate change on an international level. It was planned then to establish a hub of research and initiatives of the organization in the civil area, dealing with environmental topics as acid rain and the greenhouse effect. The suggestion of US President Richard Nixon was not very successful with the administration of German Chancellor Kurt Georg Kiesinger. But the topics and the preparation work done on the NATO proposal by the German authorities gained international momentum, (see e.g. the Stockholm United Nations Conference on the Human Environment 1970) as the government of Willy Brandt started to apply them on the civil sphere instead.\nAlso in 1969, Mikhail Budyko published a theory on the ice-albedo feedback, a foundational element of what is today known as Arctic amplification. The same year a similar model was published by William D. Sellers. Both studies attracted significant attention, since they hinted at the possibility for a runaway positive feedback within the global climate system.\nIn the early 1970s, evidence that aerosols were increasing worldwide encouraged Reid Bryson and some others to warn of the possibility of severe cooling. Meanwhile, the new evidence that the timing of ice ages was set by predictable orbital cycles suggested that the climate would gradually cool, over thousands of years. For the century ahead, however, a survey of the scientific literature from 1965 to 1979 found 7 articles predicting cooling and 44 predicting warming (many other articles on climate made no prediction); the warming articles were cited much more often in subsequent scientific literature. Several scientific panels from this time period concluded that more research was needed to determine whether warming or cooling was likely, indicating that the trend in the scientific literature had not yet become a consensus.\nJohn Sawyer published the study Man-made Carbon Dioxide and the \"Greenhouse\" Effect in 1972. He summarized the knowledge of the science at the time, the anthropogenic attribution of the carbon dioxide greenhouse gas, distribution and exponential rise, findings which still hold today. Additionally he accurately predicted the rate of global warming for the period between 1972 and 2000.\nThe mainstream news media at the time exaggerated the warnings of the minority who expected imminent cooling. For example, in 1975, Newsweek magazine published a story that warned of \"ominous signs that the Earth's weather patterns have begun to change.\" The article continued by stating that evidence of global cooling was so strong that meteorologists were having \"a hard time keeping up with it.\" On 23 October 2006, Newsweek issued an update stating that it had been \"spectacularly wrong about the near-term future\".\nIn the first two \"Reports for the Club of Rome\" in 1972 and 1974, the anthropogenic climate changes by  increase as well as by waste heat were mentioned. About the latter John Holdren wrote in a study cited in the 1st report, \"... that global thermal pollution is hardly our most immediate environmental threat. It could prove to be the most inexorable, however, if we are fortunate enough to evade all the rest.\" Simple global-scale estimates that recently have been actualized and confirmed by more refined model calculations show noticeable contributions from waste heat to global warming after the year 2100, if its growth rates are not strongly reduced (below the averaged 2% p.a. which occurred since 1973).\nEvidence for warming accumulated. By 1975, Manabe and Wetherald had developed a three-dimensional Global climate model that gave a roughly accurate representation of the current climate. Doubling  in the model's atmosphere gave a roughly 2&nbsp;°C rise in global temperature. Several other kinds of computer models gave similar results: it was impossible to make a model that gave something resembling the actual climate and not have the temperature rise when the  concentration was increased.\nThe 1979 World Climate Conference (12 to 23 February) of the World Meteorological Organization concluded \"it appears plausible that an increased amount of carbon dioxide in the atmosphere can contribute to a gradual warming of the lower atmosphere, especially at higher latitudes....It is possible that some effects on a regional and global scale may be detectable before the end of this century and become significant before the middle of the next century.\"\nIn July 1979 the United States National Research Council published a report,\nconcluding (in part):\ncontent of the atmosphere is doubled and statistical thermal equilibrium is achieved, the more realistic of the modeling efforts predict a global surface warming of between 2&nbsp;°C and 3.5&nbsp;°C, with greater increases at high latitudes.\n... we have tried but have been unable to find any overlooked or underestimated physical effects that could reduce the currently estimated global warmings due to a doubling of atmospheric  to negligible proportions or reverse them altogether.}}\nduring his 1988 testimony to Congress, which alerted the public to the dangers of global warming]]\nBy the early 1980s, the slight cooling trend from 1945 to 1975 had stopped.  Aerosol pollution had decreased in many areas due to environmental legislation and changes in fuel use, and it became clear that the cooling effect from aerosols was not going to increase substantially while carbon dioxide levels were progressively increasing.\nHansen and others published the 1981 study Climate impact of increasing atmospheric carbon dioxide, and noted: }}\nIn 1982, Greenland ice cores drilled by Hans Oeschger, Willi Dansgaard, and collaborators revealed dramatic temperature oscillations in the space of a century in the distant past. The most prominent of the changes in their record corresponded to the violent Younger Dryas climate oscillation seen in shifts in types of pollen in lake beds all over Europe. Evidently drastic climate changes were possible within a human lifetime.\nIn 1985 a joint UNEP/WMO/ICSU Conference on the \"Assessment of the Role of Carbon Dioxide and Other Greenhouse Gases in Climate Variations and Associated Impacts\"  concluded that greenhouse gases \"are expected\" to cause significant warming in the next century and that some warming is inevitable.\nMeanwhile, ice cores drilled by a Franco-Soviet team at the Vostok Station in Antarctica showed that  and temperature had gone up and down together in wide swings through past ice ages. This confirmed the -temperature relationship in a manner entirely independent of computer climate models, strongly reinforcing the emerging scientific consensus. The findings also pointed to powerful biological and geochemical feedbacks.\nIn June 1988, James E. Hansen made one of the first assessments that human-caused warming had already measurably affected global climate. Shortly after, a \"World Conference on the Changing Atmosphere: Implications for Global Security\" gathered hundreds of scientists and others in Toronto. They concluded that the changes in the atmosphere due to human pollution \"represent a major threat to international security and are already having harmful consequences over many parts of the globe,\" and declared that by 2005 the world would be well-advised to push its emissions some 20% below the 1988 level.\nThe 1980s saw important breakthroughs with regard to global environmental challenges. Ozone depletion was mitigated by the Vienna Convention (1985) and the Montreal Protocol (1987). Acid rain was mainly regulated on national and regional levels.\nColors indicate temperature anomalies (NASA/NOAA; 20 January 2016).\nIn 1988 the WMO established the Intergovernmental Panel on Climate Change with the support of the UNEP. The IPCC continues its work through the present day, and issues a series of Assessment Reports and supplemental reports that describe the state of scientific understanding at the time each report is prepared. Scientific developments during this period are summarized about once every five to six years in the IPCC Assessment Reports which were published in 1990 (First Assessment Report), 1995 (Second Assessment Report), 2001 (Third Assessment Report), 2007 (Fourth Assessment Report), and 2013/2014 (Fifth Assessment Report).\nSince the 1990s, research on climate change has expanded and grown, linking many fields such as atmospheric sciences, numerical modeling, behavioral sciences, geology and economics, or security.\nEngineering and technology\nI, December 17, 1903, Orville piloting, Wilbur running at wingtip.]]\nOne of the prominent traits of the 20th century was the dramatic growth of technology. Organized research and practice of science led to advancement in the fields of communication, engineering, travel, medicine, and war.\n* The number and types of home appliances increased dramatically due to advancements in technology, electricity availability, and increases in wealth and leisure time. Such basic appliances as washing machines, clothes dryers, furnaces, exercise machines, refrigerators, freezers, electric stoves, and vacuum cleaners all became popular from the 1920s through the 1950s. The microwave oven was built on 25 October 1955 and became popular during the 1980s and have become a standard in all homes by the 1990s. Radios were popularized as a form of entertainment during the 1920s, which extended to television during the 1950s. Cable and satellite television spread rapidly during the 1980s and 1990s. Personal computers began to enter the home during the 1970s–1980s as well. The age of the portable music player grew during the 1960s with the development of the transistor radio,  8-track and cassette tapes, which slowly began to replace record players These were in turn replaced by the CD during the late 1980s and 1990s. The proliferation of the Internet in the mid-to-late 1990s made digital distribution of music (mp3s) possible. VCRs were popularized in the 1970s, but by the end of the 20th century, DVD players were beginning to replace them, making the VHS obsolete by the end of the first decade of the 21st century.\n* The first airplane was flown in 1903.  With the engineering of the faster jet engine in the 1940s, mass air travel became commercially viable.\n* The assembly line made mass production of the automobile viable. By the end of the 20th century, billions of people had automobiles for personal transportation.  The combination of the automobile, motor boats and air travel allowed for unprecedented personal mobility. In western nations, motor vehicle accidents became the greatest cause of death for young people. However, expansion of divided highways reduced the death rate.\n* The triode tube, transistor and integrated circuit successively revolutionized electronics and computers, leading to the proliferation of the personal computer in the 1980s and cell phones and the public-use Internet in the 1990s.\n* New materials, most notably stainless steel, Velcro, silicone, teflon, and plastics such as polystyrene, PVC, polyethylene, and nylon came into widespread use for many various applications. These materials typically have tremendous performance gains in strength, temperature, chemical resistance, or mechanical properties over those known prior to the 20th century.\n* Aluminium became an inexpensive metal and became second only to iron in use.\n* Semiconductor materials were discovered, and methods of production and purification developed for use in electronic devices. Silicon became one of the purest substances ever produced.\n* Thousands of chemicals were developed for industrial processing and home use.\nMathematics\nThe 20th century saw mathematics become a major profession. As in most areas of study, the explosion of knowledge in the scientific age has led to specialization: by the end of the century there were hundreds of specialized areas in mathematics and the Mathematics Subject Classification was dozens of pages long.  Every year, thousands of new Ph.D.s in mathematics were awarded, and jobs were available in both teaching and industry.  More and more mathematical journals were published and, by the end of the century, the development of the World Wide Web led to online publishing. Mathematical collaborations of unprecedented size and scope took place. An example is the classification of finite simple groups (also called the \"enormous theorem\"), whose proof between 1955 and 1983 required 500-odd journal articles by about 100 authors, and filling tens of thousands of pages.\nIn a 1900 speech to the International Congress of Mathematicians, David Hilbert set out a list of 23 unsolved problems in mathematics. These problems, spanning many areas of mathematics, formed a central focus for much of 20th-century mathematics. Today, 10 have been solved, 7 are partially solved, and 2 are still open. The remaining 4 are too loosely formulated to be stated as solved or not.\nIn 1929 and 1930, it was proved the truth or falsity of all statements formulated about the natural numbers plus one of addition and multiplication, was decidable, i.e. could be determined by some algorithm. In 1931, Kurt Gödel found that this was not the case for the natural numbers plus both addition and multiplication; this system, known as Peano arithmetic, was in fact incompletable. (Peano arithmetic is adequate for a good deal of number theory, including the notion of prime number.) A consequence of Gödel's two incompleteness theorems is that in any mathematical system that includes Peano arithmetic (including all of analysis and geometry), truth necessarily outruns proof, i.e. there are true statements that cannot be proved within the system. Hence mathematics cannot be reduced to mathematical logic, and David Hilbert's dream of making all of mathematics complete and consistent needed to be reformulated.\nIn 1963, Paul Cohen proved that the continuum hypothesis is independent of (could neither be proved nor disproved from) the standard axioms of set theory. In 1976, Wolfgang Haken and Kenneth Appel used a computer to prove the four color theorem. Andrew Wiles, building on the work of others, proved Fermat's Last Theorem in 1995. In 1998 Thomas Callister Hales proved the Kepler conjecture.\n]]\nDifferential geometry came into its own when Albert Einstein used it in general relativity. Entirely new areas of mathematics such as mathematical logic, topology, and John von Neumann's game theory changed the kinds of questions that could be answered by mathematical methods. All kinds of structures were abstracted using axioms and given names like metric spaces, topological spaces etc. As mathematicians do, the concept of an abstract structure was itself abstracted and led to category theory. Grothendieck and Serre recast algebraic geometry using sheaf theory. Large advances were made in the qualitative study of dynamical systems that Poincaré had begun in the 1890s.\nMeasure theory was developed in the late 19th and early 20th centuries. Applications of measures include the Lebesgue integral, Kolmogorov's axiomatisation of probability theory, and ergodic theory. Knot theory greatly expanded. Quantum mechanics led to the development of functional analysis. Other new areas include Laurent Schwartz's distribution theory, fixed point theory, singularity theory and René Thom's catastrophe theory, model theory, and Mandelbrot's fractals. Lie theory with its Lie groups and Lie algebras became one of the major areas of study.\nNon-standard analysis, introduced by Abraham Robinson, rehabilitated the infinitesimal approach to calculus, which had fallen into disrepute in favour of the theory of limits, by extending the field of real numbers to the Hyperreal numbers which include infinitesimal and infinite quantities. An even larger number system, the surreal numbers were discovered by John Horton Conway in connection with combinatorial games.\nThe development and continual improvement of computers, at first mechanical analog machines and then digital electronic machines, allowed industry to deal with larger and larger amounts of data to facilitate mass production and distribution and communication, and new areas of mathematics were developed to deal with this: Alan Turing's computability theory; complexity theory; Derrick Henry Lehmer's use of ENIAC to further number theory and the Lucas-Lehmer test; Rózsa Péter's recursive function theory; Claude Shannon's information theory; signal processing; data analysis; optimization and other areas of operations research. In the preceding centuries much mathematical focus was on calculus and continuous functions, but the rise of computing and communication networks led to an increasing importance of discrete concepts and the expansion of combinatorics including graph theory. The speed and data processing abilities of computers also enabled the handling of mathematical problems that were too time-consuming to deal with by pencil and paper calculations, leading to areas such as numerical analysis and symbolic computation. Some of the most important methods and algorithms of the 20th century are: the simplex algorithm, the fast Fourier transform, error-correcting codes, the Kalman filter from control theory and the RSA algorithm of public-key cryptography.\nPhysics\n* New areas of physics, like special relativity, general relativity, and quantum mechanics, were developed during the first half of the century. In the process, the internal structure of atoms came to be clearly understood, followed by the discovery of elementary particles.\n* It was found that all the known forces can be traced to only four fundamental interactions. It was discovered further that two forces, electromagnetism and weak interaction, can be merged in the electroweak interaction, leaving only three different fundamental interactions.\n* Discovery of nuclear reactions, in particular nuclear fusion, finally revealed the source of solar energy.\n*Radiocarbon dating was invented, and became a powerful technique for determining the age of prehistoric animals and plants as well as historical objects.\n* Stellar nucleosynthesis was refined as a theory in 1954 by Fred Hoyle; the theory was supported by astronomical evidence that showed chemical elements were created by nuclear fusion reactions within stars.\nQuantum mechanics\nSocial sciences\n* Ivan Pavlov developed the theory of classical conditioning.\n* The Austrian School of economic theory gained in prominence.\nReferences"
    }
  ]
}