{
  "content": [
    {
      "type": "text",
      "text": "# Cauchy–Schwarz inequality__disambig_1\n\nThe Cauchy–Schwarz inequality (also called Cauchy–Bunyakovsky–Schwarz inequality) is an upper bound on the absolute value of the inner product between two vectors in an inner product space in terms of the product of the vector norms. It is considered one of the most important and widely used inequalities in mathematics.\nInner products of vectors can describe finite sums (via finite-dimensional vector spaces), infinite series (via vectors in sequence spaces), and integrals (via vectors in Hilbert spaces). The inequality for sums was published by . The corresponding inequality for integrals was published by  and . Schwarz gave the modern proof of the integral version.\nStatement of the inequality\nThe Cauchy–Schwarz inequality states that for all vectors \\mathbf{u} and \\mathbf{v} of an inner product space\n{{NumBlk|:|\\left |\\langle \\mathbf{u}, \\mathbf{v} \\rangle\\right |^2 \\leq \\langle \\mathbf{u}, \\mathbf{u} \\rangle \\cdot \\langle \\mathbf{v}, \\mathbf{v} \\rangle,|}}\nwhere \\langle \\cdot, \\cdot \\rangle is the inner product. Examples of inner products include the real and complex dot product; see the examples in inner product. Every inner product gives rise to a Euclidean \\ell_2 norm, called the  or  , where the norm of a vector \\mathbf{u} is denoted and defined by\n\\|\\mathbf{u}\\| := \\sqrt{\\langle \\mathbf{u}, \\mathbf{u} \\rangle}, where \\langle \\mathbf{u}, \\mathbf{u} \\rangle is always a non-negative real number (even if the inner product is complex-valued).\nBy taking the square root of both sides of the above inequality, the Cauchy–Schwarz inequality can be written in its more familiar form in terms of the norm:\n{{NumBlk|:||\\langle \\mathbf{u}, \\mathbf{v} \\rangle| \\leq \\|\\mathbf{u}\\|  \\|\\mathbf{v}\\|.|}}\nMoreover, the two sides are equal if and only if \\mathbf{u} and \\mathbf{v} are linearly dependent.\nSpecial cases\nSedrakyan's lemma – positive real numbers\nSedrakyan's inequality, also known as Bergström's inequality, Engel's form, Titu's lemma (or the T2 lemma), states that for real numbers u_1, u_2, \\dots, u_n and positive real numbers v_1, v_2, \\dots, v_n:\n\\frac{\\left(u_1 + u_2 + \\cdots + u_n\\right)^2}{v_1 + v_2 + \\cdots + v_n} \\leq \\frac{u^2_1}{v_1} + \\frac{u^2_2}{v_2} + \\cdots + \\frac{u^2_n}{v_n},\nor, using summation notation,\n\\biggl(\\sum_{i=1}^n u_i\\biggr)^2 \\bigg/ \\sum_{i=1}^n v_i \\,\\leq\\, \\sum_{i=1}^n \\frac{u_i^2}{v_i}.\nIt is a direct consequence of the Cauchy–Schwarz inequality, obtained by using the dot product on \\R^n upon substituting u_i' = \\frac{u_i}{\\sqrt{v_i\\vphantom{t}}} and v_i' = {\\textstyle \\sqrt{v_i\\vphantom{t}}}. This form is especially helpful when the inequality involves fractions where the numerator is a perfect square.\n- The plane\nThe real vector space \\R^2 denotes the 2-dimensional plane. It is also the 2-dimensional Euclidean space where the inner product is the dot product.\nIf \\mathbf{u} = (u_1, u_2) and \\mathbf{v} = (v_1, v_2) then the Cauchy–Schwarz inequality becomes:\n\\langle \\mathbf{u}, \\mathbf{v} \\rangle^2 = \\bigl(\\|\\mathbf{u}\\| \\|\\mathbf{v}\\| \\cos \\theta\\bigr)^2 \\leq \\|\\mathbf{u}\\|^2 \\|\\mathbf{v}\\|^2,\nwhere \\theta is the angle between \\mathbf{u} and \\mathbf{v}.\nThe form presented here is perhaps the easiest in which to understand the inequality, as the square of the cosine can be at most 1, which occurs when the vectors are in the same or opposite directions. It can also be restated in terms of the vector coordinates u_1, u_2, v_1, and v_2 as\n\\left(u_1 v_1 + u_2 v_2\\right)^2 \\leq \\left(u_1^2 + u_2^2\\right) \\left(v_1^2 + v_2^2\\right),\nwhere equality holds if and only if the vector \\left(u_1, u_2\\right) is in the same or opposite direction as the vector \\left(v_1, v_2\\right), or if one of them is the zero vector.\n: n-dimensional Euclidean space\nIn Euclidean space \\R^n with the standard inner product, which is the dot product, the Cauchy–Schwarz inequality becomes:\n\\biggl(\\sum_{i=1}^n u_i v_i\\biggr)^2 \\leq \\biggl(\\sum_{i=1}^n u_i^2\\biggr) \\biggl(\\sum_{i=1}^n v_i^2\\biggr).\nThe Cauchy–Schwarz inequality can be proved using only elementary algebra in this case by observing that the difference of the right and the left hand side is\n\\tfrac{1}{2} \\sum_{i=1}^n\\sum_{j=1}^n (u_i v_j - u_j v_i)^2 \\ge 0\nor by considering the following quadratic polynomial in x\n(u_1 x + v_1)^2 + \\cdots + (u_n x + v_n)^2 = \\biggl(\\sum_i u_i^2\\biggr) x^2 + 2 \\biggl(\\sum_i u_i v_i\\biggr) x + \\sum_i v_i^2.\nSince the latter polynomial is nonnegative, it has at most one real root, hence its discriminant is less than or equal to zero. That is,\n\\biggl(\\sum_i u_i v_i\\biggr)^2 - \\biggl(\\sum_i {u_i^2}\\biggr)  \\biggl(\\sum_i {v_i^2}\\biggr) \\leq 0.\n: n-dimensional complex space\nIf \\mathbf{u}, \\mathbf{v} \\in \\Complex^n with \\mathbf{u} = (u_1, \\ldots, u_n) and \\mathbf{v} = (v_1, \\ldots, v_n) (where u_1, \\ldots, u_n \\in \\Complex and v_1, \\ldots, v_n \\in \\Complex) and if the inner product on the vector space \\Complex^n is the canonical complex inner product (defined by \\langle \\mathbf{u}, \\mathbf{v} \\rangle := u_1 \\overline{v_1} + \\cdots + u_{n} \\overline{v_n}, where the bar notation is used for complex conjugation), then the inequality may be restated more explicitly as follows:\n\\bigl|\\langle \\mathbf{u}, \\mathbf{v} \\rangle\\bigr|^2\n= \\Biggl|\\sum_{k=1}^n u_k\\bar{v}_k\\Biggr|^2\n\\leq \\langle \\mathbf{u}, \\mathbf{u} \\rangle \\langle \\mathbf{v}, \\mathbf{v} \\rangle\n= \\biggl(\\sum_{k=1}^n u_k \\bar{u}_k\\biggr) \\biggl(\\sum_{k=1}^n v_k \\bar{v}_k\\biggr)\n= \\sum_{j=1}^n |u_j|^2 \\sum_{k=1}^n |v_k|^2.\nThat is,\n\\bigl|u_1 \\bar{v}_1 + \\cdots + u_n \\bar{v}_n\\bigr|^2 \\leq \\bigl(|u_1|{}^2 + \\cdots + |u_n|{}^2\\bigr) \\bigl(|v_1|{}^2 + \\cdots + |v_n|{}^2\\bigr).\nFor the inner product space of square-integrable complex-valued functions, the following inequality holds.\n\\left|\\int_{\\R^n} f(x) \\overline{g(x)}\\,dx\\right|^2  \\leq  \\int_{\\R^n} \\bigl|f(x)\\bigr|^2\\,dx \\int_{\\R^n} \\bigl|g(x)\\bigr|^2 \\,dx.\nThe Hölder inequality is a generalization of this.\nApplications\nAnalysis\nIn any inner product space, the triangle inequality is a consequence of the Cauchy–Schwarz inequality, as is now shown:\n\\begin{alignat}{4}\n\\|\\mathbf{u} + \\mathbf{v}\\|^2\n&= \\langle \\mathbf{u} + \\mathbf{v}, \\mathbf{u} + \\mathbf{v} \\rangle && \\\\\n&= \\|\\mathbf{u}\\|^2 + \\langle \\mathbf{u}, \\mathbf{v} \\rangle + \\langle \\mathbf{v}, \\mathbf{u} \\rangle + \\|\\mathbf{v}\\|^2 ~ && ~ \\text{ where } \\langle \\mathbf{v}, \\mathbf{u} \\rangle = \\overline{\\langle \\mathbf{u}, \\mathbf{v} \\rangle} \\\\\n&= \\|\\mathbf{u}\\|^2 + 2 \\operatorname{Re} \\langle \\mathbf{u}, \\mathbf{v} \\rangle + \\|\\mathbf{v}\\|^2 && \\\\\n&\\leq \\|\\mathbf{u}\\|^2 + 2|\\langle \\mathbf{u}, \\mathbf{v} \\rangle| + \\|\\mathbf{v}\\|^2 && \\\\\n&\\leq \\|\\mathbf{u}\\|^2 + 2\\|\\mathbf{u}\\|\\|\\mathbf{v}\\| + \\|\\mathbf{v}\\|^2 ~ && ~ \\text{ using CS}\\\\\n&=\\bigl(\\|\\mathbf{u}\\| + \\|\\mathbf{v}\\|\\bigr)^2. &&\n\\end{alignat}\nTaking square roots gives the triangle inequality:\n\\|\\mathbf{u} + \\mathbf{v}\\| \\leq \\|\\mathbf{u}\\| + \\|\\mathbf{v}\\|.\nThe Cauchy–Schwarz inequality is used to prove that the inner product is a continuous function with respect to the topology induced by the inner product itself.\nGeometry\nThe Cauchy–Schwarz inequality allows one to extend the notion of \"angle between two vectors\" to any real inner-product space by defining:\n\\cos\\theta_{\\mathbf{u} \\mathbf{v}} = \\frac{\\langle \\mathbf{u}, \\mathbf{v} \\rangle}{\\|\\mathbf{u}\\| \\|\\mathbf{v}\\|}.\nThe Cauchy–Schwarz inequality proves that this definition is sensible, by showing that the right-hand side lies in the interval  and justifies the notion that (real) Hilbert spaces are simply generalizations of the Euclidean space. It can also be used to define an angle in complex inner-product spaces, by taking the absolute value or the real part of the right-hand side, as is done when extracting a metric from quantum fidelity.\nProbability theory\n\\operatorname{Var}(Y) \\geq \\operatorname{Cov} (Y, X) \\operatorname{Var}^{-1}(X) \\operatorname{Cov}(X, Y)\nThis inequality means that the difference is semidefinite positive. -->\nLet X and Y be random variables. Then the covariance inequality is given by:\n\\operatorname{Var}(X) \\geq \\frac{\\operatorname{Cov}(X, Y)^2}{\\operatorname{Var}(Y)}.\nAfter defining an inner product on the set of random variables using the expectation of their product,\n\\langle X, Y \\rangle := \\operatorname{E}(X Y),\nthe Cauchy–Schwarz inequality becomes\n\\bigl|\\operatorname{E}(XY)\\bigr|^2 \\leq \\operatorname{E}(X^2) \\operatorname{E}(Y^2).\nTo prove the covariance inequality using the Cauchy–Schwarz inequality, let \\mu = \\operatorname{E}(X) and \\nu = \\operatorname{E}(Y), then\n\\begin{align}\n\\bigl|\\operatorname{Cov}(X, Y)\\bigr|^2\n&= \\bigl|\\operatorname{E}((X - \\mu)(Y - \\nu))\\bigr|^2 \\\\\n&= \\bigl|\\langle X - \\mu, Y - \\nu \\rangle \\bigr|^2\\\\\n&\\leq \\langle X - \\mu, X - \\mu \\rangle \\langle Y - \\nu, Y - \\nu \\rangle \\\\\n& = \\operatorname{E}\\left((X - \\mu)^2\\right) \\operatorname{E}\\left((Y - \\nu)^2\\right) \\\\\n& = \\operatorname{Var}(X) \\operatorname{Var}(Y),\n\\end{align}\nwhere \\operatorname{Var} denotes variance and \\operatorname{Cov} denotes covariance.\nProofs\nThere are many different proofs of the Cauchy–Schwarz inequality other than those given below.\nWhen consulting other sources, there are often two sources of confusion. First, some authors define  to be linear in the second argument rather than the first.\nSecond, some proofs are only valid when the field is \\mathbb R and not \\mathbb C.\nThis section gives two proofs of the following theorem:\n{{math theorem|name=Cauchy–Schwarz inequality|note=|style=|math_statement=\nLet \\mathbf{u} and \\mathbf{v} be arbitrary vectors in an inner product space over the scalar field \\mathbb{F}, where \\mathbb F is the field of real numbers \\R or complex numbers \\Complex. Then\n{{NumBlk|:|\\bigl|\\langle \\mathbf{u}, \\mathbf{v} \\rangle\\bigr| \\leq \\|\\mathbf{u}\\| \\|\\mathbf{v}\\||}}\nwith  in the  if and only if \\mathbf{u} and \\mathbf{v} are linearly dependent.\nMoreover, if  \\left| \\langle \\mathbf{u}, \\mathbf{v} \\rangle\\right| = \\|\\mathbf{u}\\| \\|\\mathbf{v}\\| and \\mathbf{v} \\neq \\mathbf{0} then \\mathbf{u} = \\frac{\\langle \\mathbf{u}, \\mathbf{v} \\rangle}{\\|\\mathbf{v}\\|^2} \\mathbf{v}.\n}}\nIn both of the proofs given below, the proof in the trivial case where at least one of the vectors is zero (or equivalently, in the case where \\|\\mathbf{u}\\|\\|\\mathbf{v}\\|= 0) is the same. It is presented immediately below only once to reduce repetition. It also includes the easy part of the proof of the Equality Characterization given above; that is, it proves that if \\mathbf{u} and \\mathbf{v} are linearly dependent then \\bigl|\\langle \\mathbf{u}, \\mathbf{v} \\rangle\\bigr| = \\|\\mathbf{u}\\| \\|\\mathbf{v}\\|.\n{{collapse top|title=Proof of the trivial parts: Case where a vector is \\mathbf{0} and also one direction of the Equality Characterization|left=true}}\nBy definition, \\mathbf{u} and \\mathbf{v} are linearly dependent if and only if one is a scalar multiple of the other.\nIf \\mathbf{u} = c \\mathbf{v} where c is some scalar then\n|\\langle \\mathbf{u}, \\mathbf{v} \\rangle|\n= |\\langle c \\mathbf{v}, \\mathbf{v} \\rangle|\n= |c \\langle \\mathbf{v}, \\mathbf{v} \\rangle|\n= |c|\\|\\mathbf{v}\\| \\|\\mathbf{v}\\|\n=\\|c \\mathbf{v}\\| \\|\\mathbf{v}\\|\n=\\|\\mathbf{u}\\| \\|\\mathbf{v}\\|\nwhich shows that equality holds in the .\nThe case where \\mathbf{v} = c \\mathbf{u} for some scalar c follows from the previous case:\n|\\langle \\mathbf{u}, \\mathbf{v} \\rangle|\n= |\\langle \\mathbf{v}, \\mathbf{u} \\rangle|\n=\\|\\mathbf{v}\\| \\|\\mathbf{u}\\|.\nIn particular, if at least one of \\mathbf{u} and \\mathbf{v} is the zero vector then \\mathbf{u} and \\mathbf{v} are necessarily linearly dependent (for example, if \\mathbf{u} = \\mathbf{0} then \\mathbf{u} = c \\mathbf{v} where c = 0), so the above computation shows that the Cauchy–Schwarz inequality holds in this case.\nConsequently, the Cauchy–Schwarz inequality only needs to be proven only for non-zero vectors and also only the non-trivial direction of the Equality Characterization must be shown.\nProof via the Pythagorean theorem\nThe special case of \\mathbf{v} = \\mathbf{0} was proven above so it is henceforth assumed that \\mathbf{v} \\neq \\mathbf{0}.\nLet\n\\mathbf{z} := \\mathbf{u} - \\frac {\\langle \\mathbf{u}, \\mathbf{v} \\rangle} {\\langle \\mathbf{v}, \\mathbf{v} \\rangle} \\mathbf{v}.\nIt follows from the linearity of the inner product in its first argument that:\n\\langle \\mathbf{z}, \\mathbf{v} \\rangle\n= \\left\\langle \\mathbf{u} - \\frac{\\langle \\mathbf{u}, \\mathbf{v} \\rangle} {\\langle \\mathbf{v}, \\mathbf{v} \\rangle} \\mathbf{v}, \\mathbf{v} \\right\\rangle\n= \\langle \\mathbf{u}, \\mathbf{v} \\rangle - \\frac{\\langle \\mathbf{u}, \\mathbf{v} \\rangle} {\\langle \\mathbf{v}, \\mathbf{v} \\rangle} \\langle \\mathbf{v}, \\mathbf{v} \\rangle\n= 0.\nTherefore, \\mathbf{z} is a vector orthogonal to the vector \\mathbf{v} (Indeed, \\mathbf{z} is the projection of \\mathbf{u} onto the plane orthogonal to \\mathbf{v}.) We can thus apply the Pythagorean theorem to\n\\mathbf{u}= \\frac{\\langle \\mathbf{u}, \\mathbf{v} \\rangle} {\\langle \\mathbf{v}, \\mathbf{v} \\rangle} \\mathbf{v} + \\mathbf{z}\nwhich gives\n\\|\\mathbf{u}\\|^2\n= \\left|\\frac{\\langle \\mathbf{u}, \\mathbf{v} \\rangle}{\\langle \\mathbf{v}, \\mathbf{v} \\rangle}\\right|^2 \\|\\mathbf{v}\\|^2 + \\|\\mathbf{z}\\|^2\n= \\frac{|\\langle \\mathbf{u}, \\mathbf{v} \\rangle|^2}{(\\|\\mathbf{v}\\|^2 )^2} \\,\\|\\mathbf{v}\\|^2 + \\|\\mathbf{z}\\|^2\n= \\frac{|\\langle \\mathbf{u}, \\mathbf{v} \\rangle|^2}{\\|\\mathbf{v}\\|^2} + \\|\\mathbf{z}\\|^2 \\geq \\frac{|\\langle \\mathbf{u}, \\mathbf{v} \\rangle|^2}{\\|\\mathbf{v}\\|^2}.\nThe Cauchy–Schwarz inequality follows by multiplying by \\|\\mathbf{v}\\|^2 and then taking the square root.\nMoreover, if the relation \\geq in the above expression is actually an equality, then \\|\\mathbf{z}\\|^2 = 0 and hence \\mathbf{z} = \\mathbf{0}; the definition of \\mathbf{z} then establishes a relation of linear dependence between \\mathbf{u} and \\mathbf{v}. The converse was proved at the beginning of this section, so the proof is complete. \\blacksquare\nProof by analyzing a quadratic\nConsider an arbitrary pair of vectors \\mathbf{u}, \\mathbf{v}.  Define the function p : \\R \\to \\R defined by p(t) = \\langle t\\alpha\\mathbf{u} + \\mathbf{v}, t\\alpha\\mathbf{u} + \\mathbf{v}\\rangle, where \\alpha is a complex number satisfying |\\alpha| = 1 and \\alpha\\langle\\mathbf{u}, \\mathbf{v}\\rangle = |\\langle\\mathbf{u}, \\mathbf{v}\\rangle|.\nSuch an \\alpha exists since if \\langle\\mathbf{u}, \\mathbf{v}\\rangle = 0 then \\alpha can be taken to be 1.\nSince the inner product is positive-definite, p(t) only takes non-negative real values. On the other hand, p(t) can be expanded using the bilinearity of the inner product:\n\\begin{align}\np(t)\n&= \\langle t\\alpha\\mathbf{u}, t\\alpha\\mathbf{u}\\rangle + \\langle t\\alpha\\mathbf{u}, \\mathbf{v}\\rangle + \\langle\\mathbf{v}, t\\alpha\\mathbf{u}\\rangle + \\langle\\mathbf{v}, \\mathbf{v}\\rangle \\\\\n&= t\\alpha t\\overline{\\alpha}\\langle\\mathbf{u}, \\mathbf{u}\\rangle + t\\alpha\\langle\\mathbf{u}, \\mathbf{v}\\rangle + t\\overline{\\alpha}\\langle \\mathbf{v}, \\mathbf{u}\\rangle + \\langle\\mathbf{v}, \\mathbf{v}\\rangle \\\\\n&= \\lVert \\mathbf{u} \\rVert^2 t^2 + 2|\\langle\\mathbf{u}, \\mathbf{v}\\rangle|t + \\lVert \\mathbf{v} \\rVert^2\n\\end{align}\nThus, p is a polynomial of degree 2 (unless \\mathbf{u} = 0, which is a case that was checked earlier). Since the sign of p does not change, the discriminant of this polynomial must be non-positive:\n\\Delta = 4 \\bigl(\\,|\\langle \\mathbf{u}, \\mathbf{v} \\rangle|^2 - \\Vert \\mathbf{u} \\Vert^2 \\Vert \\mathbf{v} \\Vert^2\\bigr) \\leq 0.\nThe conclusion follows.\nFor the equality case, notice that \\Delta = 0 happens if and only if p(t) = \\bigl(t\\Vert \\mathbf{u} \\Vert + \\Vert \\mathbf{v} \\Vert\\bigr)^2. If t_0 = -\\Vert \\mathbf{v} \\Vert / \\Vert \\mathbf{u} \\Vert, then p(t_0) = \\langle t_0\\alpha\\mathbf{u} + \\mathbf{v},t_0\\alpha\\mathbf{u} + \\mathbf{v}\\rangle = 0, and hence \\mathbf{v} = -t_0\\alpha\\mathbf{u}.\nGeneralizations\nVarious generalizations of the Cauchy–Schwarz inequality exist. Hölder's inequality generalizes it to L^p norms. More generally, it can be interpreted as a special case of the definition of the norm of a linear operator on a Banach space (Namely, when the space is a Hilbert space).  Further generalizations are in the context of operator theory, e.g. for operator-convex functions and operator algebras, where the domain and/or range are replaced by a C*-algebra or W*-algebra.\nAn inner product can be used to define a positive linear functional. For example, given a Hilbert space L^2(m), m being a finite measure, the standard inner product gives rise to a positive functional \\varphi by \\varphi (g) = \\langle g, 1 \\rangle.  Conversely, every positive linear functional \\varphi on L^2(m) can be used to define an  inner product \\langle f, g \\rangle _\\varphi := \\varphi\\left(g^* f\\right), where g^* is the pointwise complex conjugate of g. In this language, the Cauchy–Schwarz inequality becomes\n\\bigl|\\varphi(g^* f)\\bigr|^2 \\leq \\varphi\\left(f^* f\\right) \\varphi\\left(g^* g\\right),\nwhich extends verbatim to positive functionals on C*-algebras:\n|note=|style=|math_statement=\nIf \\varphi is a positive linear functional on a C*-algebra A, then for all a, b \\in A, \\left|\\varphi\\left(b^*a\\right)\\right|^2 \\leq \\varphi\\left(b^*b\\right) \\varphi\\left(a^*a\\right).\n}}\nThe next two theorems are further examples in operator algebra.\n|note=Named after Richard Kadison|style=|math_statement=\nIf \\varphi is a unital positive map, then for every normal element a in its domain, we have \\varphi(a^*a) \\geq \\varphi\\left(a^*\\right) \\varphi(a) and \\varphi\\left(a^*a\\right) \\geq \\varphi(a) \\varphi\\left(a^*\\right).\n}}\nThis extends the fact \\varphi\\left(a^*a\\right) \\cdot 1 \\geq \\varphi(a)^* \\varphi(a) = |\\varphi(a)|^2, when \\varphi is a linear functional. The case when a is self-adjoint, that is, a = a^*, is sometimes known as '''Kadison's inequality'''.\n|style=|math_statement=\nFor a 2-positive map \\varphi between C*-algebras, for all a, b in its domain,\n\\begin{align}\n\\varphi(a)^*\\varphi(a) &\\leq \\Vert\\varphi(1)\\Vert \\varphi\\left(a^*a\\right), \\text{ and } \\\\[5mu]\n\\Vert\\varphi\\left(a^* b\\right)\\Vert^2 &\\leq \\Vert\\varphi\\left(a^*a\\right)\\Vert \\cdot \\Vert\\varphi\\left(b^*b\\right)\\Vert.\n\\end{align}\n}}\nAnother generalization is a refinement obtained by interpolating between both sides of the Cauchy–Schwarz inequality:\n|note=|style=|math_statement=\nFor reals 0 \\leq s \\leq t \\leq 1,\n\\begin{align}\n\\biggl(\\sum_{i=1}^n a_i b_i\\biggr)^2\n~&\\leq~ \\biggl(\\sum_{i=1}^n a_i^{1+s} b_i^{1-s}\\biggr) \\biggl(\\sum_{i=1}^n a_i^{1-s} b_i^{1+s}\\biggr) \\\\\n&\\leq~ \\biggl(\\sum_{i=1}^n a_i^{1+t} b_i^{1-t}\\biggr) \\biggl(\\sum_{i=1}^n a_i^{1-t} b_i^{1+t}\\biggr)\n~\\leq~ \\biggl(\\sum_{i=1}^n a_i^2\\biggr) \\biggl(\\sum_{i=1}^n b_i^2\\biggr).\n\\end{align}\n}}\nThis theorem can be deduced from Hölder's inequality. There are also non-commutative versions for operators and tensor products of matrices.\nSeveral matrix versions of the Cauchy–Schwarz inequality and Kantorovich inequality are applied to linear regression models.\nSee also\n*\n*\n*\n*\n*\n*\n*\nCitations\nReferences\n*\n*\n*\n*\n*\n*\n* .\n*\n* .\n*\n*\n*\nExternal links\n* [http://jeff560.tripod.com/c.html Earliest Uses: The entry on the Cauchy–Schwarz inequality has some historical information.]\n* [http://people.revoledu.com/kardi/tutorial/LinearAlgebra/LinearlyIndependent.html#LinearlyIndependentVectors Example of application of Cauchy–Schwarz inequality to determine Linearly Independent Vectors] Tutorial and Interactive program."
    }
  ]
}