{
  "content": [
    {
      "type": "text",
      "text": "# Backward stochastic differential equation\n\nA backward stochastic differential equation (BSDE) is a stochastic differential equation with a terminal condition in which the solution is required  to be adapted with respect to an underlying filtration. BSDEs naturally arise in various applications such as stochastic control, mathematical finance, and nonlinear Feynman-Kac formula.\nBackground\nBackward stochastic differential equations were introduced by Jean-Michel Bismut in 1973 in the linear case and by Ã‰tienne Pardoux and Shige Peng in 1990 in the nonlinear case.\nMathematical framework\nFix a terminal time T>0 and a probability space (\\Omega,\\mathcal{F},\\mathbb{P}). Let (B_t)_{t\\in [0,T]} be a Brownian motion with natural filtration (\\mathcal{F}_t)_{t\\in [0,T]}. A backward stochastic differential equation is an integral equation of the type\n{{NumBlk|:|Y_t = \\xi + \\int_t^T f(s,Y_s,Z_s) \\mathrm{d}s - \\int_t^T Z_s \\mathrm{d}B_s,\\quad t\\in[0,T],|}}\nwhere f:[0,T]\\times\\mathbb{R}\\times\\mathbb{R}\\to\\mathbb{R} is called the generator of the BSDE, the terminal condition \\xi is an \\mathcal{F}_T-measurable random variable, and the solution (Y_t,Z_t)_{t\\in[0,T]} consists of stochastic processes (Y_t)_{t\\in[0,T]} and (Z_t)_{t\\in[0,T]} which are adapted to the filtration (\\mathcal{F}_t)_{t\\in [0,T]}.\nExample\nIn the case f\\equiv 0, the BSDE () reduces to\n{{NumBlk|:|Y_t = \\xi - \\int_t^T Z_s \\mathrm{d}B_s,\\quad t\\in[0,T].|}}\nIf \\xi\\in L^2(\\Omega,\\mathbb{P}), then it follows from the martingale representation theorem, that there exists a unique stochastic process (Z_t)_{t\\in [0,T]} such that Y_t = \\mathbb{E} [ \\xi | \\mathcal{F}_t ] and Z_t satisfy the BSDE ().\nNumerical Method\nDeep backward stochastic differential equation method is a numerical method that combines deep learning with Backward stochastic differential equation (BSDE). This method is particularly useful for solving high-dimensional problems in financial mathematics problems. By leveraging the powerful function approximation capabilities of deep neural networks, deep BSDE addresses the computational challenges faced by traditional numerical methods in high-dimensional settings. Specifically, traditional methods like finite difference methods or Monte Carlo simulations often struggle with the curse of dimensionality, where computational cost increases exponentially with the number of dimensions. Deep BSDE methods, however, employ deep neural networks to approximate solutions of high-dimensional partial differential equations (PDEs), effectively reducing the computational burden.\nSee also\n* Martingale representation theorem\n* Stochastic control\n* Stochastic differential equation\nReferences\nFurther reading\n*\n*"
    }
  ]
}