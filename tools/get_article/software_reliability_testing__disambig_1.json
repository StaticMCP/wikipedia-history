{
  "content": [
    {
      "type": "text",
      "text": "# Software reliability testing__disambig_1\n\nSoftware reliability testing is a field of software-testing that relates to testing a software's ability to function, given environmental conditions, for a  particular amount of time. Software reliability testing helps discover many problems in the software design and functionality.\nOverview\nSoftware reliability is the probability that software will work properly in a specified environment and for a given amount of time. Using the following formula, the probability of failure is calculated by testing a sample of all available input states.\nMean Time Between Failure(MTBF)=Mean Time To Failure(MTTF)+ Mean Time To Repair(MTTR)\n:Probability = Number of failing cases / Total number of cases under consideration\nThe set of all possible input states is called the input space. To find reliability of software, we need to find output space from given input space and software.\nFor reliability testing, data is gathered from various stages of development, such as the design and operating stages. The tests are limited due to restrictions such as cost and time restrictions. Statistical samples are obtained from the software products to test for the reliability of the software. Once sufficient data or information is gathered, statistical studies are done. Time constraints are handled by applying fixed dates or deadlines for the tests to be performed. After this phase, design of the software is stopped and the actual implementation phase starts. As there are restrictions on costs and time, the data is gathered carefully so that each data has some purpose and gets its expected precision.\nTo achieve the satisfactory results from reliability testing one must take care of some reliability characteristics.\nFor example, Mean Time to Failure (MTTF) is measured in terms of three factors:\n# operating time,\n# number of on off cycles,\n# and calendar time.\nIf the restrictions are on operation time or if the focus is on first point for improvement, then one can apply compressed time accelerations to reduce the testing time. If the focus is on calendar time (i.e. if there are predefined deadlines), then intensified stress testing is used.\nMeasurement\nSoftware availability is measured in terms of mean time between failures (MTBF).\nMTBF consists of mean time to failure (MTTF) and mean time to repair (MTTR). MTTF is the difference of time between two consecutive failures and MTTR is the time required to fix the failure.\n: MTBF = MTTF + MTTR\nSteady state availability represents the percentage the software is operational.\n: A = \\frac{MTTF}{MTTF+MTTR} = \\frac{MTTF}{MTBF}\nFor example, if MTTF = 1000 hours for a software, then the software should work for 1000 hours of continuous operations.\nFor the same software if the MTTR = 2 hours, then the MTBF = 1000 + 2 = 1002.\nAccordingly, A = 1000/1002 \\approx 0.998\nSoftware reliability is measured in terms of failure rate (\\lambda).\n: \\lambda = \\frac{1}{MTBF}\n: R(t) = e^{-\\lambda\\cdot t}\nReliability for software is a number between 0 and 1. Reliability increases when errors or bugs from the program are removed. There are many software reliability growth models (SRGM) (List of software reliability models) including, logarithmic, polynomial, exponential, power, and S-shaped\nObjectives of reliability testing\nThe main objective of the reliability testing is to test software performance under given conditions without any type of corrective measure using known fixed procedures considering its specifications.\nSecondary objectives\nThe secondary objectives of reliability testing is:\n# To find perceptual structure of repeating failures.\n# To find the number of failures occurring in a specified amount of time.\n# To find the mean life of the software.\n# To discover the main cause of failure.\n# Checking the performance of different units of software after taking preventive actions.\nPoints for defining objectives\nSome restrictions on creating objectives include:\n# Behaviour of the software should be defined in given conditions.\n# The objective should be feasible.\n# Time constraints should be provided.\nImportance of reliability testing\nThe application of computer software has crossed into many different fields, with software being an essential part of industrial, commercial and military systems. Because of its many applications in safety critical systems, software reliability is now an important research area. Although software engineering is becoming the fastest developing technology of the last century, there is no complete, scientific, quantitative measure to assess them. Software reliability testing is being used as a tool to help assess these software engineering technologies.\nTo improve the performance of software product and software development process, a thorough assessment of reliability is required. Testing software reliability is important because it is of great use for software managers and practitioners.\nTo verify the reliability of the software via testing:\n# A sufficient number of test cases should be executed for a sufficient amount of time to get a reasonable estimate of how long the software will execute without failure. Long duration tests are needed to identify defects (such as memory leakage and buffer overflows) that take time to cause a fault or failure to occur.\n# The distribution of test cases should match the actual or planned operational profile of the software. The more often a function or subset of the software is executed, the greater the percentage of test cases that should be allocated to that function or subset.\nTypes of reliability testing\nSoftware reliability testing includes feature testing, load testing, and regression testing.\nFeature test\nFeature testing checks the features provided by the software and is conducted in the following steps:\n* Each operation in the software is executed once.\n* Interaction between the two operations is reduced and\n* Each operation is checked for its proper execution.\nThe feature test is followed by the load test.\nLoad test\nThis test is conducted to check the performance of the software under maximum work load. Any software performs better up to some amount of workload, after which the response time of the software starts degrading. For example, a web site can be tested to see how many simultaneous users it can support without performance degradation. This testing mainly helps for Databases and Application servers. Load testing also requires software performance testing, which checks how well some software performs under workload.\nRegression test\nRegression testing is used to check if any new bugs have been introduced through previous bug fixes. Regression testing is conducted after every change or update in the software features. This testing is periodic, depending on the length and features of the software.\nTest planning\nReliability testing is more costly compared to other types of testing. Thus while doing reliability testing, proper management and planning is required. This plan includes testing process to be implemented, data about its environment, test schedule, test points, etc.\nProblems in designing test cases\nSome common problems that occur when designing test cases include:\n* Test cases can be designed simply by selecting only valid input values for each field in the software. When changes are made in a particular module, the previous values may not actually test the new features introduced after the older version of software.\n* There may be some critical runs in the software which are not handled by any existing test case. Therefore, it is necessary to ensure that all possible types of test cases are considered through careful test case selection.\nReliability enhancement through testing\nStudies during development and design of software help for improving the reliability of a product. Reliability testing is essentially performed to eliminate the failure mode of the software. Life testing of the product should always be done after the design part is finished or at least the complete design is finalized.\nFailure analysis and design improvement is achieved through testings.\nReliability growth testing\nThis testing is used to check new prototypes of the software which are initially supposed to fail frequently. The causes of failure are detected and actions are taken to reduce defects.\nSuppose T is total accumulated time for prototype. n(T) is number of failure from start to time T. The graph drawn for n(T)/T is a straight line. This graph is called Duane Plot. One can get how much reliability can be gained after all other cycles of test and fix it.\n\\begin{alignat}{5}\nln\\left[ \\frac {n\\left( T\\right)} {T}\\right] = -\\alpha ln\\left( T\\right) + b ; \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ ..... Eq:1\n\\end{alignat}\nsolving eq.1 for n(T),\n\\begin{alignat}{5}\nn \\left( T\\right) = KT^{1-\\alpha} ; \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ ...... Eq:2\n\\end{alignat}\nwhere K is e^b.\nIf the value of alpha in the equation is zero the reliability can not be improved as expected for given number of failure. For alpha greater than zero, cumulative time T increases. This explains that number of the failures doesn't depends on test lengths.\nDesigning test cases for current release\nIf new features are being added to the current version of software, then writing a test case for that operation is done differently.\n* First plan how many new test cases are to be written for current version.\n* If the new feature is part of any existing feature, then share the test cases of new and existing features among them.\n* Finally combine all test cases from current version and previous one and record all the results.\nThere is a predefined rule to calculate count of new test cases for the software. If N is the probability of occurrence of new operations for new release of the software, R is the probability of occurrence of used operations in the current release and T is the number of all previously used test cases then\n\\begin{alignat}{5}\nNew Test cases_{(current release)} = \\left( \\frac {N} {R}\\right) * T\n\\end{alignat}\nReliability evaluation based on operational testing\nThe method of operational testing is used to test the reliability of software. Here one checks how the software works in its relevant operational environment. The main problem with this type of evaluation is constructing such an operational environment. Such type of simulation is observed in some industries like nuclear industries, in aircraft, etc. Predicting future reliability is a part of reliability evaluation.\nThere are two techniques used for operational testing to test the reliability of software:\n; Steady state reliability estimation : In this case, we use feedback from delivered software products. Depending on those results, we can predict the future reliability for the next version of product. This is similar to sample testing for physical products.\n; Reliability growth based prediction : This method uses documentation of the testing procedure. For example, consider a developed software and that we are creating different new versions of that software. We consider data on the testing of each version and based on the observed trend, we predict the reliability of the new version of software.\nReliability growth assessment and prediction\nIn the assessment and prediction of software reliability, we use the reliability growth model. During operation of the software, any data about its failure is stored in statistical form and is given as input to the reliability growth model. Using this data, the reliability growth model can evaluate the reliability of software.\nMuch data about reliability growth model is available with probability models claiming to represent failure process. But there is no model which is best suited for all conditions. Therefore, we must choose a model based on the appropriate conditions.\nReliability estimation based on failure-free working\nIn this case, the reliability of the software is estimated with assumptions like the following:\n* If a defect is found, then is it going to be fixed by someone.\n* Fixing the defect will not have any effect on the reliability of the software.\n* Each fix in the software is accurate.\nSee also\n* Software testing\n* Load testing\n* Regression testing\n* Reliability engineering\n* List of software reliability models\nReferences\nExternal links\n* [http://www.weibull.com/hotwire/issue94/relbasics94.htm/ Mean Time Between Failure]\n* [http://www.weibull.com/basics/accelerated.htm/ Software Life Testing]"
    }
  ]
}